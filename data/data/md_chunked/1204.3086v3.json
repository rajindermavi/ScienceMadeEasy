[
  {
    "id": "1204.3086v3::L1-17::s0",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 1,
    "end_line": 17,
    "text": "# Definitions, notations, statement of main results\n\nIn this paper we study the one-dimensional lattice quasiperiodic Schrödinger operator $H (\\underline{x})$ acting on $l^2(\\mathbb{Z})$ by: $$\\label{op1} \n[H (\\underline{x}) \\, \\psi]_n := - \\psi_{n+1} - \\psi_{n-1} + \\lambda\\, v ({\\rm T}^n \\underline{x}) \\, \\psi_n$$ where in equation (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>):\n\n$\\rule[.2ex]{.8ex}{.8ex}$ $\\underline{x}= (x_1, x_2)\\in  \\mathbb{T}^2$ is a parameter that introduces some randomness into the system;\n\n$\\rule[.2ex]{.8ex}{.8ex}$ $\\lambda$ is a real number called the disorder of the system;\n\n$\\rule[.2ex]{.8ex}{.8ex}$ $v (\\underline{x})$ is a real valued function on $\\mathbb{T}^2 = (\\mathbb{R} / \\mathbb{Z})^2$, that is, a real valued $1$-periodic function in each variable;\n\n$\\rule[.2ex]{.8ex}{.8ex}$ ${\\rm T}$ is a specific ergodic transformation on $\\mathbb{T}^2$, and ${\\rm T}^n$ is its $n$th iteration.\n\nSome of the questions of interest regarding this, or other related operators, are the spectral types (pure point, absolutely continuous, singularly continuous), the topological structure of the spectrum, the rate of decay of the eigenfunctions, the positivity and regularity of the Lyapunov exponent, the regularity of the integrated density of states.\n\nDue to the ergodicity of the transformation ${\\rm T}$, the spectrum and the spectral types of the Hamiltonian system $[ H (\\underline{x}) ]_{\\underline{x}\\in \\mathbb{T}^2}$ defined by (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>) are not random - that is, they are independent of $\\underline{x}$ almost surely (see ).",
    "labels": [
      "op1"
    ],
    "refs": [
      "op1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L18-32::s1",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L18-32::s1",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L33-52::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L18-32::s1",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 18,
    "end_line": 32,
    "text": "Due to the ergodicity of the transformation ${\\rm T}$, the spectrum and the spectral types of the Hamiltonian system $[ H (\\underline{x}) ]_{\\underline{x}\\in \\mathbb{T}^2}$ defined by (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>) are not random - that is, they are independent of $\\underline{x}$ almost surely (see ).\n\nA stronger property than pure point spectrum is Anderson localization, which for the physical model indicates an insulating behavior, while a purely absolutely continuous spectrum indicates metallic (conductive) behavior.\n\nLet us describe these concepts more formally.\n\n<div id=\"ALdef\" class=\"definition\">\n\n**Definition 1**. *An operator satisfies Anderson localization (AL) if it has pure point spectrum with exponentially decaying eigenfunctions.*\n\n</div>\n\nConsider now the Schrödinger equation: $$\\label{seq}\nH (\\underline{x}) \\psi  =  E \\psi$$ for $\\psi = [ \\psi_n ]_{n \\in \\mathbb{Z}} \\subset  \\mathbb{R}$ and $E \\in \\mathbb{R}$.\n\nDue to Schnol-Simon’s theorem (see ), to prove AL it is enough to show that every extended state is exponentially decaying. In other words, if $\\psi$ is a formal solution to the Schrödinger equation (<a href=\"#seq\" data-reference-type=\"ref\" data-reference=\"seq\">[seq]</a>) and if $\\psi$ grows at most polynomially $\\bigl| \\psi_n \\bigr| \\lesssim\\left| n \\right|$ then $\\psi$ decays exponentially: $\\bigl| \\psi_n \\bigr|  \\lesssim e^{-c \\left| n \\right|}$",
    "labels": [
      "ALdef",
      "seq"
    ],
    "refs": [
      "op1",
      "seq"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1-17::s0",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L33-52::s2",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L1-17::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L33-52::s2",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L33-52::s2",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 33,
    "end_line": 52,
    "text": "Due to Schnol-Simon’s theorem (see ), to prove AL it is enough to show that every extended state is exponentially decaying. In other words, if $\\psi$ is a formal solution to the Schrödinger equation (<a href=\"#seq\" data-reference-type=\"ref\" data-reference=\"seq\">[seq]</a>) and if $\\psi$ grows at most polynomially $\\bigl| \\psi_n \\bigr| \\lesssim\\left| n \\right|$ then $\\psi$ decays exponentially: $\\bigl| \\psi_n \\bigr|  \\lesssim e^{-c \\left| n \\right|}$\n\nThe Schrödinger equation (<a href=\"#seq\" data-reference-type=\"ref\" data-reference=\"seq\">[seq]</a>) is a second order finite differences equation: $$- \\psi_{n+1} - \\psi_{n-1} + \\lambda\\, v ({\\rm T}^n \\underline{x}) \\, \\psi_n = E \\, \\psi_n$$ which becomes $$\\Bigl[\\begin{array}{cc}\n\\psi_{n+1}\\\\\n\\psi_n \\\\  \\end{array} \\Bigr]  = M_{N} (\\underline{x}, E)  \\Bigl[ \\begin{array}{cc}\n\\psi_1\\\\\n\\psi_0 \\\\  \\end{array} \\Bigr]$$ where $$M_{N} (\\underline{x}, E) = M_{N} (\\underline{x}, \\lambda, E)  :=\n\\prod_{j=N}^{1}  \\Bigl[ \\begin{array}{ccc}\n\\lambda v ({\\rm T}^j \\, \\underline{x}) - E  & &  - 1  \\\\\n1 & &  0 \\\\  \\end{array} \\Bigr]$$ is called the transfer (or fundamental) matrix of (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>).\n\nDefine further the function $$L_{N} (\\underline{x}, E) = L_{N} (\\underline{x}, \\lambda, E)  := \\frac{1}{N} \\log \\lVert M_N (\\underline{x}, E) \\rVert$$ and its mean $$L_N (E) = L_{N} (\\lambda, E) := \\int_{\\mathbb{T}^2} \\frac{1}{N} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d\\underline{x}$$ Due to sub-additivity, the sequence $L_N (E)$ converges.\n\n<div id=\"lyapdef\" class=\"definition\">\n\n**Definition 2**. *The limit $$L(E) := \\lim_{N \\rightarrow \\infty} L_N (E)$$ is called the Lyapunov exponent of (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>) and it measures the average exponential growth of the transfer matrices.*\n\n</div>\n\nErgodicity in fact implies that for a.e. $\\underline{x}\\in \\mathbb{T}^2$, $$\\label{ldt-ergod}\nL(E) := \\lim_{N \\rightarrow \\infty} \\frac{1}{N} \\log \\lVert M_{N}(\\underline{x}, E) \\rVert$$",
    "labels": [
      "ldt-ergod",
      "lyapdef"
    ],
    "refs": [
      "op1",
      "seq"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L18-32::s1",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L53-65::s3",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L1-17::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L18-32::s1",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L148-153::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L154-160::s3",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L53-65::s3",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 53,
    "end_line": 65,
    "text": "Ergodicity in fact implies that for a.e. $\\underline{x}\\in \\mathbb{T}^2$, $$\\label{ldt-ergod}\nL(E) := \\lim_{N \\rightarrow \\infty} \\frac{1}{N} \\log \\lVert M_{N}(\\underline{x}, E) \\rVert$$\n\nNote that since the transfer matrices have determinant $1$, the Lyapunov exponent is always nonnegative. An important question is whether it is in fact (uniformly) bounded away from $0$. This would imply, due to Kotani’s theorem, absence of absolutely continuous spectrum, and it would represent a strong indication for pure point spectrum. This is also usually the assumption under which strong continuity properties hold and an analysis of the topological structure of the spectrum is more feasible.\n\nIn this paper we prove Anderson localization and positivity and continuity of the Lyapunov exponent for large coupling constant, for certain ergodic transformations ${\\rm T}$ on $\\mathbb{T}^2$ and under certain regularity and transversality conditions on the potential function $v (\\underline{x})$. While all of our results are stated and proven for the two-dimensional torus $\\mathbb{T}^2$, their analogues on the higher dimensional torus hold as well.\n\nWe describe the assumptions on the transformation and on the potential function.\n\nWe start with some notations: for a multi-index $\\underline{m}= (m_1, m_2)\\in \\mathbb{Z}^2$, we write $\\left| \\underline{m} \\right| := \\left| m_1 \\right| + \\left| m_2 \\right|$ and if $\\underline{m}= (m_1, m_2)\\in \\mathbb{N}^2$, then $\\underline{m}! := m_1! \\cdot m_2!$ Moreover, for $\\underline{\\alpha}= (\\alpha_1, \\alpha_2) \\text{ and }  \\underline{m}= (m_1, m_2)\\in \\mathbb{N}^2$, we write $\\underline{\\alpha}\\le \\underline{m}$ when $\\alpha_1 \\le m_1$ and $\\alpha_2 \\le m_2$.\n\nThroughout this paper, the transformation ${\\rm T}\\colon \\mathbb{T}^2 \\to \\mathbb{T}^2$ will represent:\n\n$\\rule[.2ex]{.8ex}{.8ex}$ Either the *skew-shift* $$\\label{skew}\n{\\rm S}_\\omega\\, (x_1, x_2):= (x_1 + x_2,  x_2  + \\omega)$$ where $\\omega\\in \\mathbb{T}$ is irrational.",
    "labels": [
      "ldt-ergod",
      "skew"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L33-52::s2",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L148-153::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L154-160::s3",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L66-84::s4",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 66,
    "end_line": 84,
    "text": "$\\rule[.2ex]{.8ex}{.8ex}$ Either the *skew-shift* $$\\label{skew}\n{\\rm S}_\\omega\\, (x_1, x_2):= (x_1 + x_2,  x_2  + \\omega)$$ where $\\omega\\in \\mathbb{T}$ is irrational.\n\nIts $n$th iteration is given by: $$\\label{skewn}\n{\\rm S}_\\omega^n \\, (x_1, x_2)= (x_1 + n x_2 + \\frac{n (n-1)}{2} \\omega, \\, x_2 + n \\omega)$$\n\n$\\rule[.2ex]{.8ex}{.8ex}$ Or the *multi-frequency shift* $$\\label{multishift}\n{\\rm T}_{\\underline{\\omega}} \\, (x_1, x_2):= (x_1 + \\omega_1,  x_2 + \\omega_2)$$ where $\\underline{\\omega}= (\\omega_1, \\omega_2) \\in \\mathbb{T}^2$ and $\\omega_1,  \\omega_2$ are rationally independent.\n\nIts $n$th iteration is given by: $$\\label{multishiftn}\n{\\rm T}_{\\underline{\\omega}}^n \\, (\\underline{x}) = \\underline{x}+ n \\, \\underline{\\omega}= (x_1 + n \\omega_1, \\, x_2 + n \\omega_2)$$\n\nThe irrationality / rational independence of the frequency ensures that the corresponding transformation is ergodic. However, we need to make a quantitative assumption on this rational independence, for reasons that will be described later.\n\nWe say that the frequency $\\omega\\in \\mathbb{T}$ satisfies a Diophantine condition $DC_\\kappa$ for some $\\kappa > 0$ if $$\\label{DC}\n\\mbox{dist } (l \\omega,  \\mathbb{Z} )  =:  \\lVert l \\, \\omega\\rVert > \\kappa \\cdot \n\\frac{1} {\\left| l \\right| [ \\log(1 + \\left| l \\right|) ]^{2}}   \\quad \\text{ for all } \\  l \\in  \\mathbb{Z} \\setminus \\{ 0 \\}$$\n\nWe say that the (multi)frequency $\\underline{\\omega}\\in \\mathbb{T}^2$ satisfies a Diophantine condition $DC_\\kappa$ for some $\\kappa > 0$ and a fixed constant $A >2$, if $$\\label{DCM}\n \\lVert\\underline{l}\\cdot \\underline{\\omega}\\rVert := \\lVert l_1 \\,  \\omega_1 + l_2 \\, \\omega_2\\rVert > \\kappa \\cdot \n\\frac{1} {\\left| \\underline{l} \\right|^A}  \\quad \\text{ for all } \\  \\underline{l}\\in  \\mathbb{Z}^2 \\setminus \\{ (0, 0) \\}$$",
    "labels": [
      "DC",
      "DCM",
      "multishift",
      "multishiftn",
      "skew",
      "skewn"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L53-65::s3",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L85-98::s5",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 85,
    "end_line": 98,
    "text": "We say that the (multi)frequency $\\underline{\\omega}\\in \\mathbb{T}^2$ satisfies a Diophantine condition $DC_\\kappa$ for some $\\kappa > 0$ and a fixed constant $A >2$, if $$\\label{DCM}\n \\lVert\\underline{l}\\cdot \\underline{\\omega}\\rVert := \\lVert l_1 \\,  \\omega_1 + l_2 \\, \\omega_2\\rVert > \\kappa \\cdot \n\\frac{1} {\\left| \\underline{l} \\right|^A}  \\quad \\text{ for all } \\  \\underline{l}\\in  \\mathbb{Z}^2 \\setminus \\{ (0, 0) \\}$$\n\nNote that the set of frequencies which satisfy either <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a> or <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> has measure $1 - \\text{O} (\\kappa)$, hence almost every frequency satisfies such a Diophantine condition $DC_\\kappa$ for some $\\kappa> 0$.\n\nWhen necessary, to emphasize the dependence of the operator on the frequency, we will use the notation $H_{\\omega} (\\underline{x})$ or $H_{\\underline{\\omega}} (\\underline{x})$ respectively.\n\nNow we describe the assumptions on the potential function $v (\\underline{x})$.\n\n$\\rule[.2ex]{.8ex}{.8ex}$ We say that a $C^\\infty$ function $v (\\underline{x})$ on $\\mathbb{T}^2$ belongs to the Gevrey class $G^{s} (\\mathbb{T}^2)$ for some $s > 1$ if its partial derivatives have the following bounds: $$\\label{GC}\n\\sup_{ \\underline{x}\\in \\mathbb{T}^2}  \\bigl|  \\partial ^{\\underline{m}} \\, \\, v(\\underline{x})  \\bigr| \\leq M  K^{|\\underline{m}|} ( \\underline{m}! )^{s}  \\quad\n\\text{ for all } \\quad  \\underline{m}\\in \\mathbb{N}^2$$ for some constants $M,$ $K$ $> 0$.\n\nThis condition is equivalent (see the exercises from Chapter IV in ) to the following exponential-type decay of the Fourier coefficients of $v$: $$\\label{fcoef} \n\\bigl|  \\hat{v} (\\underline{l})  \\bigr| \\leq  M e^{- \\rho \\left|  \\underline{l} \\right|^{1/s}} \\quad  \\text{ for all } \\quad  \\underline{l}\\in \\mathbb{Z}^2$$ for some constants $M,$ $\\rho$ $> 0,$ where $\\displaystyle \nv(\\underline{x}) = \\sum_{\\underline{l}\\in \\mathbb{Z}^2} \\hat{v} (\\underline{l}) \\, e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$",
    "labels": [
      "DCM",
      "GC",
      "fcoef"
    ],
    "refs": [
      "DC",
      "DCM"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L184-187::s1",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L99-113::s6",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 99,
    "end_line": 113,
    "text": "This condition is equivalent (see the exercises from Chapter IV in ) to the following exponential-type decay of the Fourier coefficients of $v$: $$\\label{fcoef} \n\\bigl|  \\hat{v} (\\underline{l})  \\bigr| \\leq  M e^{- \\rho \\left|  \\underline{l} \\right|^{1/s}} \\quad  \\text{ for all } \\quad  \\underline{l}\\in \\mathbb{Z}^2$$ for some constants $M,$ $\\rho$ $> 0,$ where $\\displaystyle \nv(\\underline{x}) = \\sum_{\\underline{l}\\in \\mathbb{Z}^2} \\hat{v} (\\underline{l}) \\, e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$\n\nNote from (<a href=\"#GC\" data-reference-type=\"ref\" data-reference=\"GC\">[GC]</a>) or (<a href=\"#fcoef\" data-reference-type=\"ref\" data-reference=\"fcoef\">[fcoef]</a>) with $s = 1$ that the Gevrey class $G^{1} (\\mathbb{T}^2)$ is the class of real analytic functions on $\\mathbb{T}^2$.\n\nNote also that $s_1  <  s_2 \\hspace{.1in} \\Rightarrow \\hspace{.1in} G^{s_1} (\\mathbb{T}^2) \\subset G^{s_2} (\\mathbb{T}^2)$, so the greater the order of the Gevrey class, the larger the class.\n\nThe Gevrey-class of any order $s > 1$ is an intermediate Carleman class of functions between analytic functions and $C^\\infty$ functions. They are not, however, quasi-analytic (one can easily construct examples or use a general test for quasi-analyticity of Carleman classes, as in Chapter V.2 in ).\n\nWe will then impose on our potential function $v$ the following generic transversality condition (TC).\n\n$\\rule[.2ex]{.8ex}{.8ex}$ We say that a function $v (\\underline{x})$ is transversal if $v$ is not flat at any point: $$\\label{TC}\n\\text{For any } \\,  \\underline{x}\\in \\mathbb{T}^2 \\  \\text{ there is }  \\,  \\underline{m}\\in \\mathbb{N}^2, \\,  \\left| \\underline{m} \\right|  \\neq 0  \\ \\text{ such that }  \\  \\partial ^{\\underline{m}} \\, \\, v(\\underline{x}) \\neq 0$$\n\nNon-constant analytic functions automatically satisfy <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>. Therefore, a Schrödinger operator with potential given by a function which satisfies the Gevrey regularity condition <a href=\"#GC\" data-reference-type=\"eqref\" data-reference=\"GC\">[GC]</a> and the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> is a natural extension of the non constant analytic case considered in , .\n\nWe are ready to formulate the main result of this paper.",
    "labels": [
      "TC",
      "fcoef"
    ],
    "refs": [
      "GC",
      "TC",
      "fcoef"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L148-153::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L168-171::s5",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L184-187::s1",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1111-1120::s32",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1121-1144::s33",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L114-127::s7",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 114,
    "end_line": 127,
    "text": "We are ready to formulate the main result of this paper.\n\n<div id=\"main\" class=\"theorem\">\n\n**Theorem 1**. *Consider the Schrödinger operator (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>) on $l^2(\\mathbb{Z})$: $$[H (\\underline{x}) \\, \\psi]_n := - \\psi_{n+1} - \\psi_{n-1} + \\lambda\\, v ({\\rm T}^n \\underline{x}) \\, \\psi_n$$ where the transformation ${\\rm T}$ is either the skew-shift <a href=\"#skew\" data-reference-type=\"eqref\" data-reference=\"skew\">[skew]</a> or the multi-frequency shift <a href=\"#multishift\" data-reference-type=\"eqref\" data-reference=\"multishift\">[multishift]</a>. Assume that for some $\\kappa> 0$ the underlying frequency satisfies the Diophantine condition $DC_\\kappa$ described in <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a> or <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> respectively.*\n\n*Assume moreover that the potential function $v (\\underline{x})$ belongs to a Gevrey class $G^s (\\mathbb{T}^2)$ and that it is transversal as in <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>.*\n\n*There is $\\lambda_{0} = \\lambda_{0} (v, \\kappa)$ such that the following hold:*\n\n*$\\rule[.2ex]{.8ex}{.8ex}$ If $\\left| \\lambda \\right|  \\geq \\lambda_{0},$ the Lyapunov exponent is positive for all energies $E \\in \\mathbb{R}$: $$\\label{lyap1} \nL (E) \\geq \\frac{1}{4} \\log \\left| \\lambda \\right|  > 0$$*\n\n*$\\rule[.2ex]{.8ex}{.8ex}$ If $\\left| \\lambda \\right| \\geq \\lambda_{0},$ the Lyapunov exponent $L (E)$ is a continuous functions of the energy $E$, with modulus of continuity on any compact interval $\\mathcal{E}$ at least: $$\\label{modcont}\nh (t) = C \\, e^{- c  \\left| \\log t \\right|^{\\eta}}$$ where $C = C( \\mathcal{E}, \\lambda, v, \\kappa, s)$ and $c$, $\\eta$ are some positive absolute constants.*",
    "labels": [
      "lyap1",
      "main",
      "modcont"
    ],
    "refs": [
      "DC",
      "DCM",
      "TC",
      "multishift",
      "op1",
      "skew"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L128-133::s8",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1-17::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L53-65::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L148-153::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L128-133::s8",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Definitions, notations, statement of main results",
    "start_line": 128,
    "end_line": 133,
    "text": "*$\\rule[.2ex]{.8ex}{.8ex}$ If $\\left| \\lambda \\right| \\geq \\lambda_{0},$ the Lyapunov exponent $L (E)$ is a continuous functions of the energy $E$, with modulus of continuity on any compact interval $\\mathcal{E}$ at least: $$\\label{modcont}\nh (t) = C \\, e^{- c  \\left| \\log t \\right|^{\\eta}}$$ where $C = C( \\mathcal{E}, \\lambda, v, \\kappa, s)$ and $c$, $\\eta$ are some positive absolute constants.*\n\n*$\\rule[.2ex]{.8ex}{.8ex}$ Let ${\\rm T}= {\\rm S}_\\omega$ be the skew-shift. For every $\\lambda$ with $\\left| \\lambda \\right| \\geq \\lambda_{0}$, there is an exceptional set $\\mathscr{B}= \\mathscr{B}_\\lambda\\subset \\mathbb{T}^3$, with $mes \\,  \\mathscr{B}< \\kappa$, such that for all $(\\omega, \\underline{x}) \\notin \\mathscr{B}$, the operator $H_{\\omega} (\\underline{x})$ satisfies Anderson localization.*\n\n*$\\rule[.2ex]{.8ex}{.8ex}$ Let ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$ be the multi-frequency shift. Fix $\\underline{x}_0 \\in \\mathbb{T}^2$ and $\\lambda$ with $\\left| \\lambda \\right| \\geq \\lambda_{0}$. Then for a.e. multi-frequency $\\underline{\\omega}\\in DC_\\kappa$, the operator $H_{\\underline{\\omega}} (\\underline{x}_0)$ satisfies Anderson localization.*\n\n</div>",
    "labels": [
      "modcont"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Definitions, notations, statement of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L134-141::s0",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L134-141::s0",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Summary of related results, general strategy",
    "start_line": 134,
    "end_line": 141,
    "text": "# Summary of related results, general strategy\n\nThe results in this paper extend the ones in and (see also J. Bourgain’s monograph ) from non-constant real analytic potential functions, to the more general class of Gevrey potential functions satisfying a transversality condition. They also mirror similar results obtained for the one-frequency shift model on the torus $\\mathbb{T}$ (see ).\n\nIt should be noted, however, that unlike the one or multi-frequency shift, the skew-shift, due to its weekly mixing properties, is expected to behave more like the random model (presumably regardless of the regularity of the potential). In other words, for the skew-shift, these results are expected to be independent of the size of the disorder $\\lambda$. Hence one expects that if $\\lambda\\neq 0$, the Lyapunov exponent is positive and Anderson localization holds for all energies. Moreover, one expects no gaps in the spectrum (unlike in the one-frequency shift case, when the spectrum is a Cantor set) - see the comments at the end of Chapter 15 in . Some results on these very challenging problems have been obtained in , , , .\n\nLocalization results for these types of operators defined by skew-shift dynamics have applications to quantum chaos problems. More specifically, they imply existence of almost periodic solutions to the quantum kicked rotator equation. However, one has to establish (dynamical) localization for a more general, long range operator, one where the discrete Laplacian is replaced by a Toeplitz operator with fast off-diagonal decay of its monodromy matrix entries. This was already established for analytic potential functions (see Chapter 15 and 16 in ), but we will not address this problem for Gevrey potential functions in this paper.",
    "labels": [],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Summary of related results, general strategy"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L128-133::s8",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L142-147::s1",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L142-147::s1",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Summary of related results, general strategy",
    "start_line": 142,
    "end_line": 147,
    "text": "Localization results for these types of operators defined by skew-shift dynamics have applications to quantum chaos problems. More specifically, they imply existence of almost periodic solutions to the quantum kicked rotator equation. However, one has to establish (dynamical) localization for a more general, long range operator, one where the discrete Laplacian is replaced by a Toeplitz operator with fast off-diagonal decay of its monodromy matrix entries. This was already established for analytic potential functions (see Chapter 15 and 16 in ), but we will not address this problem for Gevrey potential functions in this paper.\n\nMost of the results on localization for discrete quasiperiodic Schrödinger operators (with either shift or skew-shift dynamics) have been obtained under the assumption that the potential function is the cosine function, or a trigonometric polynomial or a real analytic and non-constant function (see J. Bourgain’s monograph ).\n\nAssuming Gevrey regularity and a transversality condition, there are localization results for the shift model that closely resemble the ones in the analytic case (see , ). It should be noted, however, that they are usually perturbative and that more subtle results regarding fine continuity properties of the integrated density of states (as in , ) or the topological structure of the spectrum (as in ) are not available in this context.\n\nFor potential functions that are more general than Gevrey, namely $C^\\alpha$, the results available now (on localization and positivity of the Lyapunov exponent) require that a(n asymptotically small relative to the size $\\lambda$ of the disorder but) positive set of energies be excluded or that the potential function be replaced by some generic variations of itself (see , , ).",
    "labels": [],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Summary of related results, general strategy"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L134-141::s0",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L148-153::s2",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L148-153::s2",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Summary of related results, general strategy",
    "start_line": 148,
    "end_line": 153,
    "text": "For potential functions that are more general than Gevrey, namely $C^\\alpha$, the results available now (on localization and positivity of the Lyapunov exponent) require that a(n asymptotically small relative to the size $\\lambda$ of the disorder but) positive set of energies be excluded or that the potential function be replaced by some generic variations of itself (see , , ).\n\nTo prove Theorem <a href=\"#main\" data-reference-type=\"ref\" data-reference=\"main\">1</a> we will follow the same strategy used in for the single frequency shift model: at each scale, substitute the potential function by an appropriate polynomial approximation (see Section <a href=\"#approximation\" data-reference-type=\"ref\" data-reference=\"approximation\">3</a>). This in turn will allow the use of subharmonic functions techniques (see Section <a href=\"#averages\" data-reference-type=\"ref\" data-reference=\"averages\">4</a>) developed in , , . An additional challenge is describing the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> for multi-variable smooth functions in a quantitive way. We derive (see Section <a href=\"#lojasiewicz\" data-reference-type=\"ref\" data-reference=\"lojasiewicz\">5</a>) a Łojasiewicz type inequality for such functions, of the kind previously available for non-constant trigonometric polynomials (see , ) or analytic functions (see , ).\n\nThe main technical result of this paper, from which all statements in Theorem <a href=\"#main\" data-reference-type=\"ref\" data-reference=\"main\">1</a> follow, is a large deviation theorem (LDT) for logarithmic averages of transfer matrices (see Section <a href=\"#ldt_proofs\" data-reference-type=\"ref\" data-reference=\"ldt_proofs\">6</a>).\n\nAccording to (<a href=\"#ldt-ergod\" data-reference-type=\"ref\" data-reference=\"ldt-ergod\">[ldt-ergod]</a>), due to ergodicity, for a.e. $\\underline{x}\\in \\mathbb{T}^2$: $$\\frac{1}{N} \\log \\lVert M_{N}(\\underline{x}, E) \\rVert \\to L(E) \\ \\text{ as } N \\to \\infty$$",
    "labels": [],
    "refs": [
      "TC",
      "approximation",
      "averages",
      "ldt-ergod",
      "ldt_proofs",
      "lojasiewicz",
      "main"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Summary of related results, general strategy"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L142-147::s1",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L154-160::s3",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L33-52::s2",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L53-65::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L154-160::s3",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Summary of related results, general strategy",
    "start_line": 154,
    "end_line": 160,
    "text": "According to (<a href=\"#ldt-ergod\" data-reference-type=\"ref\" data-reference=\"ldt-ergod\">[ldt-ergod]</a>), due to ergodicity, for a.e. $\\underline{x}\\in \\mathbb{T}^2$: $$\\frac{1}{N} \\log \\lVert M_{N}(\\underline{x}, E) \\rVert \\to L(E) \\ \\text{ as } N \\to \\infty$$\n\nThe LDT provides a quantitative version of this convergence: $$\\label{ldt-idea}\n\\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2: \\bigl|  \\frac{1}{N} \\log \\lVert M_{N}(\\underline{x}, E) \\rVert- L_{N} (E)  \\bigr| > \\epsilon ] <  \\delta (N, \\epsilon)$$ where $\\epsilon = o (1)$ and $\\delta (N, \\epsilon) \\rightarrow 0$ as $N \\rightarrow \\infty$\n\nThe size of the deviation $\\epsilon$ and the measure of the exceptional set $\\delta (N, \\epsilon)$ are very important. The sharpest such estimate (see Theorem 7.1 in ), available for the single-frequency shift model with analytic potential, holds for any $\\epsilon >0$ and exponentially small measure $\\delta (N, \\epsilon) \\approx e^{-c \\delta N}$, thus morally matching the large deviation estimates for random variables that these deterministic quantities mimic here. Having such sharp estimates leads to a sharper modulus of continuity of the Lyapunov exponent (see ).\n\nFor the multi-frequency shift and the skew-shift models, even with analytic potentials, the available estimates are not as sharp. In this paper, for Gevrey potential functions, we will get $\\epsilon \\approx N^{-\\tau}$ and $\\delta \\approx e^{-N^\\sigma}$ for some absolute constants $\\tau, \\sigma \\in (0,1)$.",
    "labels": [
      "ldt-idea"
    ],
    "refs": [
      "ldt-ergod"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Summary of related results, general strategy"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L148-153::s2",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L33-52::s2",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L53-65::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L161-167::s4",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Summary of related results, general strategy",
    "start_line": 161,
    "end_line": 167,
    "text": "For the multi-frequency shift and the skew-shift models, even with analytic potentials, the available estimates are not as sharp. In this paper, for Gevrey potential functions, we will get $\\epsilon \\approx N^{-\\tau}$ and $\\delta \\approx e^{-N^\\sigma}$ for some absolute constants $\\tau, \\sigma \\in (0,1)$.\n\nFollowing the approach in , , a large deviation estimate like (<a href=\"#ldt-idea\" data-reference-type=\"ref\" data-reference=\"ldt-idea\">[ldt-idea]</a>) will allow us to obtain a lower (positive) bound and continuity of the Lyapunov exponent, once these properties are established at an initial scale $N_0$ for $L_{N_0} (E)$. It will also allow us (the reader will be refered to , for details) to establish estimates on the Green’s functions associated with the operator (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>), more specifically the fact that double resonances for Green’s functions occur with small probability, which leads to Anderson localization.\n\nMost of the paper will then be devoted to proving a LDT like (<a href=\"#ldt-idea\" data-reference-type=\"ref\" data-reference=\"ldt-idea\">[ldt-idea]</a>): $$\\label{ldt-strategy}\n\\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2: | \\frac{1}{N} \\log \\lVert M_{N}(\\underline{x}, E) \\rVert- L_{N} (E) | > N^{-\\tau} ] <  e^{-N^\\sigma}$$ through an inductive process on the scale $N$.\n\nThe *base step* of the inductive process for proving the LDT (<a href=\"#ldt-strategy\" data-reference-type=\"ref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a>) is based exclusively on the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> on the potential, and on choosing a sufficiently large disorder $\\lambda$. The latter is what makes this approach perturbative (and, in the case of the skew-shift model, wasteful, since it does not exploit the weakly-mixing properties of its dynamics). The former implies a Łojasiewicz type inequality, which we prove using a quantitative form of the implicit function theorem.",
    "labels": [
      "ldt-strategy"
    ],
    "refs": [
      "TC",
      "ldt-idea",
      "ldt-strategy",
      "op1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Summary of related results, general strategy"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L154-160::s3",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L168-171::s5",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L154-160::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1-17::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L168-171::s5",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L168-171::s5",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Summary of related results, general strategy",
    "start_line": 168,
    "end_line": 171,
    "text": "The *base step* of the inductive process for proving the LDT (<a href=\"#ldt-strategy\" data-reference-type=\"ref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a>) is based exclusively on the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> on the potential, and on choosing a sufficiently large disorder $\\lambda$. The latter is what makes this approach perturbative (and, in the case of the skew-shift model, wasteful, since it does not exploit the weakly-mixing properties of its dynamics). The former implies a Łojasiewicz type inequality, which we prove using a quantitative form of the implicit function theorem.\n\nIn the *inductive step* we use the regularity of the potential function $v (\\underline{x})$ and the arithmetic properties of the frequency. The regularity of $v (\\underline{x})$ allows us to approximate it efficiently by trigonometric polynomials $v_N (\\underline{x})$ at each scale $N,$ and to use these approximants in place of $v (\\underline{x})$ to get analytic substitutes $\\tilde{M_N} (\\underline{x})$ for the transfer matrices $M_N (\\underline{x})$. Their corresponding logarithmic averages will be subharmonic in each variable which will allow us to employ the subharmonic functions techniques developed in , , .\n\nThe main technical difficulty with this approach, and what restricts it to Gevrey (instead of say, $C^\\alpha$) potential functions, is that the holomorphic extensions of the transfer matrix substitutes $\\tilde{M_N} (\\underline{x})$ will have to be restricted to domains of size $\\approx N^{-\\delta}$ for some $\\delta > 0$. In other words, the estimates will not be uniform in $N$, and this decreasing width of the domain of holomorphicity will have to be overpowered. This will not be possible for a $C^\\alpha$ potential function because its trigonometric polynomial approximation is less efficient, so the width of holomorphicity in this case will decrease too fast (exponentially fast).",
    "labels": [],
    "refs": [
      "TC",
      "ldt-strategy"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Summary of related results, general strategy"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L172-183::s0",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L172-183::s0",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 172,
    "end_line": 183,
    "text": "#  Description of the approximation process\n\nLet $v \\in G^s (\\mathbb{T}^2)$ be a Gevrey potential function. Then $$\\label{fourierexp}\nv(\\underline{x}) = \\sum_{\\underline{l}\\in \\mathbb{Z}^2} \\hat{v} (\\underline{l}) e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$$ where for some constants $M, \\rho > 0,$ its Fourier coefficients have the decay: $$\\label{fouriercoef} \n\\bigl|   \\hat{v} (\\underline{l})  \\bigr| \\leq  M e^{- \\rho | \\underline{l}|^{1/s}}  \\ \\text{ for all } \\  \\underline{l}\\in \\mathbb{Z}^2$$\n\nWe will compare the logarithmic averages of the transfer matrix $$\\label{LNx}\nL_N (\\underline{x}, E) = \\frac{1}{N} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d\\underline{x}= \\frac{1}{N} \\, \\log \\lVert \\prod_{j=N}^{1}  \\Bigl[ \\begin{array}{ccc}\n\\lambda v ({\\rm T}^j \\, \\underline{x}) - E  &   - 1  \\\\\n1 &   0 \\\\  \\end{array} \\Bigr] \\rVert$$ with their means $$\\label{LN}\nL_{N} (E) = \\int_{\\mathbb{T}^2} L_N (\\underline{x}, E)  \\, d\\underline{x}$$",
    "labels": [
      "LN",
      "LNx",
      "fouriercoef",
      "fourierexp"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L168-171::s5",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L184-187::s1",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L184-187::s1",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L184-187::s1",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 184,
    "end_line": 187,
    "text": "We will compare the logarithmic averages of the transfer matrix $$\\label{LNx}\nL_N (\\underline{x}, E) = \\frac{1}{N} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d\\underline{x}= \\frac{1}{N} \\, \\log \\lVert \\prod_{j=N}^{1}  \\Bigl[ \\begin{array}{ccc}\n\\lambda v ({\\rm T}^j \\, \\underline{x}) - E  &   - 1  \\\\\n1 &   0 \\\\  \\end{array} \\Bigr] \\rVert$$ with their means $$\\label{LN}\nL_{N} (E) = \\int_{\\mathbb{T}^2} L_N (\\underline{x}, E)  \\, d\\underline{x}$$\n\nTo be able to use subharmonic functions techniques, we will have to approximate the potential function $v (\\underline{x})$ by trigonometric polynomials $v_N (\\underline{x})$ and substitute $v$ by $v_N$ into (<a href=\"#LNx\" data-reference-type=\"ref\" data-reference=\"LNx\">[LNx]</a>). At each scale $N$ we will have a different approximant $v_N$ chosen in such a way that the “transfer matrix substitute” would be close to the original transfer matrix. The approximant $v_N$ will then have to differ from $v$ by a very small error - (super)exponentially small in $N$. That, in turn, will make the degree deg $v_N =: \\tilde{N}$ of this polynomial very large - based on the rate of decay (<a href=\"#fcoef\" data-reference-type=\"ref\" data-reference=\"fcoef\">[fcoef]</a>) of the Fourier coefficients of $v$, $\\tilde{N}$ should be a power of $N$, dependent on the Gevrey class $s$.\n\nThe trigonometric polynomial $v_N (\\underline{x})$ has an extension $v_N (\\underline{z})$, $\\underline{z}= (z_1, z_2)$, which is separately holomorphic on the whole complex plane in each variable. We have to restrict $v_N (\\underline{z})$ in each variable to a narrow strip (or annulus, if we identify the torus $\\mathbb{T}$ with $\\mathbb{R}/\\mathbb{Z}$) of width $\\rho_N$, where $\\rho_N \\approx ( \\mbox{deg }v_N )^{- 1} \\approx \\tilde{N}^{-1} \\approx N^{- \\theta}$, for some power $\\theta > 0$. This is needed in order to get a uniform in $N$ bound on the extension $v_N (\\underline{z})$. Moreover, in the case of the skew-shift, this is also needed because its dynamics expands in the imaginary direction, and in this case, the width of holomorphicity in the second variable will have to be smaller than in the first by a factor of $\\approx \\frac{1}{N}$.",
    "labels": [
      "LN",
      "LNx"
    ],
    "refs": [
      "LNx",
      "fcoef"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L172-183::s0",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L188-201::s2",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L172-183::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L188-201::s2",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 188,
    "end_line": 201,
    "text": "The trigonometric polynomial $v_N (\\underline{x})$ has an extension $v_N (\\underline{z})$, $\\underline{z}= (z_1, z_2)$, which is separately holomorphic on the whole complex plane in each variable. We have to restrict $v_N (\\underline{z})$ in each variable to a narrow strip (or annulus, if we identify the torus $\\mathbb{T}$ with $\\mathbb{R}/\\mathbb{Z}$) of width $\\rho_N$, where $\\rho_N \\approx ( \\mbox{deg }v_N )^{- 1} \\approx \\tilde{N}^{-1} \\approx N^{- \\theta}$, for some power $\\theta > 0$. This is needed in order to get a uniform in $N$ bound on the extension $v_N (\\underline{z})$. Moreover, in the case of the skew-shift, this is also needed because its dynamics expands in the imaginary direction, and in this case, the width of holomorphicity in the second variable will have to be smaller than in the first by a factor of $\\approx \\frac{1}{N}$.\n\nThe fact that the “substitutes” $v_N (\\underline{x})$ have different, smaller and smaller widths of holomorphicity creates significant technical problems compared to the case when $v(\\underline{x})$ is a real analytic function. It also makes this approach fail when the rate of decay of the Fourier coefficients of the potential function $v (\\underline{x})$ is slower.\n\nTherefore, we have to find the optimal “error vs. degree” approximations of $v(\\underline{x})$ by trigonometric polynomials $v_N (\\underline{x})$. Here are the formal calculations.\n\nFor every positive integer $N$, consider the truncation $$\\label{trunc}\nv_N (\\underline{x}) := \\sum_{| \\underline{l}| \\leq \\tilde{N}} \\hat{v} (\\underline{l}) \\, e^{2 \\pi i \\, \\underline{l}\\cdot  \\underline{x}}$$ where $\\tilde{N} = \\mbox{deg } v_N$ will be determined later.\n\nSince $v_N (x_1, x_2)$ is in each variable a $1$-periodic, real analytic function on $\\mathbb{R}$, it can be extended to a separately in each variable $1$-periodic holomorphic function on $\\mathbb{C}$: $$\\label{holext} \nv_N (\\underline{z}) := \\sum_{\\left|  \\underline{l} \\right| \\leq \\tilde{N}} \\hat{v} (\\underline{l}) e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{z}}$$\n\nTo ensure the uniform boundedness in $N$ of $v_N (z_1, z_2)$ we have to restrict $v_N (z_1, z_2)$ to the annulus/strip $[ \\left|  \\Im z   \\right| < \\rho_{1,N} ] \\times [ \\left|  \\Im z   \\right| < \\rho_{1,N} ]$, where $$\\rho_{1,N} := \\frac{\\rho}{2} \\tilde{N}^{ - 1 + 1/s}$$\n\nIndeed, if $z_1 = x_1 + iy_1$, $z_1 = x_1 + iy_1$ and $\\left| y_1 \\right|, \\left| y_2 \\right| < \\rho_{1,N}$, then:",
    "labels": [
      "holext",
      "trunc"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L184-187::s1",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L202-239::s3",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L202-239::s3",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 202,
    "end_line": 239,
    "text": "Indeed, if $z_1 = x_1 + iy_1$, $z_1 = x_1 + iy_1$ and $\\left| y_1 \\right|, \\left| y_2 \\right| < \\rho_{1,N}$, then:\n\n$$\\begin{aligned}\n\\bigl|  v_N (z_1, z_2) \\bigr| = \\bigl|  \\sum_{| \\underline{l}| \\leq \\tilde{N}} \\hat{v} (\\underline{l}) e^{2 \\pi i \\, \\underline{l}\\cdot  \\underline{z}}  \\bigr|  \\le & \\, \n\\sum_{| \\underline{l}| \\leq \\tilde{N}} \\, \\bigl| \\hat{v} (\\underline{l})  \\bigr| e^{- 2 \\pi \\, \\underline{l}\\cdot \\underline{y}} \\\\\n \\leq M \\sum_{| \\underline{l}| \\leq \\tilde{N}} e^{- \\rho | \\underline{l}|^{1/s}}  e^{| l_1 | | y_1 | + |l_2| |y_2|}\n\\le & \\,\n M \\sum_{| \\underline{l}| \\leq \\tilde{N}} e^{- \\rho | \\underline{l}|^{1/s}}  e^{| \\underline{l}| \\, \\rho_{1,N}}   \\\\\n\\le M \\sum_{| \\underline{l}| \\leq \\tilde{N}}  e^{- \\rho | \\underline{l}|^{1/s}} \\cdot e^{| \\underline{l}| \\,  \\rho/2 \\, | \\underline{l}|^{- 1 + 1/s}}  = & \\, \nM \\sum_{| \\underline{l}| \\leq \\tilde{N}}  e^{- \\frac{\\rho}{2} | \\underline{l}|^{1/s}}   \\\\\n\\le M \\sum_{\\underline{l}\\in \\mathbb{Z}^2}  e^{- \\frac{\\rho}{2} | \\underline{l}|^{1/s}}  =: & \\, B < \\infty \n\\end{aligned}$$ where $B$ is a constant which depends on $v$ (not on the scale $N$) and we have used : $\\left| y_1 \\right|, \\left| y_2 \\right|  <  \\rho_{1, N} =  \\frac{\\rho}{2} \\tilde{N}^{- 1 + 1/s} \\leq  \\frac{\\rho}{2} | \\underline{l}|^{- 1 + 1/s}$ for $| \\underline{l}| \\leq \\tilde{N}$, since $s > 1$.\n\nWe also clearly have $| v (\\underline{x}) - v_N (\\underline{x})| \\lesssim e^{-\\rho \\tilde{N}^{1/s}}$ for all $\\underline{x}\\in \\mathbb{T}^2$.\n\nWe will need, as mentioned above, super-exponentially small error in how $v_N (\\underline{x})$ approximates $v (\\underline{x})$, otherwise the error would propagate and the transfer matrix substitutes will not be close to the original transfer matrices. Hence $\\tilde{N}$ should be chosen such that say $e^{-\\rho \\tilde{N}^{1/s}} \\leq e^{- \\rho N^{2}}.$ So if $\\tilde{N} := N^{2 s}$, then the width of the holomorphic (in each variable) extension $v_N (\\underline{z})$ will be $\\rho_{1,N}  = \\frac{\\rho}{2} N^{2  s  (- 1+ \\frac{1}{s})} =  \\frac{\\rho}{2}  N^{- 2 (s - 1)}\n=: \\frac{\\rho}{2} N^{- \\delta}$, where $\\delta := 2 \\, (s - 1) > 0$.\n\nWe conclude: for every integer $N \\geq 1$, we have a function $v_N (\\underline{x})$ on $\\mathbb{T}^2$ such that $$\\label{aproxtrunc} \n\\bigl|  v (\\underline{x}) - v_N (\\underline{x})  \\bigr| < e^{- \\rho N^2}$$ and $v_N (\\underline{x})$ has a $1$-periodic separately holomorphic extension $v_N (\\underline{z})$ to the strip $[ \\left|  \\Im z   \\right| < \\rho_{1,N} ] \\times [ \\left|  \\Im z   \\right| < \\rho_{1,N} ]$, where $\\rho_{1,N}  = \\frac{\\rho}{2} N^{- \\delta}$, for which $$\\label{boundv} \n\\bigl|  v_N (\\underline{z})  \\bigr| \\leq B$$ The positive constants $\\rho$, $B$, $\\delta$ above depend only on $v$ (not on the scale $N$). The constant $\\delta$ depends on the Gevrey class of $v$: $\\delta := 2 (s - 1)$ so it is fixed but presumably very large.\n\nWe now substitute these approximants $v_N (\\underline{x})$ for $v(\\underline{x})$ in the definition of the transfer matrix $M_N (\\underline{x})$.\n\nLet $$A(\\underline{x}, E)  \n :=  \\Bigl[ \\begin{array}{ccc}\n\\lambda v (\\underline{x}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$ be the cocycle that defines the transfer matrix $M_N (\\underline{x})$.\n\nConsider then $$\\tilde{A}_N (\\underline{x}, E) \n :=  \\Bigl[ \\begin{array}{ccc}\n\\lambda v_N (\\underline{x}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$ which leads to the transfer matrix substitutes $$\\tilde{M} _{N} (\\underline{x}, E)  := \\prod_{j=N}^{1} \\tilde{A}_N ({\\rm T}^{j} \\underline{x}, E)$$\n\nTo show that the substitutes are close to the original matrices, we use Trotter’s formula. This is a wasteful approach, and clearly in part responsible for our inability to apply these methods beyond Gevrey functions. There are other, much more subtle reasons for why this approach is limited to this class of functions.\n\n$$M_{N} (\\underline{x}) -  \\tilde{M}_{N} (\\underline{x})  =$$ $$= \\sum_{j=1}^{N} A ({\\rm T}^N \\underline{x}) \\ldots A ({\\rm T}^{j+1} \\underline{x}) \\,  [A ({\\rm T}^j \\underline{x}) - \\tilde{A}_{N}({\\rm T}^j \\underline{x})] \\,  \\tilde{A}_{N}(T^{j-1} \\underline{x}) \\ldots \\tilde{A}_{N} ({\\rm T}\\underline{x})$$ $$A ({\\rm T}^j \\underline{x}) - \\tilde{A}_{N}({\\rm T}^j \\underline{x}) = \\left[ \\begin{array}{cc}\n\\lambda v ({\\rm T}^j \\underline{x}) - \\lambda v_{N} ({\\rm T}^j \\underline{x})  &   0  \\\\\n0 &   0 \\\\  \\end{array} \\right ]$$ so $$\\lVert A ({\\rm T}^j \\underline{x}) - \\tilde{A}_{N}({\\rm T}^j \\underline{x}) \\rVert \\le \\left| \\lambda \\right| \\, \\sup_{\\underline{y}\\in \\mathbb{T}^2} \\bigl|  v (\\underline{y}) - v_N (\\underline{y})  \\bigr|  <   \\left| \\lambda \\right| \\, e^{-\\rho N^{2}}$$",
    "labels": [
      "aproxtrunc",
      "boundv"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L188-201::s2",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L240-257::s4",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L240-257::s4",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 240,
    "end_line": 257,
    "text": "$$\\begin{aligned}\n\\bigl|  v_N (z_1, z_2) \\bigr| = \\bigl|  \\sum_{| \\underline{l}| \\leq \\tilde{N}} \\hat{v} (\\underline{l}) e^{2 \\pi i \\, \\underline{l}\\cdot  \\underline{z}}  \\bigr|  \\le & \\, \n\\sum_{| \\underline{l}| \\leq \\tilde{N}} \\, \\bigl| \\hat{v} (\\underline{l})  \\bigr| e^{- 2 \\pi \\, \\underline{l}\\cdot \\underline{y}} \\\\\n \\leq M \\sum_{| \\underline{l}| \\leq \\tilde{N}} e^{- \\rho | \\underline{l}|^{1/s}}  e^{| l_1 | | y_1 | + |l_2| |y_2|}\n\\le & \\,\n M \\sum_{| \\underline{l}| \\leq \\tilde{N}} e^{- \\rho | \\underline{l}|^{1/s}}  e^{| \\underline{l}| \\, \\rho_{1,N}}   \\\\\n\\le M \\sum_{| \\underline{l}| \\leq \\tilde{N}}  e^{- \\rho | \\underline{l}|^{1/s}} \\cdot e^{| \\underline{l}| \\,  \\rho/2 \\, | \\underline{l}|^{- 1 + 1/s}}  = & \\, \nM \\sum_{| \\underline{l}| \\leq \\tilde{N}}  e^{- \\frac{\\rho}{2} | \\underline{l}|^{1/s}}   \\\\\n\\le M \\sum_{\\underline{l}\\in \\mathbb{Z}^2}  e^{- \\frac{\\rho}{2} | \\underline{l}|^{1/s}}  =: & \\, B < \\infty \n\\end{aligned}$$ where $B$ is a constant which depends on $v$ (not on the scale $N$) and we have used : $\\left| y_1 \\right|, \\left| y_2 \\right|  <  \\rho_{1, N} =  \\frac{\\rho}{2} \\tilde{N}^{- 1 + 1/s} \\leq  \\frac{\\rho}{2} | \\underline{l}|^{- 1 + 1/s}$ for $| \\underline{l}| \\leq \\tilde{N}$, since $s > 1$.\n\nWe also clearly have $| v (\\underline{x}) - v_N (\\underline{x})| \\lesssim e^{-\\rho \\tilde{N}^{1/s}}$ for all $\\underline{x}\\in \\mathbb{T}^2$.\n\nWe will need, as mentioned above, super-exponentially small error in how $v_N (\\underline{x})$ approximates $v (\\underline{x})$, otherwise the error would propagate and the transfer matrix substitutes will not be close to the original transfer matrices. Hence $\\tilde{N}$ should be chosen such that say $e^{-\\rho \\tilde{N}^{1/s}} \\leq e^{- \\rho N^{2}}.$ So if $\\tilde{N} := N^{2 s}$, then the width of the holomorphic (in each variable) extension $v_N (\\underline{z})$ will be $\\rho_{1,N}  = \\frac{\\rho}{2} N^{2  s  (- 1+ \\frac{1}{s})} =  \\frac{\\rho}{2}  N^{- 2 (s - 1)}\n=: \\frac{\\rho}{2} N^{- \\delta}$, where $\\delta := 2 \\, (s - 1) > 0$.\n\nWe conclude: for every integer $N \\geq 1$, we have a function $v_N (\\underline{x})$ on $\\mathbb{T}^2$ such that $$\\label{aproxtrunc} \n\\bigl|  v (\\underline{x}) - v_N (\\underline{x})  \\bigr| < e^{- \\rho N^2}$$ and $v_N (\\underline{x})$ has a $1$-periodic separately holomorphic extension $v_N (\\underline{z})$ to the strip $[ \\left|  \\Im z   \\right| < \\rho_{1,N} ] \\times [ \\left|  \\Im z   \\right| < \\rho_{1,N} ]$, where $\\rho_{1,N}  = \\frac{\\rho}{2} N^{- \\delta}$, for which $$\\label{boundv} \n\\bigl|  v_N (\\underline{z})  \\bigr| \\leq B$$ The positive constants $\\rho$, $B$, $\\delta$ above depend only on $v$ (not on the scale $N$). The constant $\\delta$ depends on the Gevrey class of $v$: $\\delta := 2 (s - 1)$ so it is fixed but presumably very large.\n\nWe now substitute these approximants $v_N (\\underline{x})$ for $v(\\underline{x})$ in the definition of the transfer matrix $M_N (\\underline{x})$.\n\nLet $$A(\\underline{x}, E)  \n :=  \\Bigl[ \\begin{array}{ccc}\n\\lambda v (\\underline{x}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$ be the cocycle that defines the transfer matrix $M_N (\\underline{x})$.\n\nConsider then $$\\tilde{A}_N (\\underline{x}, E) \n :=  \\Bigl[ \\begin{array}{ccc}\n\\lambda v_N (\\underline{x}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$ which leads to the transfer matrix substitutes $$\\tilde{M} _{N} (\\underline{x}, E)  := \\prod_{j=N}^{1} \\tilde{A}_N ({\\rm T}^{j} \\underline{x}, E)$$\n\nTo show that the substitutes are close to the original matrices, we use Trotter’s formula. This is a wasteful approach, and clearly in part responsible for our inability to apply these methods beyond Gevrey functions. There are other, much more subtle reasons for why this approach is limited to this class of functions.\n\n$$M_{N} (\\underline{x}) -  \\tilde{M}_{N} (\\underline{x})  =$$ $$= \\sum_{j=1}^{N} A ({\\rm T}^N \\underline{x}) \\ldots A ({\\rm T}^{j+1} \\underline{x}) \\,  [A ({\\rm T}^j \\underline{x}) - \\tilde{A}_{N}({\\rm T}^j \\underline{x})] \\,  \\tilde{A}_{N}(T^{j-1} \\underline{x}) \\ldots \\tilde{A}_{N} ({\\rm T}\\underline{x})$$ $$A ({\\rm T}^j \\underline{x}) - \\tilde{A}_{N}({\\rm T}^j \\underline{x}) = \\left[ \\begin{array}{cc}\n\\lambda v ({\\rm T}^j \\underline{x}) - \\lambda v_{N} ({\\rm T}^j \\underline{x})  &   0  \\\\\n0 &   0 \\\\  \\end{array} \\right ]$$ so $$\\lVert A ({\\rm T}^j \\underline{x}) - \\tilde{A}_{N}({\\rm T}^j \\underline{x}) \\rVert \\le \\left| \\lambda \\right| \\, \\sup_{\\underline{y}\\in \\mathbb{T}^2} \\bigl|  v (\\underline{y}) - v_N (\\underline{y})  \\bigr|  <   \\left| \\lambda \\right| \\, e^{-\\rho N^{2}}$$\n\nSince $\\sup_{\\underline{x}\\in \\mathbb{T}^2} | v (\\underline{x}) | \\leq B$, the spectrum of the operator $H (\\underline{x})$ is contained in the interval $[ -2 - \\left| \\lambda \\right| \\, B,  2 + \\left| \\lambda \\right| \\, B \\, ]$. Hence it is enough to consider only the energies $E$ such that $|E| \\leq 2 + |\\lambda| \\, B$. We then have:\n\n$$\\lVert A ({\\rm T}^j \\underline{x}) \\rVert  = \\Bigl\\|   \\Bigl[ \\begin{array}{cc}\n\\lambda v ({\\rm T}^j \\underline{x}) - E  & - 1  \\\\\n1 & 0 \\\\  \\end{array} \\Bigr] \\Bigr\\|  \\le  \\left| \\lambda \\right| \\, B  + \\bigl| E \\bigr| + 2  \\le  2 \\left| \\lambda \\right|  B + 4  \\le  e^{S(\\lambda)}$$\n\nand\n\n$$\\lVert \\tilde{A}_{N} ({\\rm T}^j \\underline{x}) \\rVert  \\le  \\Bigl\\|   \\Bigl[ \\begin{array}{cc}\n\\lambda v_{N} ({\\rm T}^j \\underline{x}) - E  & - 1 \\\\\n1 & 0 \\\\  \\end{array} \\Bigr] \\Bigr\\|  \\le \\left| \\lambda \\right|  \\, B + \\bigl| E \\bigr| + 2  \\leq e^{S(\\lambda)}$$\n\nTherefore, $$\\label{boundA}\n \\lVert A ({\\rm T}^j \\underline{x}) \\rVert, \\, \\lVert \\tilde{A}_{N} ({\\rm T}^j \\underline{x}) \\rVert   \\leq  e^{S(\\lambda)}$$ where $S(\\lambda) \\approx \\log \\left| \\lambda \\right|$ is a scaling factor that depends only on the (assumed large) disorder $\\lambda$ and on $v$ (the constants inherent in $\\approx$ depend on the number $B = B(v)$ which also determines the range of spectral values $E$).\n\nWe then have: $$\\lVert M_{N} (\\underline{x}, E) - \\tilde{M}_{N} (\\underline{x}, E) \\rVert  \\le  \\sum_{j=1}^{N} e^{S(\\lambda)} \n\\ldots  e^{S(\\lambda)} \\,  | \\lambda| \\, e^{-\\rho N^2}  e^{S(\\lambda)} \\ldots  e^{S(\\lambda)} \\leq$$ $$\\leq e^{N S(\\lambda) - \\rho N^2}  \\leq  e^{-\\frac{\\rho}{2}N^2}$$ provided $N \\gtrsim S(\\lambda)$.",
    "labels": [
      "aproxtrunc",
      "boundA",
      "boundv"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L202-239::s3",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L258-265::s5",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L258-265::s5",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 258,
    "end_line": 265,
    "text": "We then have: $$\\lVert M_{N} (\\underline{x}, E) - \\tilde{M}_{N} (\\underline{x}, E) \\rVert  \\le  \\sum_{j=1}^{N} e^{S(\\lambda)} \n\\ldots  e^{S(\\lambda)} \\,  | \\lambda| \\, e^{-\\rho N^2}  e^{S(\\lambda)} \\ldots  e^{S(\\lambda)} \\leq$$ $$\\leq e^{N S(\\lambda) - \\rho N^2}  \\leq  e^{-\\frac{\\rho}{2}N^2}$$ provided $N \\gtrsim S(\\lambda)$.\n\nHence uniformly in $\\underline{x}\\in \\mathbb{T}^2$ we get: $$\\label{tmclose}\n \\lVert  M_{N} (\\underline{x}, E) - \\tilde{M}_{N} (\\underline{x}, E) \\rVert \\le e^{-\\frac{\\rho}{2}N^2}$$ provided we choose $$\\label{n>b(la)}\nN \\gtrsim S(\\lambda)$$ which means roughly that $\\lambda$ has to be at most exponential in the scale $N$.\n\nWe are now going to turn our attention to the logarithmic averages of the transfer matrices.\n\nSince $\\det M_N (\\underline{x}) = 1$ and $\\det \\tilde{M}_N (\\underline{x}) = 1$, we have that $\\lVert M_N (\\underline{x}) \\rVert \\ge  1$ and $\\lVert \\tilde{M}_N (\\underline{x}) \\rVert \\ge  1$. Thus, for all $N \\gtrsim S(\\lambda)$ and for every $\\underline{x}\\in \\mathbb{T}^2$,",
    "labels": [
      "n>b(la)",
      "tmclose"
    ],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L240-257::s4",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L266-567::s6",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 266,
    "end_line": 567,
    "text": "Since $\\det M_N (\\underline{x}) = 1$ and $\\det \\tilde{M}_N (\\underline{x}) = 1$, we have that $\\lVert M_N (\\underline{x}) \\rVert \\ge  1$ and $\\lVert \\tilde{M}_N (\\underline{x}) \\rVert \\ge  1$. Thus, for all $N \\gtrsim S(\\lambda)$ and for every $\\underline{x}\\in \\mathbb{T}^2$,\n\n$$\\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert  -  \\frac{1}{N} \\log \\lVert \\tilde{M}_{N} (\\underline{x}) \\rVert  \\bigr|  \\le  \\frac{1}{N} \\lVert M_{N} (\\underline{x})  - \\tilde{M} _{N} (\\underline{x}) \\rVert  < e^{-\\frac{\\rho}{2}N^2}$$\n\nRecall the following notation: $$\\label{LNxE}\nL_N (\\underline{x}, E) = \\frac{1}{N} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d\\underline{x}$$ and define its substitute: $$\\label{shN}\nu_{N} (\\underline{x}, E)  := \\frac{1}{N} \\log || \\tilde{M}_{N} (\\underline{x}) ||$$\n\nTherefore, uniformly in $\\underline{x}\\in \\mathbb{T}^2$ and in the energy $E$: $$\\bigl|  L_N (\\underline{x}, E)  - u_{N} (\\underline{x}, E)  \\bigr|  < e^{-\\frac{\\rho}{2}N^2}$$ and by averaging in $\\underline{x}$: $$\\bigl|  L_N (E) - \\left< u_N (E) \\right>  \\bigr|  < e^{-\\frac{\\rho}{2}N^2}$$ where $L_{N} (E) := \\int_{\\mathbb{T}^2} L_N (\\underline{x}, E)  \\, d\\underline{x}$ and for any function $u (\\underline{x})$, $\\ \\left< u \\right> := \\int_{\\mathbb{T}^2} u (\\underline{x}) \\, d \\underline{x}$.\n\nThe advantage of the substitutes $u_{N} (\\underline{x})$ is that they extend to pluri-subharmonic functions in a neighborhood of the torus $\\mathbb{T}^2$, as explained below.\n\nFor the skew-shift transformation ${\\rm T}= {\\rm S}_\\omega$ we consider the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N} := [ \\left|  \\Im z   \\right| < \\rho_{1,N} ] \\times [ \\left|  \\Im z   \\right| < \\rho_{2,N} ]$ where $\\rho_{1,N} = \\frac{\\rho}{4}N^{- \\delta}$ and $\\rho_{2,N} := \\frac{\\rho_{1,N}}{2 N}  = \\frac{\\rho}{4}N^{- \\delta -1}$\n\nWe have to reduce the size of the strip in the second variable to account for the fact that the skew-shift expands in the imaginary direction. Our approximation method required a reduction in the size of the holomorphicity strip at each scale, and this additional reduction will be comparatively harmless.\n\nIf we extend the map ${\\rm S}_\\omega$ from $\\mathbb{T}^2 = (\\mathbb{R}/\\mathbb{Z})^2$ to $\\mathbb{C}^2$, by $$\\displaystyle {\\rm S}_\\omega(z_1, z_2)= (z_1+z_2, z_2 + \\omega)$$ we get as in (<a href=\"#skewn\" data-reference-type=\"ref\" data-reference=\"skewn\">[skewn]</a>) that $$\\displaystyle \n{\\rm S}_\\omega^n (z_1, z_2)= (z_1 + n z_2 + \\frac{n (n-1)}{2} \\omega, z_2 + n \\omega)$$\n\nThen if $(z_1, z_2)\\in  \\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ and if we perform $n \\leq N$ iterations, we have: $$\\label{goodstrip}\n\\bigl|   \\Im (z_1 + n z_2 + \\frac{n (n-1)}{2} \\omega)  \\bigr| = \\bigl|  \\Im (z_1 + n z_2)  \\bigr| = \\left|  y_1 + n y_2  \\right| < \\frac{\\rho}{2}N^{-\\delta}$$\n\nThe matrix function $$\\displaystyle  \\tilde{A}_N (\\underline{x}) =  \\Bigl[ \\begin{array}{ccc}\n\\lambda v_N (\\underline{x}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$ extends to a $1$-periodic, separately in each variable holomorphic matrix valued function: $$\\tilde{A}_N (\\underline{z}) \n :=  \\Bigl[ \\begin{array}{ccc}\n\\lambda v_N (\\underline{z}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$\n\nUsing <a href=\"#boundv\" data-reference-type=\"eqref\" data-reference=\"boundv\">[boundv]</a> and the definition of the scaling factor $S (\\lambda)$, we have that on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ the matrix valued function $\\tilde{A}_N (\\underline{z})$ is uniformly in $N$ bounded by $e^{S(\\lambda)}$. Combining this with (<a href=\"#goodstrip\" data-reference-type=\"ref\" data-reference=\"goodstrip\">[goodstrip]</a>), the transfer matrix substitutes extend on the same strip to separately holomorphic matrix valued functions $$\\tilde{M} _{N} (\\underline{z}, E)  := \\prod_{j=N}^{1} \\tilde{A}_N ({\\rm S}_\\omega^{j} \\, \\underline{z}, E)$$ such that, for all $\\underline{z}\\in \\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ and for all energies $E$ we have $$\\lVert \\tilde{M} _{N} (\\underline{z}, E)  \\rVert \\le e^{N S(\\lambda)}$$\n\nTherefore, $$u_{N} (\\underline{z})  := \\frac{1}{N} \\log \\lVert \\tilde{M}_{N} (\\underline{z}) \\rVert$$ is a pluri-subharmonic function on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$, and for any $\\underline{z}$ in this strip, $$\\left|  u_N (\\underline{z})  \\right|  \\le  S(\\lambda)$$\n\nThe same argument applies to the multifrequency shift ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$. The extension of this dynamics to the complex plane $${\\rm T}_{\\underline{\\omega}}(z_1, z_2)= (z_1 +  \\omega_1, z_2 +  \\omega_2)$$ does not expand in the imaginary direction, so there is no need to decrease the width of the strip in the second variable as in the case of the skew-shift. However, for convenience of notations, we will choose the same strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ for both transformations.\n\nWe can now summarize all of the above into the following.\n\n<div id=\"lemma1\" class=\"lemma\">\n\n**Lemma 1**. *For fixed parameters $\\lambda, E$, for a fixed transformation ${\\rm T}= {\\rm S}_\\omega$ or ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$ and for $\\delta = 2 (s-1)$, at every scale $N$ we have a $1$-periodic function $$u_{N} (\\underline{x})  := \\frac{1}{N} \\log \\lVert \\tilde{M}_{N} (\\underline{x}) \\rVert$$ which extends to a pluri-subharmonic function $u_N (\\underline{z})$ on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N} =  [ \\left| \\Im z \\right| < \\rho_{1, N} ]  \\times [ \\left| \\Im z \\right| < \\rho_{2, N} ]$, where $\\rho_{1,N}  \\approx  N^{- \\delta}$, $\\rho_{2,N}  \\approx  N^{- \\delta-1}$ so that $$\\label{boundu}\n\\left|  u_N (\\underline{z})  \\right|  \\le  S(\\lambda) \\quad \\text{ for all } \\quad  \n\\underline{z}\\in  \\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$$*\n\n*Note that the bound (<a href=\"#boundu\" data-reference-type=\"ref\" data-reference=\"boundu\">[boundu]</a>) is uniform in $N$.*\n\n*Moreover, if $N \\gtrsim  S(\\lambda)$, then the logarithmic averages of the transfer matrices $M_N (\\underline{x})$ are well approximated by their substitutes $u_N (\\underline{x})$: $$\\label{aproxu}  \n\\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert  -  u_N (\\underline{x})  \\bigr| \\lesssim e^{- N^2}$$ $$\\label{aprox<u>} \n\\bigl|  L_N -  \\left< u_N \\right>  \\bigr|  \\lesssim e^{- N^2}$$*\n\n</div>\n\nAll the inherent constants in the above (and future) estimates are either universal or depend only on $v$ (and not on the scale $N$) so they can be ignored. The estimates above are independent of the variable $\\underline{x}$, the parameters $\\lambda, E$ and the transformation ${\\rm T}$.\n\nThis s a crucial technical result in our paper, which will allow us to use subharmonic functions techniques as in , for the functions $u_N$, and then transfer the relevant estimates to the rougher functions they substitute.\n\nThe logarithmic averages of the transfer matrix have an almost invariance (under the dynamics) property:\n\n<div id=\"inv\" class=\"lemma\">\n\n**Lemma 2**. *For all $\\underline{x}\\in \\mathbb{T}^2,$ for all parameters $\\lambda, E$ and for all transformations ${\\rm T}$ we have : $$\\label{mshift} \n\\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert -  \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}\\, \\underline{x}) \\rVert \\,  \\bigr| \\lesssim  \\frac{S(\\lambda)}{N}$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* $$\\begin{aligned}\n \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert -  \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}\\, \\underline{x}) \\rVert \\,  \\bigr|  = \\bigl|  \\frac{1}{N} \\log \\frac{\\lVert M_{N} (\\underline{x}) \\rVert}{\\lVert M_{N} ({\\rm T}\\, \\underline{x}) \\rVert}  \\,  \\bigr| \\\\\n = \\bigl|  \\frac{1}{N} \\log \n\\frac{\\lVert A ({\\rm T}^N \\underline{x}) \\cdot \\ldots \\cdot A ({\\rm T}^2 \\underline{x}) \\cdot  A ({\\rm T}\\, \\underline{x}) \\rVert }\n{\\lVert A ( {\\rm T}^{N + 1} \\underline{x}) \\cdot  A ({\\rm T}^N \\underline{x}) \\cdot \\ldots \\cdot A ({\\rm T}^2 \\underline{x}) \\rVert } \\,  \\bigr|  \\\\\n \\le \\frac{1}{N} \\log [ \\, \n \\lVert ( A({\\rm T}^{N + 1} \\underline{x}) )^{- 1} \\rVert \\cdot  \\lVert A ({\\rm T}\\, \\underline{x}) \\rVert \\, ] \n  \\lesssim \\frac{S (\\lambda)}{N} \n\\end{aligned}$$ where the last bound is due to (<a href=\"#boundA\" data-reference-type=\"ref\" data-reference=\"boundA\">[boundA]</a>). The inequality (<a href=\"#mshift\" data-reference-type=\"ref\" data-reference=\"mshift\">[mshift]</a>) then follows. ◻\n\n</div>\n\n# Averages of shifts of pluri-subharmonic functions\n\nOne of the main ingredients in the proof of the LDT <a href=\"#ldt-strategy\" data-reference-type=\"eqref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a> is an estimate on averages of shifts of pluri-subharmonic functions. These averages are shown to converge in a quantitative way to the mean of the function. The result holds for both the skew-shift and the multi-frequency shift.\n\nFor the skew-shift, the result was proven in (see Lemma 2.6 there). We will reproduce here the scaled version of that result, the one that takes into account the size of the domain of subharmonicity and the sup norm of the function. The reader can verify, by following the details of the proof in , that this is indeed the correct scaled version. For the multi-frequency shift, the result is essentially contained within the proof of Theorem 5.5 in , but for completeness, we will include here the details of its proof.\n\n<div id=\"avshifts\" class=\"proposition\">\n\n**Proposition 1**. *Let $u (\\underline{x})$ be a real valued function on $\\mathbb{T}^2$, that extends to a pluri-subharmonic function $u (\\underline{z})$ on a strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}} = [ \\left|  \\Im z_1  \\right| < \\rho_1 ] \\times   [ \\left|  \\Im z_2  \\right| < \\rho_2 ]$. Let $\\rho = \\min \\{\\rho_1, \\rho_2 \\}$. Let ${\\rm T}$ be either the skew-shift or the multi-frequency shift on $\\mathbb{T}^2$, where the underlying frequency satisfies the $DC_\\kappa$ described in <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a> or <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> respectively. Assume that $$\\sup_{\\underline{z}\\in \\underline{\\mathcal{A}}_{\\underline{\\rho}}} \\, | u (\\underline{z}) | \\leq S$$ Then for some explicit constants $\\sigma_0, \\tau_0 > 0$, and for $n \\geq n (\\kappa)$ we have: $$\\label{shiftldt} \n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u ({\\rm T}^j \\underline{x})  \\, -  \\left< u \\right>    \\bigr| > \\frac{S}{\\rho} \\, n^{- \\tau_0} ] < \ne^{- n^{\\sigma_0}}$$*\n\n</div>\n\nHere is how this estimate can be understood. Given the ergodicity of the transformation ${\\rm T}$ for irrational (or rationally independent) frequencies, on the long run, the orbits ${\\rm T}^j \\underline{x}$ of most points $\\underline{x}$ will tend to be fairly well distributed throughout the torus $\\mathbb{T}^2$ (see the picture below).\n\nThe average $\\ \\frac{1}{n} \\sum_{j = 0}^{n-1}  u ({\\rm T}^j \\underline{x})$ will then resemble a Riemann sum of the function $u (\\underline{x})$ and as such, it will approach the integral $\\left< u \\right>$.\n\nMoreover, a quantitative description of the irrationality (or rational independence) of the frequency in the form of a Diophantine condition like <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a>, <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a>, should lead to a quantitative description of the convergence of the average sum to the integral $\\left< u \\right>$.\n\nTo prove this quantitative convergence result, we consider the Fourier expansion of the function $u (\\underline{x})$ and apply it to the average sums. This leads to a convolution of $u (\\underline{x})$ with a Fejér-type kernel. It is crucial to have estimates on the Fourier coefficients of the function $u$, and they are obtained via Riesz’ representation theorem for subharmonic functions (see Corollary 4.1. in ). Since $u (z_1, z_2)$ is pluri-subharmonic, the scaled version of Corollary 4.1. in implies: $$\\label{Riesz} \n\\sup_{x_2 \\in \\mathbb{T}} \\, \\bigl| \\hat{u} (l_1, x_2) \\bigr|  \\lesssim\\frac{S}{\\rho_1} \\cdot \\frac{1}{\\left| l_1 \\right|}  \\ \\text{ and  } \\ \n\\sup_{x_1 \\in \\mathbb{T}} \\, \\bigl| \\hat{u} (x_1, l_2) \\bigr|  \\lesssim\\frac{S}{\\rho_2} \\cdot \\frac{1}{\\left| l_2 \\right|}$$\n\nThe estimates (<a href=\"#Riesz\" data-reference-type=\"ref\" data-reference=\"Riesz\">[Riesz]</a>) imply (small) upper bounds on the $L^2$ - norm of the part of the Fourier expansion for which at least one of the indices $l_1$ and $l_2$ is large. The difficult part is when both indices $l_1$ and $l_2$ are small, in which case we use the Diophantine condition on the frequency to estimate the resulting exponential sums.\n\nIn the case of the skew shift dynamics <a href=\"#skewn\" data-reference-type=\"eqref\" data-reference=\"skewn\">[skewn]</a>, the resulting exponential sums are quadratic, and they are estimated using Weyl’s method (see for the details of the proof). We will now present the details of the proof for the multi-frequency shift case ${\\rm T}\\, \\underline{x}= {\\rm T}_{\\underline{\\omega}} \\, \\underline{x}:= \\underline{x}+ \\underline{\\omega}$.\n\n<div class=\"proof\">\n\n*Proof.* Expand $u (\\underline{x})$ into a Fourier series $$u (\\underline{x}) = \\left< u \\right> + \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\hat{u} (\\underline{l}) \\cdot e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$$ Then the averages of shifts have the form $$\\begin{aligned}\n\\frac{1}{n} \\sum_{j = 0}^{n-1}  u ({\\rm T}^j \\underline{x})  \\ = \\ & \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega}) \\\\\n= \\ & \\left< u \\right> +  \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\hat{u} (\\underline{l}) \\cdot e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}} \\cdot \\Bigl( \\frac{1}{n} \\sum_{j = 0}^{n-1}  e^{2 \\pi i \\, j \\, \\underline{l}\\cdot \\underline{\\omega}} \\Bigr )\\\\\n= \\ & \\left< u \\right> +  \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\hat{u} (\\underline{l}) \\cdot e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}} \\cdot  K_n (\\underline{l}\\cdot \\underline{\\omega})\n\\end{aligned}$$ where we denoted by $K_n (t)$ the Fejér kernel $$K_n (t) = \\frac{1}{n} \\sum_{j = 0}^{n-1}  e^{2 \\pi i \\, j t} \\, = \\, \\frac{1}{n} \\, \\frac{1 - e^{2 \\pi i \\, n t}}{1 - e^{2 \\pi i \\, t}}$$ which clearly has the bound $$\\label{fejerkernelbound}\n\\bigl| K_n (t) \\bigr| \\le \\min \\Bigl\\{ 1, \\frac{1}{n \\lVert t\\rVert} \\Bigr\\}$$ We then have: $$\\begin{aligned}\n\\Bigl\\|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega}) - \\left< u \\right> \\Bigr\\|_{L^2(\\mathbb{T}^2)}^2 \\  = \\ &\n \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2\\\\\n =  \\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2 \\  + \\ &\n  \\sum_{\\left| \\underline{l} \\right| \\ge K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2\n\\end{aligned}$$ We will estimate the second sum above using the bounds <a href=\"#Riesz\" data-reference-type=\"eqref\" data-reference=\"Riesz\">[Riesz]</a> on the Fourier coefficients of $u (\\underline{x})$ and the first sum using the DC <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> on the frequency $\\underline{\\omega}$. The splitting point $K$ will be chosen to optimize the sum of these estimates.\n\nClearly <a href=\"#Riesz\" data-reference-type=\"eqref\" data-reference=\"Riesz\">[Riesz]</a> implies: $$\\sum_{l_2 \\in \\mathbb{Z}} \\, \\bigl| \\hat{u} (l_1, l_2) \\bigr|^2 = \\Bigl\\| \\hat{u} (l_1, x_2)\\Bigr\\|_{L_{x_2}^2(\\mathbb{T})}^2 \\lesssim\\, \\Bigr( \\frac{S}{\\rho_1} \\, \\frac{1}{\\left| l_1 \\right|}\\Bigl)^2 \\le  \\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\frac{1}{\\left| l_1 \\right|^2}$$ and $$\\sum_{l_1 \\in \\mathbb{Z}} \\, \\bigl| \\hat{u} (l_1, l_2) \\bigr|^2 = \\Bigl\\| \\hat{u} (x_1, l_2)\\Bigr\\|_{L_{x_1}^2(\\mathbb{T})}^2 \\lesssim\\, \\Bigr( \\frac{S}{\\rho_2} \\, \\frac{1}{\\left| l_2 \\right|}\\Bigl)^2 \\le  \\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\frac{1}{\\left| l_2 \\right|^2}$$\n\nThen we have: $$\\begin{aligned}\n \\sum_{\\left| \\underline{l} \\right| \\ge K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2   \\le \\sum_{\\left| \\underline{l} \\right| \\ge K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\\\\n   \\le  \\sum_{\\underline{l}\\colon \\left| l_1 \\right| \\ge K/2} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2  +    \\sum_{\\underline{l}\\colon \\left| l_2 \\right| \\ge K/2}  \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \n \\lesssim\\,  \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\frac{1}{K}\n\\end{aligned}$$\n\nEstimate <a href=\"#Riesz\" data-reference-type=\"eqref\" data-reference=\"Riesz\">[Riesz]</a> clearly impies: $$\\bigl| \\hat{u} (\\underline{l}) \\bigr| \\lesssim\\frac{S}{\\rho} \\, \\frac{1}{\\left| \\underline{l} \\right|}$$ Then using the DC <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> on $\\underline{\\omega}$ and <a href=\"#fejerkernelbound\" data-reference-type=\"eqref\" data-reference=\"fejerkernelbound\">[fejerkernelbound]</a>, we obtain: $$\\begin{aligned}\n\\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2 \\le \n\\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\,\\frac{1}{\\left| \\underline{l} \\right|^2} \\cdot \\frac{1}{n^2 \\, \\lVert\\underline{l}\\cdot \\underline{\\omega}\\rVert^2} \\\\\n\\le \\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\,\\frac{1}{\\left| \\underline{l} \\right|^2} \\cdot \\frac{\\left| \\underline{l} \\right|^{2 A}}{n^2 \\, \\kappa^2}\n\\lesssim\\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\,  \\frac{K^{2 A}}{n^2 \\kappa^2}\n\\end{aligned}$$\n\nWe conclude: $$\\Bigl\\|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega}) - \\left< u \\right> \\Bigr\\|_{L^2(\\mathbb{T}^2)} \\ \\le \\ \\frac{S}{\\rho} \\Bigr( \\frac{1}{K^{1/2}} + \\frac{K^A}{n \\kappa} \\Bigl) \\le \\frac{S}{\\rho} n^{- a}$$ for some positive constant $a$ that depends on $A$ and for $n$ large enough depending on $A$ and $\\kappa$.\n\nUsing Chebyshev’s inequality, the above estimate implies: $$\\label{apriori-avshifts}\n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega})  \\, -  \\left< u \\right>  \\bigr|  > \\frac{S}{\\rho} \\, n^{- a/3} ] \\ < \\  \n n^{-4 a/3}$$\n\nThis is not exactly what we wanted, since the size of the “bad” set above decays only polynomially fast in $n$, instead of exponentially fast.\n\nTo boost this estimate, we will use Lemma 4.12 in J. Bourgain’s monograph . This result shows that a weaker a-priori estimate on a subharmonic function implies an upper bound on its BMO norm, which in turn leads, via John-Nirenberg inequality, to a stronger estimate on the function. We reproduce here a “rescaled” version of the estimate in , one that takes into account the width $\\rho$ of subharmonicity. The reader may verify that this is indeed the correct rescaled version of the statement.\n\n<div id=\"boost\" class=\"lemma\">\n\n**Lemma 3**. *Assume that $u = u (\\underline{x}) \\colon \\mathbb{T}^2 \\to \\mathbb{R}$ has a pluri-subharmonic extension $u (\\underline{z})$ on $\\underline{\\mathcal{A}}_{\\underline{\\rho}} = [ \\left|  \\Im z_1  \\right| < \\rho_1 ] \\times   [ \\left|  \\Im z_2  \\right| < \\rho_2 ]$ such that $\\displaystyle \\sup_{\\underline{z}\\in \\underline{\\mathcal{A}}_{\\underline{\\rho}}} \\, \\bigl|  u (\\underline{z})  \\bigr| \\le B$. Let $\\rho = \\min \\{\\rho_1, \\rho_2 \\}$. If $$\\label{weak}\n \\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|  u (\\underline{x}) - \\left< u \\right>  \\bigr|  > \\epsilon _0 ] < \\epsilon _1$$ then for an absolute constant $c > 0$, $$\\label{strong}\n \\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|   u (\\underline{x}) - \\left< u \\right>  \\bigr| > {\\epsilon _0}^{1/4} ] \n < e^{- c \\bigl(  {\\epsilon _0}^{1/4} + \\sqrt{\\frac{B}{\\rho}}  \\;   \\frac{{\\epsilon_1}^{1/4}} {{\\epsilon_0}^{1/2}}    \\bigr)^{- 1}}$$*\n\n</div>\n\nWe will apply this result to the average $$u^\\sharp (\\underline{x}) := \\frac{\\rho}{S} \\,  \\frac{1}{n}\\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega})$$\n\nClearly $u^\\sharp (\\underline{x})$ is pluri-subharmonic on the same strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}}$ as $u (\\underline{x})$, its upper bound on this strip is $B = \\rho$ and its mean is $\\displaystyle \\bigr< u^\\sharp \\bigl> =  \\frac{\\rho}{S} \\, \\left< u \\right>$\n\nThen <a href=\"#apriori-avshifts\" data-reference-type=\"eqref\" data-reference=\"apriori-avshifts\">[apriori-avshifts]</a> implies $$\\label{apriori-avg}\n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 \\colon \\bigl|  u^\\sharp (\\underline{x}) -  \\bigr< u^\\sharp \\bigl>   \\bigr| > \\epsilon_0 ] < \\epsilon_1$$ where $\\epsilon_0 := n^{- a/3}$ and $\\epsilon_1 := n^{-4 a/3}$ so $\\epsilon_1 \\ll \\epsilon_0$.\n\nApplying Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a> and performing the obvious calculations, from inequality <a href=\"#strong\" data-reference-type=\"eqref\" data-reference=\"strong\">[strong]</a> we get $$\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 \\colon \\bigl|  u^\\sharp (\\underline{x}) -  \\bigr< u^\\sharp \\bigl>   \\bigr| >  n^{- a/12} ] <  e^{-c \\, n^{a/12}}$$ which then implies <a href=\"#shiftldt\" data-reference-type=\"eqref\" data-reference=\"shiftldt\">[shiftldt]</a> for the multi-frequency shift ${\\rm T}_{\\underline{\\omega}}$. ◻\n\n</div>\n\n# Łojasiewicz inequality for multivariable smooth functions\n\nTo prove the large deviation estimate <a href=\"#ldt-strategy\" data-reference-type=\"eqref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a> for a large enough initial scale $N_0$, we will need a quantitative description of the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>. More precisely, we will show that if a smooth function $v (\\underline{x})$ is not flat at any point as defined in <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>, then the set $[\\underline{x}\\colon v (\\underline{x}) \\approx E]$ of points where $v (\\underline{x})$ is almost constant has small measure (and bounded complexity).\n\nSuch an estimate is called a Łojasiewicz type inequality and it is already available for non-constant analytic functions. For such functions it can be derived using complex analysis methods from , namely lower bounds for the modulus of a holomorphic function on a disk (see Lemma 11.4 in ).\n\nFor non-analytic functions, the proof is more difficult. Using Sard-type arguments, we have obtained a similar result for one-variable functions (see Lemma 5.3 in ). For multivariable smooth functions, the argument is more technical and it involves a quantitative form of the implicit function theorem, also used in and .\n\nWe begin with a simple compactness argument that shows that in the TC <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> we can work with finitely many partial derivatives.\n\n<div id=\"compactarg\" class=\"lemma\">\n\n**Lemma 4**. *Assume $v (\\underline{x})$ is a smooth, $1$-periodic function on $\\mathbb{R}^2$. Then $v (\\underline{x})$ satisfies the transversality condition (<a href=\"#TC\" data-reference-type=\"ref\" data-reference=\"TC\">[TC]</a>) if and only if $$\\label{TC'}\n \\exists \\, \\underline{m}\\in \\mathbb{N}^2 \\  \\left| \\underline{m} \\right| \\neq 0 \\  \\ \\exists  c > 0 \\ \\colon  \\  \\forall \\underline{x}\\in \\mathbb{T}^2  \\  \\max_{\\genfrac{}{}{0cm}{}{\\underline{\\alpha}\\leq \\underline{m}}{\\left| \\alpha \\right| \\neq 0}} \\bigl|  \\partial^{\\underline{\\alpha}} \\, v (\\underline{x})  \\bigr| \\geq c$$ The constants $m, c$ in (<a href=\"#TC&#39;\" data-reference-type=\"ref\" data-reference=\"TC&#39;\">[TC']</a>) depend only on $v$.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* Clearly (<a href=\"#TC&#39;\" data-reference-type=\"ref\" data-reference=\"TC&#39;\">[TC']</a>) $\\Rightarrow$ (<a href=\"#TC\" data-reference-type=\"ref\" data-reference=\"TC\">[TC]</a>). We prove the converse. The TC <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> implies $$\\forall \\, \\underline{x}\\in \\mathbb{T}^2 \\  \\exists \\, \\underline{m}_{\\underline{x}} \\in \\mathbb{N}^2 \\  \\left| \\underline{m}_{\\underline{x}} \\right| \\neq 0 \\  \\mbox{ such that } \\  \\bigl|  \\partial^{\\underline{m}_{\\underline{x}}} \\, v \\, (\\underline{x})  \\bigr| >  c_{\\underline{x}}  > 0$$\n\nThen there are radii $r_{\\underline{x}} > 0$ so that if $\\underline{y}$ is in the disk $D (\\underline{x}, r_{\\underline{x}})$ we have $\\bigl|  \\partial^{\\underline{m}_{\\underline{x}}} \\, v \\, (\\underline{y})  \\bigr| \\geq c_{\\underline{x}}  > 0$. The family $\\{ D (\\underline{x}, r_{\\underline{x}})  \\colon \\underline{x}\\in \\mathbb{T}^2 \\}$ covers $\\mathbb{T}^2$. Consider a finite subcover $\\{  D (\\underline{x}_1, r_{\\underline{x}_1}), \\ldots , D (\\underline{x}_k, r_{\\underline{x}_k}) \\}$. Let $\\underline{m}\\in \\mathbb{N}^2$ such that $\\underline{m}\\ge \\underline{m}_{\\underline{x}_j}$ for all $1 \\leq j \\leq k$ and $\\displaystyle c := \\min_{1 \\le j \\le k} c_{\\underline{x}_j}$. Then (<a href=\"#TC&#39;\" data-reference-type=\"ref\" data-reference=\"TC&#39;\">[TC']</a>) follows. ◻\n\n</div>\n\nThe following is a more precise form of the implicit function theorem (which was also used in ).\n\n<div id=\"e-implicit\" class=\"lemma\">\n\n**Lemma 5**. *Let $f (\\underline{x})$ be a $C^1$ function on a rectangle $\\underline{\\mathcal{R}}= I \\times J \\subset [0, 1]^2$, let $J = [c, d]$ and $\\displaystyle A := \\max_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial_{x_1}f (\\underline{x})|$. Assume that $$\\label{dx2>}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial_{x_2}f (\\underline{x})| =: \\epsilon_0 > 0$$ If $f (a_1, a_2)= 0$ for some point $(a_1, a_2)\\in \\underline{\\mathcal{R}}$, then there is an interval $I_0 = (a_1 - \\kappa, a_2 + \\kappa) \\subset I$ and a $C^1$ function $\\phi_0 (x_1)$ on $I_0$ such that: $$\\begin{aligned}\n\\text{(i) }  & f (x_1, \\phi_0 (x_1)) = 0 & \\text{ for all }  x_1 \\in I_0\\\\\n\\text{(ii) } &  | \\partial_{x_1}\\phi_0 (x_1)| \\le A\\,  \\epsilon^{-1}_0 & \\\\\n\\text{(iii) } & x_1 \\in I_0 \\text{ and } f (x_1, x_2)= 0 &  \\implies x_2 = \\phi_0 (x_1) \n\\end{aligned}$$ Moreover, the size $\\kappa$ of the domain of $\\phi_0$ can be taken as large as $\\kappa\\sim \\epsilon_0 A^{-1}\\cdot \\min \\{a_2-c, d-a_2 \\}$.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* From <a href=\"#dx2&gt;\" data-reference-type=\"eqref\" data-reference=\"dx2&gt;\">[dx2&gt;]</a>, since $\\partial_{x_2}f (\\underline{x})$ is either positive on $\\underline{\\mathcal{R}}$ or negative on $\\underline{\\mathcal{R}}$ (in which case replace $f$ by $-f$), we may clearly assume that in fact: $$\\label{dx2p>}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}}  \\partial_{x_2}f (\\underline{x}) =: \\epsilon_0 > 0$$\n\nMoreover, note that for any fixed $x_1 \\in I$, since $\\partial_{x_2}f (x_1, x_2)\\neq 0$, the equation $f (x_1, x_2)=0$ has a unique solution $x_2$.\n\nLet $x_1 \\in I_0$. Then $$\\bigl|  f (x_1, a_2)  \\bigr| = \\bigl|  f (x_1, a_2) - f (a_1, a_2) \\bigr| = \\bigl|  \\partial_{x_1}f(\\xi, a_2)  \\bigr| \\cdot \\left|  x_1 - a_1  \\right| \\le A \\kappa$$\n\nWe have two possibilities.\n\n$\\rule[.2ex]{.8ex}{.8ex}$  $0 \\le f (x_1, a_2) \\le A \\kappa$. Then, if $a_2-t \\in J$ we have: $$f (x_1, a_2-t) - f (x_1,a_2) = \\partial_{x_2}f (x_1, \\xi) \\cdot (-t)$$ $$f (x_1, a_2-t) = f (x_1,a_2) - t \\cdot \\partial_{x_2}f (x_1, \\xi) \\le A \\kappa- t \\epsilon_0 = 0$$\n\n$\\text{ provided } t = A \\epsilon^{-1}_0 \\kappa$\n\nFor this choice of $t$, $a_2-t$ is indeed in $J$, because of the size $\\kappa_0$ of the interval $I_0$: $\\ t = A \\epsilon^{-1}_0 \\kappa\\le A \\epsilon^{-1}_0 \\epsilon_0 A^{-1}(a_2-c) = a_2-c,  \\ \\text{ so } a_2-t \\ge c$.\n\nTherefore, $$f (x_1, a_2-t) \\le 0 \\le f (x_1,a_2)$$ so there is a unique $x_2 =: \\phi_0 (x_1) \\in [a_2-t, a_2]$ such that $f(x_1, \\phi_0 (x_1)) = 0$.\n\n$\\rule[.2ex]{.8ex}{.8ex}$  $- A \\kappa\\le f (x_1, a_2) \\le 0$. Then, if $a_2+t \\in J$ we have: $$f (x_1, a_2+t) - f (x_1, a_2) = \\partial_{x_2}f (x_1, \\xi) \\cdot t$$ $$f (x_1, a_2+t) = f (x_1, a_2) + t \\cdot \\partial_{x_2}f (x_1, \\xi) \\ge - A \\kappa+ t \\epsilon_0 = 0$$\n\n$\\text{ provided } t = A \\epsilon^{-1}_0 \\kappa$\n\nAs before, for this choice of $t$, $a_2+t$ is in $J$, because of the size $\\kappa$ of the interval $I_0$: $\\ t = A \\epsilon^{-1}_0 \\kappa\\le A \\epsilon^{-1}_0 \\epsilon_0 A^{-1}(d-a_2) = d-a_2, \\ \\text{ so } a_2+t \\le d$.\n\nTherefore, $$f (x_1, a_2) \\le 0 \\le f (x_1, a_2+t)$$ so there is a unique $x_2 =: \\phi_0 (x_1) \\in [a_2, a_2+t]$ such that $f(x_1, \\phi_0 (x_1)) = 0$.\n\nWe proved (i) and (iii). The fact that $\\phi_0 (x_1)$ is $C^1$ follows from the standard implicit function theorem, while the estimate (ii) follows immediately from (i) using the chain’s rule. ◻\n\n</div>\n\nThe following is a quantitative and global version of the previous lemma (see also Lemma 8.3 in ). It says that under the same conditions as above, the points $(x_1, x_2)\\in \\underline{\\mathcal{R}}$ for which $\\bigl|  f (x_1, x_2) \\bigr| \\le \\epsilon$ are either in a narrow strip at the top or at the bottom of the rectangle $\\underline{\\mathcal{R}}$, or near the graphs of some functions $\\phi_j (x_1)$, in other words $x_2 \\approx \\phi_j (x_1)$.\n\n<div id=\"q-implicit\" class=\"lemma\">\n\n**Lemma 6**. *Let $f (\\underline{x})$ be a $C^1$ function on a rectangle $\\underline{\\mathcal{R}}= I \\times J \\subset [0, 1]^2$, where $| I | \\sim \\kappa_0$. Let $J = [c, d]$ and $\\displaystyle A := \\max_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial_{x_1}f (\\underline{x})|$. Assume that: $$\\label{dx2big}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}} \\bigl|  \\partial_{x_2}f (\\underline{x})  \\bigr| =: \\epsilon_0 > 0$$*\n\n*Let $\\epsilon_1 >0$ be small enough, i.e. $\\epsilon_1 < \\frac{\\epsilon_0 \\kappa_0}{4}$ and $\\kappa_1 \\sim \\epsilon_1 A^{-1}$.*\n\n*Then there are about $\\kappa_0 \\kappa^{-1}_1$ sub-intervals $I_j$ of length $\\kappa_1$ covering $I$, and on each interval $I_j$ there is a $C^1$ function $\\phi_j (x_1)$ such that: $$\\begin{aligned}\n\\text{(i) }  & f (x_1, \\phi_j (x_1)) = 0 & \\text{for all }  x_1 \\in I_j  \\\\\n\\text{(ii) } &  \\bigl|  \\partial_{x_1}\\phi_j (x_1)  \\bigr| \\le A\\,  \\epsilon^{-1}_0 &   \\\\\n\\text{(iii) } & [ (x_1, x_2)\\in \\underline{\\mathcal{R}}\\colon  \\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1 ]    \\subset  & \\underline{\\mathcal{R}}^t \\cup \\underline{\\mathcal{R}}^b \\cup (\\cup_{j} \\ \\underline{\\mathcal{S}}_j) \\nonumber\n\\end{aligned}$$ where $$\\begin{aligned}\n\\underline{\\mathcal{R}}^t & := & I \\times [d-2 \\epsilon_1 \\epsilon^{-1}_0, d]\\\\\n\\underline{\\mathcal{R}}^b & := & I \\times [c, c+2 \\epsilon_1 \\epsilon^{-1}_0]\\\\\n\\underline{\\mathcal{S}}_j & := & [ (x_1, x_2)\\colon x_1 \\in I_j, \\bigl|  x_2 - \\phi_j (x_1)  \\bigr| < \\epsilon_1 \\epsilon^{-1}_0 ]\n\\end{aligned}$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* Divide the interval $I$, whose length is $\\sim \\kappa_0$ into $\\sim \\kappa_0\\kappa^{-1}_1$ sub-intervals $I_j$ of length $\\kappa_1$ each.\n\nIf $\\bigl|  f (x_1, x_2) \\bigr| \\ge \\epsilon_1$ for all $(x_1, x_2)\\in I_j \\times [c + 2 \\epsilon_1 \\epsilon^{-1}_0, d -  2 \\epsilon_1 \\epsilon^{-1}_0]$, then we are done with the interval $I_j$.\n\nOtherwise, assume $\\bigl|  f (a_1, a_2) \\bigr| < \\epsilon_1$ for some $a_1 \\in I_j$ and $a_2 \\in [c + 2 \\epsilon_1 \\epsilon^{-1}_0, d -  2 \\epsilon_1 \\epsilon^{-1}_0]$.\n\nWe may assume $0 \\le f (a_1, a_2)\\le \\epsilon_1$, the other case being treated similarly. Then if $a_2 - t \\in J$ we have: $$f (a_1, a_2 - t) - f (a_1, a_2)= \\partial_{x_2}f (a_1, \\xi) \\cdot ( - t) \\ \\text{ for some } \\xi \\in (a_2 - t, a_2)$$ $$f (a_1, a_2 - t) =  f (a_1, a_2)- t \\cdot  \\partial_{x_2}f (a_1, \\xi) \\le \\epsilon_1 - \\epsilon_0 t = 0$$ provided $t = \\epsilon_1 \\epsilon^{-1}_0$. Since $a_2 \\ge c+2 \\epsilon_1 \\epsilon^{-1}_0$, for this $t$ we have $a_2-t \\in J$.\n\nWe then have $f (a_1, a_2 - t) \\le 0 \\le f (a_1, a_2)$, so $f (a_1, a_2^{*}) = 0$ for some $a_2^{*} \\in [a_2-t, a_2]$.\n\nWe can use Lemma <a href=\"#e-implicit\" data-reference-type=\"ref\" data-reference=\"e-implicit\">5</a> around the point $(a_1, a_2^{*})$. The interval we get has length at least $\\epsilon_0 A^{-1}\\cdot \\min \\{a_2-c, d-a_2 \\} > \\epsilon_0 A^{-1}\\cdot  2 \\epsilon_1 \\epsilon^{-1}_0 = 2 \\epsilon_1 A^{-1}> 2 \\kappa_1$, so it contains $I_j$, whose length is $\\sim \\kappa_1$. We have a $C^1$ function $\\phi_j$ on $I_j$ such that $| \\partial_{x_1}\\phi_j | \\le A \\epsilon^{-1}_0$ and $$x_1 \\in I_j \\text{ and }  f (x_1, x_2)= 0 \\iff x_2 = \\phi_j (x_1)$$\n\nNow let $(x_1, x_2)\\in \\underline{\\mathcal{R}}$ such that $\\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1$. Then either $(x_1, x_2)\\in \\underline{\\mathcal{R}}^t \\cup \\underline{\\mathcal{R}}^b$ or $(x_1, x_2)\\in I_j \\times [c + 2 \\epsilon_1 \\epsilon^{-1}_0, d -  2 \\epsilon_1 \\epsilon^{-1}_0]$ for some $j$, in which case: $$\\epsilon_1 > \\bigl|  f (x_1, x_2) \\bigr| = | f (x_1, x_2)- f (x_1, \\phi_j (x_1)) | =$$ $$= | \\partial_{x_2}f (x_1, \\xi) | \\cdot | x_2 - \\phi_j (x_1) | \\ge \\epsilon_0 \\cdot   | x_2 - \\phi_j (x_1) |$$ from which we conclude that $| x_2 - \\phi_j (x_1) | < \\epsilon_1 \\epsilon^{-1}_0$. ◻\n\n</div>\n\nWe have shown that the points $\\underline{x}= (x_1, x_2)\\in \\underline{\\mathcal{R}}$ for which $| f (\\underline{x}) | < \\epsilon_1$ are within $\\sim \\epsilon_1$ from the graphs of some functions $\\phi_j (x_1)$ that have bounded slopes and are defined on small intervals $I_j$. This shows that the ’bad’ set $[ \\underline{x}\\in \\underline{\\mathcal{R}}\\colon | f (\\underline{x}) | < \\epsilon_1 ]$ can be covered by small rectangles instead of $\\epsilon_1$-neighborhoods of curves, and we have control on the size of these rectangles and on their number. In turn, the ’good’ set $[ \\underline{x}\\in \\underline{\\mathcal{R}}\\colon | f (\\underline{x}) | \\ge \\epsilon_1 ]$ can be covered by a comparable number of rectangles, which can be further chopped down into squares, to preserve the symmetry between the two variables. This is the content of the following lemma.\n\n<div id=\"L-ind\" class=\"lemma\">\n\n**Lemma 7**. *Given a $C^2$ function $f (\\underline{x})$ on a square $\\underline{\\mathcal{R}}_0 = I_0 \\times J_0 \\subset [0, 1]^2$, where $| I_0 |, |J_0| \\sim \\kappa_0$. Denote $\\displaystyle A := \\max_{ |\\underline{\\alpha}| \\le 2} \\ \\max_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial^{\\underline{\\alpha}} f (\\underline{x})|$. Assume that: $$\\label{dx2big2}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_0} | \\partial_{x_2}f (\\underline{x})| =: \\epsilon_0 > 0 \\    \\text{ or }  \\ \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_0} | \\partial_{x_1}f (\\underline{x})| =: \\epsilon_0 > 0$$*\n\n*Let $\\epsilon_1 >0$ be small enough, i.e. $\\epsilon_1 < \\frac{\\epsilon_0 \\kappa_0}{4}$ and $\\kappa_1 \\sim \\epsilon_1 A^{-1}$.*\n\n*Then there is a set $\\underline{\\mathcal{B}}_1 \\subset \\underline{\\mathcal{R}}_0$, with $$\\label{bad1}\n \\text{ mes } [ \\underline{\\mathcal{B}}_1 ] \\lesssim\\kappa_0 \\, \\epsilon_1 \\, \\epsilon^{-1}_0$$ such that $\\underline{\\mathcal{R}}_0 \\setminus \\underline{\\mathcal{B}}_1$ is a union of about $(\\kappa_0 \\, \\kappa^{-1}_1)^2$ squares, where each such square has the form $\\underline{\\mathcal{R}}_1 = I_1 \\times J_1$, with $\\bigl| I_1 \\bigr|, \\bigl| J_1 \\bigr| \\sim \\kappa_1$.*\n\n*For each of these squares we have: $$\\label{f>ep1}\n \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_1} \\ \\bigl|  f (\\underline{x})  \\bigr| \\ge \\epsilon_1$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* We will use Lemma <a href=\"#q-implicit\" data-reference-type=\"ref\" data-reference=\"q-implicit\">6</a>. $I_0$ is covered by about $\\kappa_0 \\kappa^{-1}_1$ subintervals $I_j$ of length $\\kappa_1$. Consider one such subinterval. There is a $C^1$ function $\\phi_j (x_1)$ on $I_j$ such that $| \\partial_{x_1}\\phi_j (x_1)| \\le A\\,  \\epsilon^{-1}_0$ and $$[ (x_1, x_2)\\in I_j \\times J_0  \\colon  \\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1 ]    \\subset   \\underline{\\mathcal{R}}_j^t \\cup \\underline{\\mathcal{R}}_j^b  \\cup   \\underline{\\mathcal{S}}_j$$ where if $J_0 = [c_0, d_0]$ then $$\\begin{aligned}\n\\underline{\\mathcal{R}}_j^t & := & I_j  \\times [d_0-2 \\epsilon_1 \\epsilon^{-1}_0, \\, d_0]\\\\\n\\underline{\\mathcal{R}}_j^b & := & I_j  \\times [c_0, \\, c_0+2 \\epsilon_1 \\epsilon^{-1}_0]\\\\\n\\underline{\\mathcal{S}}_j & := & [ (x_1, x_2)\\colon x_1 \\in I_j, |x_2 - \\phi_j (x_1) | < \\epsilon_1 \\epsilon^{-1}_0 ]\n\\end{aligned}$$ Then $$\\underline{\\mathcal{S}}_j \\subset I_j \\times [ \\min_{x_1 \\in I_j} \\, \\phi_j (x_1) - \\epsilon_1 \\epsilon^{-1}_0, \\ \\max_{x_1 \\in I_j} \\, \\phi_j (x_1) + \\epsilon_1 \\epsilon^{-1}_0] =: I_j \\times K_j^m =: \\underline{\\mathcal{R}}_j^m$$ For any $x_1, x_1^\\prime \\in I_j$ we have $$\\bigl|  \\phi_j (x_1) - \\phi_j (x_1^\\prime) \\bigr| \\lesssim A \\epsilon^{-1}_0 \\cdot \\bigl| x_1 - x_1^\\prime \\bigr| \\le A \\epsilon^{-1}_0 \\kappa_1 \\sim \\epsilon_1 \\epsilon^{-1}_0$$ which shows that $$\\bigl|  K_j^m  \\bigr| \\lesssim\\epsilon_1 \\epsilon^{-1}_0$$\n\nWe have shown that $[ (x_1, x_2)\\in I_j \\times J_0  \\colon  \\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1 ]$ is covered by three rectangles: $\\underline{\\mathcal{R}}_j^t$, $\\underline{\\mathcal{R}}_j^b$, $\\underline{\\mathcal{R}}_j^m$, each of the form $I_j \\times K_j$ where $\\bigl| I_j \\bigr| \\sim \\kappa_1$, $\\bigl| K_j \\bigr| \\sim \\epsilon_1 \\epsilon^{-1}_0$.\n\nSumming over $j \\lesssim\\kappa_0 \\kappa^{-1}_1$, we get that the set $[ \\underline{x}\\in \\underline{\\mathcal{R}}_0 \\colon \\bigl|  f (\\underline{x})  \\bigr| < \\epsilon_1 ]$ is contained in the union $\\underline{\\mathcal{B}}_1$ of about $\\kappa_0 \\kappa^{-1}_1$ rectangles of size $\\kappa_1 \\times \\epsilon_1 \\epsilon^{-1}_0$. Then\n\n$$\\text{ mes } [ \\underline{\\mathcal{B}}_1 ] \\lesssim\\kappa_0 \\kappa^{-1}_1 \\cdot  \\kappa_1 \\cdot  \\epsilon_1 \\epsilon^{-1}_0 = \\kappa_0 \\epsilon_1 \\epsilon^{-1}_0$$ which proves <a href=\"#bad1\" data-reference-type=\"eqref\" data-reference=\"bad1\">[bad1]</a>.",
    "labels": [
      "L-ind",
      "LNxE",
      "Riesz",
      "TC'",
      "apriori-avg",
      "apriori-avshifts",
      "aprox<u>",
      "aproxu",
      "avshifts",
      "bad1",
      "boost",
      "boundu",
      "compactarg",
      "dx2>",
      "dx2big",
      "dx2big2",
      "dx2p>",
      "e-implicit",
      "f>ep1",
      "fejerkernelbound",
      "goodstrip",
      "inv",
      "lemma1",
      "mshift",
      "q-implicit",
      "shN",
      "shiftldt",
      "strong",
      "weak"
    ],
    "refs": [
      "DC",
      "DCM",
      "Riesz",
      "TC",
      "TC&#39;",
      "apriori-avshifts",
      "bad1",
      "boost",
      "boundA",
      "boundu",
      "boundv",
      "dx2&gt;",
      "e-implicit",
      "fejerkernelbound",
      "goodstrip",
      "ldt-strategy",
      "mshift",
      "q-implicit",
      "shiftldt",
      "skewn",
      "strong"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L258-265::s5",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L240-257::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L202-239::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L585-596::s8",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L597-609::s9",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L610-623::s10",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L638-669::s13",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L670-682::s14",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L737-745::s4",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L746-759::s5",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L859-867::s13",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L920-935::s19",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L568-584::s7",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 568,
    "end_line": 584,
    "text": "$$\\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert  -  \\frac{1}{N} \\log \\lVert \\tilde{M}_{N} (\\underline{x}) \\rVert  \\bigr|  \\le  \\frac{1}{N} \\lVert M_{N} (\\underline{x})  - \\tilde{M} _{N} (\\underline{x}) \\rVert  < e^{-\\frac{\\rho}{2}N^2}$$\n\nRecall the following notation: $$\\label{LNxE}\nL_N (\\underline{x}, E) = \\frac{1}{N} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d\\underline{x}$$ and define its substitute: $$\\label{shN}\nu_{N} (\\underline{x}, E)  := \\frac{1}{N} \\log || \\tilde{M}_{N} (\\underline{x}) ||$$\n\nTherefore, uniformly in $\\underline{x}\\in \\mathbb{T}^2$ and in the energy $E$: $$\\bigl|  L_N (\\underline{x}, E)  - u_{N} (\\underline{x}, E)  \\bigr|  < e^{-\\frac{\\rho}{2}N^2}$$ and by averaging in $\\underline{x}$: $$\\bigl|  L_N (E) - \\left< u_N (E) \\right>  \\bigr|  < e^{-\\frac{\\rho}{2}N^2}$$ where $L_{N} (E) := \\int_{\\mathbb{T}^2} L_N (\\underline{x}, E)  \\, d\\underline{x}$ and for any function $u (\\underline{x})$, $\\ \\left< u \\right> := \\int_{\\mathbb{T}^2} u (\\underline{x}) \\, d \\underline{x}$.\n\nThe advantage of the substitutes $u_{N} (\\underline{x})$ is that they extend to pluri-subharmonic functions in a neighborhood of the torus $\\mathbb{T}^2$, as explained below.\n\nFor the skew-shift transformation ${\\rm T}= {\\rm S}_\\omega$ we consider the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N} := [ \\left|  \\Im z   \\right| < \\rho_{1,N} ] \\times [ \\left|  \\Im z   \\right| < \\rho_{2,N} ]$ where $\\rho_{1,N} = \\frac{\\rho}{4}N^{- \\delta}$ and $\\rho_{2,N} := \\frac{\\rho_{1,N}}{2 N}  = \\frac{\\rho}{4}N^{- \\delta -1}$\n\nWe have to reduce the size of the strip in the second variable to account for the fact that the skew-shift expands in the imaginary direction. Our approximation method required a reduction in the size of the holomorphicity strip at each scale, and this additional reduction will be comparatively harmless.\n\nIf we extend the map ${\\rm S}_\\omega$ from $\\mathbb{T}^2 = (\\mathbb{R}/\\mathbb{Z})^2$ to $\\mathbb{C}^2$, by $$\\displaystyle {\\rm S}_\\omega(z_1, z_2)= (z_1+z_2, z_2 + \\omega)$$ we get as in (<a href=\"#skewn\" data-reference-type=\"ref\" data-reference=\"skewn\">[skewn]</a>) that $$\\displaystyle \n{\\rm S}_\\omega^n (z_1, z_2)= (z_1 + n z_2 + \\frac{n (n-1)}{2} \\omega, z_2 + n \\omega)$$\n\nThen if $(z_1, z_2)\\in  \\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ and if we perform $n \\leq N$ iterations, we have: $$\\label{goodstrip}\n\\bigl|   \\Im (z_1 + n z_2 + \\frac{n (n-1)}{2} \\omega)  \\bigr| = \\bigl|  \\Im (z_1 + n z_2)  \\bigr| = \\left|  y_1 + n y_2  \\right| < \\frac{\\rho}{2}N^{-\\delta}$$\n\nThe matrix function $$\\displaystyle  \\tilde{A}_N (\\underline{x}) =  \\Bigl[ \\begin{array}{ccc}\n\\lambda v_N (\\underline{x}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$ extends to a $1$-periodic, separately in each variable holomorphic matrix valued function: $$\\tilde{A}_N (\\underline{z}) \n :=  \\Bigl[ \\begin{array}{ccc}\n\\lambda v_N (\\underline{z}) - E  & &   - 1  \\\\\n1 & &   0 \\\\  \\end{array} \\Bigr]$$\n\nUsing <a href=\"#boundv\" data-reference-type=\"eqref\" data-reference=\"boundv\">[boundv]</a> and the definition of the scaling factor $S (\\lambda)$, we have that on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ the matrix valued function $\\tilde{A}_N (\\underline{z})$ is uniformly in $N$ bounded by $e^{S(\\lambda)}$. Combining this with (<a href=\"#goodstrip\" data-reference-type=\"ref\" data-reference=\"goodstrip\">[goodstrip]</a>), the transfer matrix substitutes extend on the same strip to separately holomorphic matrix valued functions $$\\tilde{M} _{N} (\\underline{z}, E)  := \\prod_{j=N}^{1} \\tilde{A}_N ({\\rm S}_\\omega^{j} \\, \\underline{z}, E)$$ such that, for all $\\underline{z}\\in \\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ and for all energies $E$ we have $$\\lVert \\tilde{M} _{N} (\\underline{z}, E)  \\rVert \\le e^{N S(\\lambda)}$$\n\nTherefore, $$u_{N} (\\underline{z})  := \\frac{1}{N} \\log \\lVert \\tilde{M}_{N} (\\underline{z}) \\rVert$$ is a pluri-subharmonic function on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$, and for any $\\underline{z}$ in this strip, $$\\left|  u_N (\\underline{z})  \\right|  \\le  S(\\lambda)$$\n\nThe same argument applies to the multifrequency shift ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$. The extension of this dynamics to the complex plane $${\\rm T}_{\\underline{\\omega}}(z_1, z_2)= (z_1 +  \\omega_1, z_2 +  \\omega_2)$$ does not expand in the imaginary direction, so there is no need to decrease the width of the strip in the second variable as in the case of the skew-shift. However, for convenience of notations, we will choose the same strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$ for both transformations.\n\nWe can now summarize all of the above into the following.\n\n<div id=\"lemma1\" class=\"lemma\">\n\n**Lemma 1**. *For fixed parameters $\\lambda, E$, for a fixed transformation ${\\rm T}= {\\rm S}_\\omega$ or ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$ and for $\\delta = 2 (s-1)$, at every scale $N$ we have a $1$-periodic function $$u_{N} (\\underline{x})  := \\frac{1}{N} \\log \\lVert \\tilde{M}_{N} (\\underline{x}) \\rVert$$ which extends to a pluri-subharmonic function $u_N (\\underline{z})$ on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N} =  [ \\left| \\Im z \\right| < \\rho_{1, N} ]  \\times [ \\left| \\Im z \\right| < \\rho_{2, N} ]$, where $\\rho_{1,N}  \\approx  N^{- \\delta}$, $\\rho_{2,N}  \\approx  N^{- \\delta-1}$ so that $$\\label{boundu}\n\\left|  u_N (\\underline{z})  \\right|  \\le  S(\\lambda) \\quad \\text{ for all } \\quad  \n\\underline{z}\\in  \\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$$*\n\n*Note that the bound (<a href=\"#boundu\" data-reference-type=\"ref\" data-reference=\"boundu\">[boundu]</a>) is uniform in $N$.*\n\n*Moreover, if $N \\gtrsim  S(\\lambda)$, then the logarithmic averages of the transfer matrices $M_N (\\underline{x})$ are well approximated by their substitutes $u_N (\\underline{x})$: $$\\label{aproxu}  \n\\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert  -  u_N (\\underline{x})  \\bigr| \\lesssim e^{- N^2}$$ $$\\label{aprox<u>} \n\\bigl|  L_N -  \\left< u_N \\right>  \\bigr|  \\lesssim e^{- N^2}$$*\n\n</div>\n\nAll the inherent constants in the above (and future) estimates are either universal or depend only on $v$ (and not on the scale $N$) so they can be ignored. The estimates above are independent of the variable $\\underline{x}$, the parameters $\\lambda, E$ and the transformation ${\\rm T}$.\n\nThis s a crucial technical result in our paper, which will allow us to use subharmonic functions techniques as in , for the functions $u_N$, and then transfer the relevant estimates to the rougher functions they substitute.\n\nThe logarithmic averages of the transfer matrix have an almost invariance (under the dynamics) property:\n\n<div id=\"inv\" class=\"lemma\">\n\n**Lemma 2**. *For all $\\underline{x}\\in \\mathbb{T}^2,$ for all parameters $\\lambda, E$ and for all transformations ${\\rm T}$ we have : $$\\label{mshift} \n\\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert -  \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}\\, \\underline{x}) \\rVert \\,  \\bigr| \\lesssim  \\frac{S(\\lambda)}{N}$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* $$\\begin{aligned}\n \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert -  \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}\\, \\underline{x}) \\rVert \\,  \\bigr|  = \\bigl|  \\frac{1}{N} \\log \\frac{\\lVert M_{N} (\\underline{x}) \\rVert}{\\lVert M_{N} ({\\rm T}\\, \\underline{x}) \\rVert}  \\,  \\bigr| \\\\\n = \\bigl|  \\frac{1}{N} \\log \n\\frac{\\lVert A ({\\rm T}^N \\underline{x}) \\cdot \\ldots \\cdot A ({\\rm T}^2 \\underline{x}) \\cdot  A ({\\rm T}\\, \\underline{x}) \\rVert }\n{\\lVert A ( {\\rm T}^{N + 1} \\underline{x}) \\cdot  A ({\\rm T}^N \\underline{x}) \\cdot \\ldots \\cdot A ({\\rm T}^2 \\underline{x}) \\rVert } \\,  \\bigr|  \\\\\n \\le \\frac{1}{N} \\log [ \\, \n \\lVert ( A({\\rm T}^{N + 1} \\underline{x}) )^{- 1} \\rVert \\cdot  \\lVert A ({\\rm T}\\, \\underline{x}) \\rVert \\, ] \n  \\lesssim \\frac{S (\\lambda)}{N} \n\\end{aligned}$$ where the last bound is due to (<a href=\"#boundA\" data-reference-type=\"ref\" data-reference=\"boundA\">[boundA]</a>). The inequality (<a href=\"#mshift\" data-reference-type=\"ref\" data-reference=\"mshift\">[mshift]</a>) then follows. ◻\n\n</div>\n\n# Averages of shifts of pluri-subharmonic functions\n\nOne of the main ingredients in the proof of the LDT <a href=\"#ldt-strategy\" data-reference-type=\"eqref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a> is an estimate on averages of shifts of pluri-subharmonic functions. These averages are shown to converge in a quantitative way to the mean of the function. The result holds for both the skew-shift and the multi-frequency shift.\n\nFor the skew-shift, the result was proven in (see Lemma 2.6 there). We will reproduce here the scaled version of that result, the one that takes into account the size of the domain of subharmonicity and the sup norm of the function. The reader can verify, by following the details of the proof in , that this is indeed the correct scaled version. For the multi-frequency shift, the result is essentially contained within the proof of Theorem 5.5 in , but for completeness, we will include here the details of its proof.\n\n<div id=\"avshifts\" class=\"proposition\">\n\n**Proposition 1**. *Let $u (\\underline{x})$ be a real valued function on $\\mathbb{T}^2$, that extends to a pluri-subharmonic function $u (\\underline{z})$ on a strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}} = [ \\left|  \\Im z_1  \\right| < \\rho_1 ] \\times   [ \\left|  \\Im z_2  \\right| < \\rho_2 ]$. Let $\\rho = \\min \\{\\rho_1, \\rho_2 \\}$. Let ${\\rm T}$ be either the skew-shift or the multi-frequency shift on $\\mathbb{T}^2$, where the underlying frequency satisfies the $DC_\\kappa$ described in <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a> or <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> respectively. Assume that $$\\sup_{\\underline{z}\\in \\underline{\\mathcal{A}}_{\\underline{\\rho}}} \\, | u (\\underline{z}) | \\leq S$$ Then for some explicit constants $\\sigma_0, \\tau_0 > 0$, and for $n \\geq n (\\kappa)$ we have: $$\\label{shiftldt} \n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u ({\\rm T}^j \\underline{x})  \\, -  \\left< u \\right>    \\bigr| > \\frac{S}{\\rho} \\, n^{- \\tau_0} ] < \ne^{- n^{\\sigma_0}}$$*\n\n</div>\n\nHere is how this estimate can be understood. Given the ergodicity of the transformation ${\\rm T}$ for irrational (or rationally independent) frequencies, on the long run, the orbits ${\\rm T}^j \\underline{x}$ of most points $\\underline{x}$ will tend to be fairly well distributed throughout the torus $\\mathbb{T}^2$ (see the picture below).\n\nThe average $\\ \\frac{1}{n} \\sum_{j = 0}^{n-1}  u ({\\rm T}^j \\underline{x})$ will then resemble a Riemann sum of the function $u (\\underline{x})$ and as such, it will approach the integral $\\left< u \\right>$.\n\nMoreover, a quantitative description of the irrationality (or rational independence) of the frequency in the form of a Diophantine condition like <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a>, <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a>, should lead to a quantitative description of the convergence of the average sum to the integral $\\left< u \\right>$.\n\nTo prove this quantitative convergence result, we consider the Fourier expansion of the function $u (\\underline{x})$ and apply it to the average sums. This leads to a convolution of $u (\\underline{x})$ with a Fejér-type kernel. It is crucial to have estimates on the Fourier coefficients of the function $u$, and they are obtained via Riesz’ representation theorem for subharmonic functions (see Corollary 4.1. in ). Since $u (z_1, z_2)$ is pluri-subharmonic, the scaled version of Corollary 4.1. in implies: $$\\label{Riesz} \n\\sup_{x_2 \\in \\mathbb{T}} \\, \\bigl| \\hat{u} (l_1, x_2) \\bigr|  \\lesssim\\frac{S}{\\rho_1} \\cdot \\frac{1}{\\left| l_1 \\right|}  \\ \\text{ and  } \\ \n\\sup_{x_1 \\in \\mathbb{T}} \\, \\bigl| \\hat{u} (x_1, l_2) \\bigr|  \\lesssim\\frac{S}{\\rho_2} \\cdot \\frac{1}{\\left| l_2 \\right|}$$\n\nThe estimates (<a href=\"#Riesz\" data-reference-type=\"ref\" data-reference=\"Riesz\">[Riesz]</a>) imply (small) upper bounds on the $L^2$ - norm of the part of the Fourier expansion for which at least one of the indices $l_1$ and $l_2$ is large. The difficult part is when both indices $l_1$ and $l_2$ are small, in which case we use the Diophantine condition on the frequency to estimate the resulting exponential sums.\n\nIn the case of the skew shift dynamics <a href=\"#skewn\" data-reference-type=\"eqref\" data-reference=\"skewn\">[skewn]</a>, the resulting exponential sums are quadratic, and they are estimated using Weyl’s method (see for the details of the proof). We will now present the details of the proof for the multi-frequency shift case ${\\rm T}\\, \\underline{x}= {\\rm T}_{\\underline{\\omega}} \\, \\underline{x}:= \\underline{x}+ \\underline{\\omega}$.\n\n<div class=\"proof\">\n\n*Proof.* Expand $u (\\underline{x})$ into a Fourier series $$u (\\underline{x}) = \\left< u \\right> + \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\hat{u} (\\underline{l}) \\cdot e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$$ Then the averages of shifts have the form $$\\begin{aligned}\n\\frac{1}{n} \\sum_{j = 0}^{n-1}  u ({\\rm T}^j \\underline{x})  \\ = \\ & \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega}) \\\\\n= \\ & \\left< u \\right> +  \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\hat{u} (\\underline{l}) \\cdot e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}} \\cdot \\Bigl( \\frac{1}{n} \\sum_{j = 0}^{n-1}  e^{2 \\pi i \\, j \\, \\underline{l}\\cdot \\underline{\\omega}} \\Bigr )\\\\\n= \\ & \\left< u \\right> +  \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\hat{u} (\\underline{l}) \\cdot e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}} \\cdot  K_n (\\underline{l}\\cdot \\underline{\\omega})\n\\end{aligned}$$ where we denoted by $K_n (t)$ the Fejér kernel $$K_n (t) = \\frac{1}{n} \\sum_{j = 0}^{n-1}  e^{2 \\pi i \\, j t} \\, = \\, \\frac{1}{n} \\, \\frac{1 - e^{2 \\pi i \\, n t}}{1 - e^{2 \\pi i \\, t}}$$ which clearly has the bound $$\\label{fejerkernelbound}\n\\bigl| K_n (t) \\bigr| \\le \\min \\Bigl\\{ 1, \\frac{1}{n \\lVert t\\rVert} \\Bigr\\}$$ We then have: $$\\begin{aligned}\n\\Bigl\\|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega}) - \\left< u \\right> \\Bigr\\|_{L^2(\\mathbb{T}^2)}^2 \\  = \\ &\n \\sum_{\\genfrac{}{}{0cm}{}{\\underline{l}\\in \\mathbb{Z}^2}{\\underline{l}\\neq (0,0)}} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2\\\\\n =  \\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2 \\  + \\ &\n  \\sum_{\\left| \\underline{l} \\right| \\ge K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2\n\\end{aligned}$$ We will estimate the second sum above using the bounds <a href=\"#Riesz\" data-reference-type=\"eqref\" data-reference=\"Riesz\">[Riesz]</a> on the Fourier coefficients of $u (\\underline{x})$ and the first sum using the DC <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> on the frequency $\\underline{\\omega}$. The splitting point $K$ will be chosen to optimize the sum of these estimates.\n\nClearly <a href=\"#Riesz\" data-reference-type=\"eqref\" data-reference=\"Riesz\">[Riesz]</a> implies: $$\\sum_{l_2 \\in \\mathbb{Z}} \\, \\bigl| \\hat{u} (l_1, l_2) \\bigr|^2 = \\Bigl\\| \\hat{u} (l_1, x_2)\\Bigr\\|_{L_{x_2}^2(\\mathbb{T})}^2 \\lesssim\\, \\Bigr( \\frac{S}{\\rho_1} \\, \\frac{1}{\\left| l_1 \\right|}\\Bigl)^2 \\le  \\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\frac{1}{\\left| l_1 \\right|^2}$$ and $$\\sum_{l_1 \\in \\mathbb{Z}} \\, \\bigl| \\hat{u} (l_1, l_2) \\bigr|^2 = \\Bigl\\| \\hat{u} (x_1, l_2)\\Bigr\\|_{L_{x_1}^2(\\mathbb{T})}^2 \\lesssim\\, \\Bigr( \\frac{S}{\\rho_2} \\, \\frac{1}{\\left| l_2 \\right|}\\Bigl)^2 \\le  \\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\frac{1}{\\left| l_2 \\right|^2}$$\n\nThen we have: $$\\begin{aligned}\n \\sum_{\\left| \\underline{l} \\right| \\ge K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2   \\le \\sum_{\\left| \\underline{l} \\right| \\ge K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\\\\n   \\le  \\sum_{\\underline{l}\\colon \\left| l_1 \\right| \\ge K/2} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2  +    \\sum_{\\underline{l}\\colon \\left| l_2 \\right| \\ge K/2}  \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \n \\lesssim\\,  \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\frac{1}{K}\n\\end{aligned}$$\n\nEstimate <a href=\"#Riesz\" data-reference-type=\"eqref\" data-reference=\"Riesz\">[Riesz]</a> clearly impies: $$\\bigl| \\hat{u} (\\underline{l}) \\bigr| \\lesssim\\frac{S}{\\rho} \\, \\frac{1}{\\left| \\underline{l} \\right|}$$ Then using the DC <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> on $\\underline{\\omega}$ and <a href=\"#fejerkernelbound\" data-reference-type=\"eqref\" data-reference=\"fejerkernelbound\">[fejerkernelbound]</a>, we obtain: $$\\begin{aligned}\n\\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\, \\bigl| \\hat{u} (\\underline{l}) \\bigr|^2 \\cdot \\bigl| K_n (\\underline{l}\\cdot \\underline{\\omega}) \\bigr|^2 \\le \n\\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\,\\frac{1}{\\left| \\underline{l} \\right|^2} \\cdot \\frac{1}{n^2 \\, \\lVert\\underline{l}\\cdot \\underline{\\omega}\\rVert^2} \\\\\n\\le \\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\, \\sum_{1 \\le \\left| \\underline{l} \\right| <  K} \\,\\frac{1}{\\left| \\underline{l} \\right|^2} \\cdot \\frac{\\left| \\underline{l} \\right|^{2 A}}{n^2 \\, \\kappa^2}\n\\lesssim\\, \\Bigr( \\frac{S}{\\rho} \\Bigl)^2 \\,  \\frac{K^{2 A}}{n^2 \\kappa^2}\n\\end{aligned}$$\n\nWe conclude: $$\\Bigl\\|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega}) - \\left< u \\right> \\Bigr\\|_{L^2(\\mathbb{T}^2)} \\ \\le \\ \\frac{S}{\\rho} \\Bigr( \\frac{1}{K^{1/2}} + \\frac{K^A}{n \\kappa} \\Bigl) \\le \\frac{S}{\\rho} n^{- a}$$ for some positive constant $a$ that depends on $A$ and for $n$ large enough depending on $A$ and $\\kappa$.\n\nUsing Chebyshev’s inequality, the above estimate implies: $$\\label{apriori-avshifts}\n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega})  \\, -  \\left< u \\right>  \\bigr|  > \\frac{S}{\\rho} \\, n^{- a/3} ] \\ < \\  \n n^{-4 a/3}$$\n\nThis is not exactly what we wanted, since the size of the “bad” set above decays only polynomially fast in $n$, instead of exponentially fast.\n\nTo boost this estimate, we will use Lemma 4.12 in J. Bourgain’s monograph . This result shows that a weaker a-priori estimate on a subharmonic function implies an upper bound on its BMO norm, which in turn leads, via John-Nirenberg inequality, to a stronger estimate on the function. We reproduce here a “rescaled” version of the estimate in , one that takes into account the width $\\rho$ of subharmonicity. The reader may verify that this is indeed the correct rescaled version of the statement.\n\n<div id=\"boost\" class=\"lemma\">\n\n**Lemma 3**. *Assume that $u = u (\\underline{x}) \\colon \\mathbb{T}^2 \\to \\mathbb{R}$ has a pluri-subharmonic extension $u (\\underline{z})$ on $\\underline{\\mathcal{A}}_{\\underline{\\rho}} = [ \\left|  \\Im z_1  \\right| < \\rho_1 ] \\times   [ \\left|  \\Im z_2  \\right| < \\rho_2 ]$ such that $\\displaystyle \\sup_{\\underline{z}\\in \\underline{\\mathcal{A}}_{\\underline{\\rho}}} \\, \\bigl|  u (\\underline{z})  \\bigr| \\le B$. Let $\\rho = \\min \\{\\rho_1, \\rho_2 \\}$. If $$\\label{weak}\n \\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|  u (\\underline{x}) - \\left< u \\right>  \\bigr|  > \\epsilon _0 ] < \\epsilon _1$$ then for an absolute constant $c > 0$, $$\\label{strong}\n \\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|   u (\\underline{x}) - \\left< u \\right>  \\bigr| > {\\epsilon _0}^{1/4} ] \n < e^{- c \\bigl(  {\\epsilon _0}^{1/4} + \\sqrt{\\frac{B}{\\rho}}  \\;   \\frac{{\\epsilon_1}^{1/4}} {{\\epsilon_0}^{1/2}}    \\bigr)^{- 1}}$$*\n\n</div>\n\nWe will apply this result to the average $$u^\\sharp (\\underline{x}) := \\frac{\\rho}{S} \\,  \\frac{1}{n}\\sum_{j = 0}^{n-1}  u (\\underline{x}+ j \\underline{\\omega})$$\n\nClearly $u^\\sharp (\\underline{x})$ is pluri-subharmonic on the same strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}}$ as $u (\\underline{x})$, its upper bound on this strip is $B = \\rho$ and its mean is $\\displaystyle \\bigr< u^\\sharp \\bigl> =  \\frac{\\rho}{S} \\, \\left< u \\right>$\n\nThen <a href=\"#apriori-avshifts\" data-reference-type=\"eqref\" data-reference=\"apriori-avshifts\">[apriori-avshifts]</a> implies $$\\label{apriori-avg}\n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 \\colon \\bigl|  u^\\sharp (\\underline{x}) -  \\bigr< u^\\sharp \\bigl>   \\bigr| > \\epsilon_0 ] < \\epsilon_1$$ where $\\epsilon_0 := n^{- a/3}$ and $\\epsilon_1 := n^{-4 a/3}$ so $\\epsilon_1 \\ll \\epsilon_0$.\n\nApplying Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a> and performing the obvious calculations, from inequality <a href=\"#strong\" data-reference-type=\"eqref\" data-reference=\"strong\">[strong]</a> we get $$\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 \\colon \\bigl|  u^\\sharp (\\underline{x}) -  \\bigr< u^\\sharp \\bigl>   \\bigr| >  n^{- a/12} ] <  e^{-c \\, n^{a/12}}$$ which then implies <a href=\"#shiftldt\" data-reference-type=\"eqref\" data-reference=\"shiftldt\">[shiftldt]</a> for the multi-frequency shift ${\\rm T}_{\\underline{\\omega}}$. ◻\n\n</div>\n\n# Łojasiewicz inequality for multivariable smooth functions\n\nTo prove the large deviation estimate <a href=\"#ldt-strategy\" data-reference-type=\"eqref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a> for a large enough initial scale $N_0$, we will need a quantitative description of the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>. More precisely, we will show that if a smooth function $v (\\underline{x})$ is not flat at any point as defined in <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>, then the set $[\\underline{x}\\colon v (\\underline{x}) \\approx E]$ of points where $v (\\underline{x})$ is almost constant has small measure (and bounded complexity).\n\nSuch an estimate is called a Łojasiewicz type inequality and it is already available for non-constant analytic functions. For such functions it can be derived using complex analysis methods from , namely lower bounds for the modulus of a holomorphic function on a disk (see Lemma 11.4 in ).\n\nFor non-analytic functions, the proof is more difficult. Using Sard-type arguments, we have obtained a similar result for one-variable functions (see Lemma 5.3 in ). For multivariable smooth functions, the argument is more technical and it involves a quantitative form of the implicit function theorem, also used in and .\n\nWe begin with a simple compactness argument that shows that in the TC <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> we can work with finitely many partial derivatives.\n\n<div id=\"compactarg\" class=\"lemma\">\n\n**Lemma 4**. *Assume $v (\\underline{x})$ is a smooth, $1$-periodic function on $\\mathbb{R}^2$. Then $v (\\underline{x})$ satisfies the transversality condition (<a href=\"#TC\" data-reference-type=\"ref\" data-reference=\"TC\">[TC]</a>) if and only if $$\\label{TC'}\n \\exists \\, \\underline{m}\\in \\mathbb{N}^2 \\  \\left| \\underline{m} \\right| \\neq 0 \\  \\ \\exists  c > 0 \\ \\colon  \\  \\forall \\underline{x}\\in \\mathbb{T}^2  \\  \\max_{\\genfrac{}{}{0cm}{}{\\underline{\\alpha}\\leq \\underline{m}}{\\left| \\alpha \\right| \\neq 0}} \\bigl|  \\partial^{\\underline{\\alpha}} \\, v (\\underline{x})  \\bigr| \\geq c$$ The constants $m, c$ in (<a href=\"#TC&#39;\" data-reference-type=\"ref\" data-reference=\"TC&#39;\">[TC']</a>) depend only on $v$.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* Clearly (<a href=\"#TC&#39;\" data-reference-type=\"ref\" data-reference=\"TC&#39;\">[TC']</a>) $\\Rightarrow$ (<a href=\"#TC\" data-reference-type=\"ref\" data-reference=\"TC\">[TC]</a>). We prove the converse. The TC <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> implies $$\\forall \\, \\underline{x}\\in \\mathbb{T}^2 \\  \\exists \\, \\underline{m}_{\\underline{x}} \\in \\mathbb{N}^2 \\  \\left| \\underline{m}_{\\underline{x}} \\right| \\neq 0 \\  \\mbox{ such that } \\  \\bigl|  \\partial^{\\underline{m}_{\\underline{x}}} \\, v \\, (\\underline{x})  \\bigr| >  c_{\\underline{x}}  > 0$$\n\nThen there are radii $r_{\\underline{x}} > 0$ so that if $\\underline{y}$ is in the disk $D (\\underline{x}, r_{\\underline{x}})$ we have $\\bigl|  \\partial^{\\underline{m}_{\\underline{x}}} \\, v \\, (\\underline{y})  \\bigr| \\geq c_{\\underline{x}}  > 0$. The family $\\{ D (\\underline{x}, r_{\\underline{x}})  \\colon \\underline{x}\\in \\mathbb{T}^2 \\}$ covers $\\mathbb{T}^2$. Consider a finite subcover $\\{  D (\\underline{x}_1, r_{\\underline{x}_1}), \\ldots , D (\\underline{x}_k, r_{\\underline{x}_k}) \\}$. Let $\\underline{m}\\in \\mathbb{N}^2$ such that $\\underline{m}\\ge \\underline{m}_{\\underline{x}_j}$ for all $1 \\leq j \\leq k$ and $\\displaystyle c := \\min_{1 \\le j \\le k} c_{\\underline{x}_j}$. Then (<a href=\"#TC&#39;\" data-reference-type=\"ref\" data-reference=\"TC&#39;\">[TC']</a>) follows. ◻\n\n</div>\n\nThe following is a more precise form of the implicit function theorem (which was also used in ).\n\n<div id=\"e-implicit\" class=\"lemma\">\n\n**Lemma 5**. *Let $f (\\underline{x})$ be a $C^1$ function on a rectangle $\\underline{\\mathcal{R}}= I \\times J \\subset [0, 1]^2$, let $J = [c, d]$ and $\\displaystyle A := \\max_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial_{x_1}f (\\underline{x})|$. Assume that $$\\label{dx2>}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial_{x_2}f (\\underline{x})| =: \\epsilon_0 > 0$$ If $f (a_1, a_2)= 0$ for some point $(a_1, a_2)\\in \\underline{\\mathcal{R}}$, then there is an interval $I_0 = (a_1 - \\kappa, a_2 + \\kappa) \\subset I$ and a $C^1$ function $\\phi_0 (x_1)$ on $I_0$ such that: $$\\begin{aligned}\n\\text{(i) }  & f (x_1, \\phi_0 (x_1)) = 0 & \\text{ for all }  x_1 \\in I_0\\\\\n\\text{(ii) } &  | \\partial_{x_1}\\phi_0 (x_1)| \\le A\\,  \\epsilon^{-1}_0 & \\\\\n\\text{(iii) } & x_1 \\in I_0 \\text{ and } f (x_1, x_2)= 0 &  \\implies x_2 = \\phi_0 (x_1) \n\\end{aligned}$$ Moreover, the size $\\kappa$ of the domain of $\\phi_0$ can be taken as large as $\\kappa\\sim \\epsilon_0 A^{-1}\\cdot \\min \\{a_2-c, d-a_2 \\}$.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* From <a href=\"#dx2&gt;\" data-reference-type=\"eqref\" data-reference=\"dx2&gt;\">[dx2&gt;]</a>, since $\\partial_{x_2}f (\\underline{x})$ is either positive on $\\underline{\\mathcal{R}}$ or negative on $\\underline{\\mathcal{R}}$ (in which case replace $f$ by $-f$), we may clearly assume that in fact: $$\\label{dx2p>}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}}  \\partial_{x_2}f (\\underline{x}) =: \\epsilon_0 > 0$$\n\nMoreover, note that for any fixed $x_1 \\in I$, since $\\partial_{x_2}f (x_1, x_2)\\neq 0$, the equation $f (x_1, x_2)=0$ has a unique solution $x_2$.\n\nLet $x_1 \\in I_0$. Then $$\\bigl|  f (x_1, a_2)  \\bigr| = \\bigl|  f (x_1, a_2) - f (a_1, a_2) \\bigr| = \\bigl|  \\partial_{x_1}f(\\xi, a_2)  \\bigr| \\cdot \\left|  x_1 - a_1  \\right| \\le A \\kappa$$\n\nWe have two possibilities.\n\n$\\rule[.2ex]{.8ex}{.8ex}$  $0 \\le f (x_1, a_2) \\le A \\kappa$. Then, if $a_2-t \\in J$ we have: $$f (x_1, a_2-t) - f (x_1,a_2) = \\partial_{x_2}f (x_1, \\xi) \\cdot (-t)$$ $$f (x_1, a_2-t) = f (x_1,a_2) - t \\cdot \\partial_{x_2}f (x_1, \\xi) \\le A \\kappa- t \\epsilon_0 = 0$$\n\n$\\text{ provided } t = A \\epsilon^{-1}_0 \\kappa$\n\nFor this choice of $t$, $a_2-t$ is indeed in $J$, because of the size $\\kappa_0$ of the interval $I_0$: $\\ t = A \\epsilon^{-1}_0 \\kappa\\le A \\epsilon^{-1}_0 \\epsilon_0 A^{-1}(a_2-c) = a_2-c,  \\ \\text{ so } a_2-t \\ge c$.\n\nTherefore, $$f (x_1, a_2-t) \\le 0 \\le f (x_1,a_2)$$ so there is a unique $x_2 =: \\phi_0 (x_1) \\in [a_2-t, a_2]$ such that $f(x_1, \\phi_0 (x_1)) = 0$.\n\n$\\rule[.2ex]{.8ex}{.8ex}$  $- A \\kappa\\le f (x_1, a_2) \\le 0$. Then, if $a_2+t \\in J$ we have: $$f (x_1, a_2+t) - f (x_1, a_2) = \\partial_{x_2}f (x_1, \\xi) \\cdot t$$ $$f (x_1, a_2+t) = f (x_1, a_2) + t \\cdot \\partial_{x_2}f (x_1, \\xi) \\ge - A \\kappa+ t \\epsilon_0 = 0$$\n\n$\\text{ provided } t = A \\epsilon^{-1}_0 \\kappa$\n\nAs before, for this choice of $t$, $a_2+t$ is in $J$, because of the size $\\kappa$ of the interval $I_0$: $\\ t = A \\epsilon^{-1}_0 \\kappa\\le A \\epsilon^{-1}_0 \\epsilon_0 A^{-1}(d-a_2) = d-a_2, \\ \\text{ so } a_2+t \\le d$.\n\nTherefore, $$f (x_1, a_2) \\le 0 \\le f (x_1, a_2+t)$$ so there is a unique $x_2 =: \\phi_0 (x_1) \\in [a_2, a_2+t]$ such that $f(x_1, \\phi_0 (x_1)) = 0$.\n\nWe proved (i) and (iii). The fact that $\\phi_0 (x_1)$ is $C^1$ follows from the standard implicit function theorem, while the estimate (ii) follows immediately from (i) using the chain’s rule. ◻\n\n</div>\n\nThe following is a quantitative and global version of the previous lemma (see also Lemma 8.3 in ). It says that under the same conditions as above, the points $(x_1, x_2)\\in \\underline{\\mathcal{R}}$ for which $\\bigl|  f (x_1, x_2) \\bigr| \\le \\epsilon$ are either in a narrow strip at the top or at the bottom of the rectangle $\\underline{\\mathcal{R}}$, or near the graphs of some functions $\\phi_j (x_1)$, in other words $x_2 \\approx \\phi_j (x_1)$.\n\n<div id=\"q-implicit\" class=\"lemma\">\n\n**Lemma 6**. *Let $f (\\underline{x})$ be a $C^1$ function on a rectangle $\\underline{\\mathcal{R}}= I \\times J \\subset [0, 1]^2$, where $| I | \\sim \\kappa_0$. Let $J = [c, d]$ and $\\displaystyle A := \\max_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial_{x_1}f (\\underline{x})|$. Assume that: $$\\label{dx2big}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}} \\bigl|  \\partial_{x_2}f (\\underline{x})  \\bigr| =: \\epsilon_0 > 0$$*\n\n*Let $\\epsilon_1 >0$ be small enough, i.e. $\\epsilon_1 < \\frac{\\epsilon_0 \\kappa_0}{4}$ and $\\kappa_1 \\sim \\epsilon_1 A^{-1}$.*\n\n*Then there are about $\\kappa_0 \\kappa^{-1}_1$ sub-intervals $I_j$ of length $\\kappa_1$ covering $I$, and on each interval $I_j$ there is a $C^1$ function $\\phi_j (x_1)$ such that: $$\\begin{aligned}\n\\text{(i) }  & f (x_1, \\phi_j (x_1)) = 0 & \\text{for all }  x_1 \\in I_j  \\\\\n\\text{(ii) } &  \\bigl|  \\partial_{x_1}\\phi_j (x_1)  \\bigr| \\le A\\,  \\epsilon^{-1}_0 &   \\\\\n\\text{(iii) } & [ (x_1, x_2)\\in \\underline{\\mathcal{R}}\\colon  \\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1 ]    \\subset  & \\underline{\\mathcal{R}}^t \\cup \\underline{\\mathcal{R}}^b \\cup (\\cup_{j} \\ \\underline{\\mathcal{S}}_j) \\nonumber\n\\end{aligned}$$ where $$\\begin{aligned}\n\\underline{\\mathcal{R}}^t & := & I \\times [d-2 \\epsilon_1 \\epsilon^{-1}_0, d]\\\\\n\\underline{\\mathcal{R}}^b & := & I \\times [c, c+2 \\epsilon_1 \\epsilon^{-1}_0]\\\\\n\\underline{\\mathcal{S}}_j & := & [ (x_1, x_2)\\colon x_1 \\in I_j, \\bigl|  x_2 - \\phi_j (x_1)  \\bigr| < \\epsilon_1 \\epsilon^{-1}_0 ]\n\\end{aligned}$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* Divide the interval $I$, whose length is $\\sim \\kappa_0$ into $\\sim \\kappa_0\\kappa^{-1}_1$ sub-intervals $I_j$ of length $\\kappa_1$ each.\n\nIf $\\bigl|  f (x_1, x_2) \\bigr| \\ge \\epsilon_1$ for all $(x_1, x_2)\\in I_j \\times [c + 2 \\epsilon_1 \\epsilon^{-1}_0, d -  2 \\epsilon_1 \\epsilon^{-1}_0]$, then we are done with the interval $I_j$.\n\nOtherwise, assume $\\bigl|  f (a_1, a_2) \\bigr| < \\epsilon_1$ for some $a_1 \\in I_j$ and $a_2 \\in [c + 2 \\epsilon_1 \\epsilon^{-1}_0, d -  2 \\epsilon_1 \\epsilon^{-1}_0]$.\n\nWe may assume $0 \\le f (a_1, a_2)\\le \\epsilon_1$, the other case being treated similarly. Then if $a_2 - t \\in J$ we have: $$f (a_1, a_2 - t) - f (a_1, a_2)= \\partial_{x_2}f (a_1, \\xi) \\cdot ( - t) \\ \\text{ for some } \\xi \\in (a_2 - t, a_2)$$ $$f (a_1, a_2 - t) =  f (a_1, a_2)- t \\cdot  \\partial_{x_2}f (a_1, \\xi) \\le \\epsilon_1 - \\epsilon_0 t = 0$$ provided $t = \\epsilon_1 \\epsilon^{-1}_0$. Since $a_2 \\ge c+2 \\epsilon_1 \\epsilon^{-1}_0$, for this $t$ we have $a_2-t \\in J$.\n\nWe then have $f (a_1, a_2 - t) \\le 0 \\le f (a_1, a_2)$, so $f (a_1, a_2^{*}) = 0$ for some $a_2^{*} \\in [a_2-t, a_2]$.\n\nWe can use Lemma <a href=\"#e-implicit\" data-reference-type=\"ref\" data-reference=\"e-implicit\">5</a> around the point $(a_1, a_2^{*})$. The interval we get has length at least $\\epsilon_0 A^{-1}\\cdot \\min \\{a_2-c, d-a_2 \\} > \\epsilon_0 A^{-1}\\cdot  2 \\epsilon_1 \\epsilon^{-1}_0 = 2 \\epsilon_1 A^{-1}> 2 \\kappa_1$, so it contains $I_j$, whose length is $\\sim \\kappa_1$. We have a $C^1$ function $\\phi_j$ on $I_j$ such that $| \\partial_{x_1}\\phi_j | \\le A \\epsilon^{-1}_0$ and $$x_1 \\in I_j \\text{ and }  f (x_1, x_2)= 0 \\iff x_2 = \\phi_j (x_1)$$\n\nNow let $(x_1, x_2)\\in \\underline{\\mathcal{R}}$ such that $\\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1$. Then either $(x_1, x_2)\\in \\underline{\\mathcal{R}}^t \\cup \\underline{\\mathcal{R}}^b$ or $(x_1, x_2)\\in I_j \\times [c + 2 \\epsilon_1 \\epsilon^{-1}_0, d -  2 \\epsilon_1 \\epsilon^{-1}_0]$ for some $j$, in which case: $$\\epsilon_1 > \\bigl|  f (x_1, x_2) \\bigr| = | f (x_1, x_2)- f (x_1, \\phi_j (x_1)) | =$$ $$= | \\partial_{x_2}f (x_1, \\xi) | \\cdot | x_2 - \\phi_j (x_1) | \\ge \\epsilon_0 \\cdot   | x_2 - \\phi_j (x_1) |$$ from which we conclude that $| x_2 - \\phi_j (x_1) | < \\epsilon_1 \\epsilon^{-1}_0$. ◻\n\n</div>\n\nWe have shown that the points $\\underline{x}= (x_1, x_2)\\in \\underline{\\mathcal{R}}$ for which $| f (\\underline{x}) | < \\epsilon_1$ are within $\\sim \\epsilon_1$ from the graphs of some functions $\\phi_j (x_1)$ that have bounded slopes and are defined on small intervals $I_j$. This shows that the ’bad’ set $[ \\underline{x}\\in \\underline{\\mathcal{R}}\\colon | f (\\underline{x}) | < \\epsilon_1 ]$ can be covered by small rectangles instead of $\\epsilon_1$-neighborhoods of curves, and we have control on the size of these rectangles and on their number. In turn, the ’good’ set $[ \\underline{x}\\in \\underline{\\mathcal{R}}\\colon | f (\\underline{x}) | \\ge \\epsilon_1 ]$ can be covered by a comparable number of rectangles, which can be further chopped down into squares, to preserve the symmetry between the two variables. This is the content of the following lemma.\n\n<div id=\"L-ind\" class=\"lemma\">\n\n**Lemma 7**. *Given a $C^2$ function $f (\\underline{x})$ on a square $\\underline{\\mathcal{R}}_0 = I_0 \\times J_0 \\subset [0, 1]^2$, where $| I_0 |, |J_0| \\sim \\kappa_0$. Denote $\\displaystyle A := \\max_{ |\\underline{\\alpha}| \\le 2} \\ \\max_{\\underline{x}\\in \\underline{\\mathcal{R}}} | \\partial^{\\underline{\\alpha}} f (\\underline{x})|$. Assume that: $$\\label{dx2big2}\n\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_0} | \\partial_{x_2}f (\\underline{x})| =: \\epsilon_0 > 0 \\    \\text{ or }  \\ \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_0} | \\partial_{x_1}f (\\underline{x})| =: \\epsilon_0 > 0$$*\n\n*Let $\\epsilon_1 >0$ be small enough, i.e. $\\epsilon_1 < \\frac{\\epsilon_0 \\kappa_0}{4}$ and $\\kappa_1 \\sim \\epsilon_1 A^{-1}$.*\n\n*Then there is a set $\\underline{\\mathcal{B}}_1 \\subset \\underline{\\mathcal{R}}_0$, with $$\\label{bad1}\n \\text{ mes } [ \\underline{\\mathcal{B}}_1 ] \\lesssim\\kappa_0 \\, \\epsilon_1 \\, \\epsilon^{-1}_0$$ such that $\\underline{\\mathcal{R}}_0 \\setminus \\underline{\\mathcal{B}}_1$ is a union of about $(\\kappa_0 \\, \\kappa^{-1}_1)^2$ squares, where each such square has the form $\\underline{\\mathcal{R}}_1 = I_1 \\times J_1$, with $\\bigl| I_1 \\bigr|, \\bigl| J_1 \\bigr| \\sim \\kappa_1$.*\n\n*For each of these squares we have: $$\\label{f>ep1}\n \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_1} \\ \\bigl|  f (\\underline{x})  \\bigr| \\ge \\epsilon_1$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* We will use Lemma <a href=\"#q-implicit\" data-reference-type=\"ref\" data-reference=\"q-implicit\">6</a>. $I_0$ is covered by about $\\kappa_0 \\kappa^{-1}_1$ subintervals $I_j$ of length $\\kappa_1$. Consider one such subinterval. There is a $C^1$ function $\\phi_j (x_1)$ on $I_j$ such that $| \\partial_{x_1}\\phi_j (x_1)| \\le A\\,  \\epsilon^{-1}_0$ and $$[ (x_1, x_2)\\in I_j \\times J_0  \\colon  \\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1 ]    \\subset   \\underline{\\mathcal{R}}_j^t \\cup \\underline{\\mathcal{R}}_j^b  \\cup   \\underline{\\mathcal{S}}_j$$ where if $J_0 = [c_0, d_0]$ then $$\\begin{aligned}\n\\underline{\\mathcal{R}}_j^t & := & I_j  \\times [d_0-2 \\epsilon_1 \\epsilon^{-1}_0, \\, d_0]\\\\\n\\underline{\\mathcal{R}}_j^b & := & I_j  \\times [c_0, \\, c_0+2 \\epsilon_1 \\epsilon^{-1}_0]\\\\\n\\underline{\\mathcal{S}}_j & := & [ (x_1, x_2)\\colon x_1 \\in I_j, |x_2 - \\phi_j (x_1) | < \\epsilon_1 \\epsilon^{-1}_0 ]\n\\end{aligned}$$ Then $$\\underline{\\mathcal{S}}_j \\subset I_j \\times [ \\min_{x_1 \\in I_j} \\, \\phi_j (x_1) - \\epsilon_1 \\epsilon^{-1}_0, \\ \\max_{x_1 \\in I_j} \\, \\phi_j (x_1) + \\epsilon_1 \\epsilon^{-1}_0] =: I_j \\times K_j^m =: \\underline{\\mathcal{R}}_j^m$$ For any $x_1, x_1^\\prime \\in I_j$ we have $$\\bigl|  \\phi_j (x_1) - \\phi_j (x_1^\\prime) \\bigr| \\lesssim A \\epsilon^{-1}_0 \\cdot \\bigl| x_1 - x_1^\\prime \\bigr| \\le A \\epsilon^{-1}_0 \\kappa_1 \\sim \\epsilon_1 \\epsilon^{-1}_0$$ which shows that $$\\bigl|  K_j^m  \\bigr| \\lesssim\\epsilon_1 \\epsilon^{-1}_0$$\n\nWe have shown that $[ (x_1, x_2)\\in I_j \\times J_0  \\colon  \\bigl|  f (x_1, x_2) \\bigr| < \\epsilon_1 ]$ is covered by three rectangles: $\\underline{\\mathcal{R}}_j^t$, $\\underline{\\mathcal{R}}_j^b$, $\\underline{\\mathcal{R}}_j^m$, each of the form $I_j \\times K_j$ where $\\bigl| I_j \\bigr| \\sim \\kappa_1$, $\\bigl| K_j \\bigr| \\sim \\epsilon_1 \\epsilon^{-1}_0$.\n\nSumming over $j \\lesssim\\kappa_0 \\kappa^{-1}_1$, we get that the set $[ \\underline{x}\\in \\underline{\\mathcal{R}}_0 \\colon \\bigl|  f (\\underline{x})  \\bigr| < \\epsilon_1 ]$ is contained in the union $\\underline{\\mathcal{B}}_1$ of about $\\kappa_0 \\kappa^{-1}_1$ rectangles of size $\\kappa_1 \\times \\epsilon_1 \\epsilon^{-1}_0$. Then\n\n$$\\text{ mes } [ \\underline{\\mathcal{B}}_1 ] \\lesssim\\kappa_0 \\kappa^{-1}_1 \\cdot  \\kappa_1 \\cdot  \\epsilon_1 \\epsilon^{-1}_0 = \\kappa_0 \\epsilon_1 \\epsilon^{-1}_0$$ which proves <a href=\"#bad1\" data-reference-type=\"eqref\" data-reference=\"bad1\">[bad1]</a>.\n\nThe complement of this set, $\\underline{\\mathcal{R}}_0 \\setminus \\underline{\\mathcal{B}}_1$, consists of about the same number $\\kappa_0 \\kappa^{-1}_1$ of rectangles - this was the reason for switching from $\\epsilon_1$-neighborhoods of curves to rectangles. Each of these rectangles has the form $I_j \\times L_j$, where $\\bigl|  I_j  \\bigr| \\sim \\kappa_1$ and $\\bigl|  L_j  \\bigr| \\sim \\kappa_0 - O(\\epsilon_1 \\epsilon^{-1}_0) \\sim \\kappa_0 \\gg \\kappa_1$. Divide each of these vertical rectangles into about $\\kappa_0 \\kappa^{-1}_1$ squares of size $\\kappa_1 \\times \\kappa_1$ each.\n\nWe conclude that $\\underline{\\mathcal{R}}_0 \\setminus \\underline{\\mathcal{B}}_1$ is covered by about $(\\kappa_0 \\kappa^{-1}_1)^2$ squares of the form $\\underline{\\mathcal{R}}_1 = I_1 \\times J_1$, where the size of each square is $\\bigl| I_1 \\bigr|, \\bigl| J_1 \\bigr| \\sim \\kappa_1$. ◻\n\n</div>\n\nWe now have all the ingredients for proving the following Łojasiewicz type inequality.\n\n<div id=\"Loj\" class=\"theorem\">\n\n**Theorem 2**. *Assume that $v (\\underline{x})$ is a smooth function on $[0,1]^2$ satisfying the transversality condition (<a href=\"#TC\" data-reference-type=\"ref\" data-reference=\"TC\">[TC]</a>). Then for every $\\epsilon> 0$ $$\\label{loj} \n\\sup_{E \\in \\mathbb{R}} \\mbox{ mes } [ \\underline{x}\\in [0,1]^2 : \\, | v (\\underline{x}) - E | < \\epsilon] < C \\cdot \\epsilon^{b}$$ where $C, b > 0$ depend only on $v$.*\n\n</div>\n\n<div class=\"proof\">",
    "labels": [
      "L-ind",
      "LNxE",
      "Loj",
      "Riesz",
      "TC'",
      "apriori-avg",
      "apriori-avshifts",
      "aprox<u>",
      "aproxu",
      "avshifts",
      "bad1",
      "boost",
      "boundu",
      "compactarg",
      "dx2>",
      "dx2big",
      "dx2big2",
      "dx2p>",
      "e-implicit",
      "f>ep1",
      "fejerkernelbound",
      "goodstrip",
      "inv",
      "lemma1",
      "loj",
      "mshift",
      "q-implicit",
      "shN",
      "shiftldt",
      "strong",
      "weak"
    ],
    "refs": [
      "DC",
      "DCM",
      "Riesz",
      "TC",
      "TC&#39;",
      "apriori-avshifts",
      "bad1",
      "boost",
      "boundA",
      "boundu",
      "boundv",
      "dx2&gt;",
      "e-implicit",
      "fejerkernelbound",
      "goodstrip",
      "ldt-strategy",
      "mshift",
      "q-implicit",
      "shiftldt",
      "skewn",
      "strong"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L585-596::s8",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L240-257::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L202-239::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L585-596::s8",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L597-609::s9",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L610-623::s10",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L638-669::s13",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L670-682::s14",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L683-692::s15",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L693-696::s16",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L737-745::s4",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L746-759::s5",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L859-867::s13",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L920-935::s19",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L585-596::s8",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 585,
    "end_line": 596,
    "text": "<div class=\"proof\">\n\n*Proof.* Using Lemma <a href=\"#compactarg\" data-reference-type=\"ref\" data-reference=\"compactarg\">4</a>, $$\\exists \\, \\underline{m}= (m_1, m_2)\\in \\mathbb{N}^2 \\  \\left| \\underline{m} \\right| \\neq 0 \\  \\ \\exists  c > 0 \\ \\colon  \\  \\forall \\underline{x}\\in \\mathbb{T}^2  \\  \\max_{\\genfrac{}{}{0cm}{}{\\underline{\\alpha}\\leq \\underline{m}}{\\left| \\alpha \\right| \\neq 0}}  \\bigl|  \\partial^{\\underline{\\alpha}} \\, v (\\underline{x})  \\bigr| \\geq c$$ Let $$A:= \\max_{\\underline{\\alpha}\\le (m_1+1, m_2+1)} \\ \\max_{\\underline{x}\\in [0,1]^2} \\,  \\bigl| \\partial^{\\underline{\\alpha}} \\, v (\\underline{x})  \\bigr|$$\n\nWe may of course assume that $\\bigl|  E  \\bigr| \\le 2 A$, otherwise there is nothing to prove.\n\nAll the constants in the estimates that follow will depend only on $\\left| \\underline{m} \\right|, c, A$ (so in particular only on $v$).\n\nPartition $[0,1]^2$ into about $(\\frac{2 A}{c})^2$ squares of the form $\\underline{\\mathcal{R}}= I \\times J$ of size $\\bigl| I \\bigr|, \\bigl| J \\bigr| \\sim \\frac{c}{2A}$.\n\nLet $\\underline{\\mathcal{R}}$ be such a square. Then either $\\left| v (\\underline{x})  \\right| \\ge \\epsilon\\ \\text{ for all } \\underline{x}\\in \\underline{\\mathcal{R}}$, in which case we are done with this square, or for some $\\underline{a}= (a_1, a_2)\\in \\underline{\\mathcal{R}}$ we have $\\left|  v (\\underline{a})  \\right| < \\epsilon$. But then for one of the partial derivatives $\\underline{\\alpha}\\le \\underline{m}$, $\\left| \\alpha \\right| \\neq 0$, we have $\\bigl|  \\partial^{\\underline{\\alpha}} \\, v (\\underline{a})   \\bigr| \\ge c$.\n\nAssume for simplicity that $\\bigl|  \\partial^{\\underline{m}} \\, v (\\underline{a})   \\bigr| \\ge c$, which is the worst case scenario.",
    "labels": [],
    "refs": [
      "compactarg"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L597-609::s9",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L597-609::s9",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 597,
    "end_line": 609,
    "text": "Assume for simplicity that $\\bigl|  \\partial^{\\underline{m}} \\, v (\\underline{a})   \\bigr| \\ge c$, which is the worst case scenario.\n\nIf $\\underline{x}\\in \\underline{\\mathcal{R}}$, then $\\lVert \\underline{x}- \\underline{a}\\rVert_{\\infty} := \\max \\{ \\left| x_1 - a_1 \\right|, \\left| x_2-a_2 \\right| \\} \\le \\frac{c}{2A}$.\n\nThen $$\\bigl|  \\partial^{\\underline{m}} \\, v (\\underline{x}) -  \\partial^{\\underline{m}} \\, v (\\underline{a}) \\bigr|  \\lesssim\\max_{\\underline{y}\\in \\underline{\\mathcal{R}}} \\, \\bigl| \\nabla \\partial^{\\underline{m}} \\, v (\\underline{y})  \\bigr| \\cdot \\lVert \\underline{x}- \\underline{a}\\rVert_{\\infty}  \\le\nA \\cdot \\frac{c}{2A} = \\frac{c}{2}$$\n\nIt follows that $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}}  \\bigl|  \\partial^{\\underline{m}} \\, v (\\underline{x})  \\bigr| \\gtrsim\\frac{c}{2}$$\n\nWe will use Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> $\\left| \\underline{m} \\right| =: m$ times.\n\n$\\rule[.2ex]{.8ex}{.8ex}$ **Step 1.** Let $$f_1 (\\underline{x}) := \\partial^{(m_1, m_2-1)} \\, v (\\underline{x})$$ Then $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}} \\bigl| \\partial_{x_2}f_1 (\\underline{x})  \\bigr| =  \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}}  \\bigl|  \\partial^{\\underline{m}} \\, v (\\underline{x})  \\bigr| \\gtrsim c$$\n\nWe apply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> to the function $f_1$ with the following data: $$\\underline{\\mathcal{R}}_0 = \\underline{\\mathcal{R}}, \\ \\kappa_0 = \\frac{c}{2A}, \\ \\epsilon_0 \\sim c, \\ \\epsilon_1 < \\frac{\\epsilon_0 \\kappa_0}{4}, \\ \\kappa_1 \\sim \\epsilon_1 A^{-1}$$ where $\\epsilon_1$ will be chosen later.",
    "labels": [],
    "refs": [
      "L-ind"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L585-596::s8",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L610-623::s10",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L610-623::s10",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 610,
    "end_line": 623,
    "text": "We apply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> to the function $f_1$ with the following data: $$\\underline{\\mathcal{R}}_0 = \\underline{\\mathcal{R}}, \\ \\kappa_0 = \\frac{c}{2A}, \\ \\epsilon_0 \\sim c, \\ \\epsilon_1 < \\frac{\\epsilon_0 \\kappa_0}{4}, \\ \\kappa_1 \\sim \\epsilon_1 A^{-1}$$ where $\\epsilon_1$ will be chosen later.\n\nWe get a set $\\underline{\\mathcal{B}}_1^{\\flat}:= \\underline{\\mathcal{B}}_1$, $\\text{ mes } [ \\underline{\\mathcal{B}}_1^\\flat ] \\lesssim\\kappa_0 \\epsilon_1 \\epsilon^{-1}_0 < \\kappa_0^2 A \\cdot \\epsilon_1 \\epsilon^{-2}_0$ such that $\\underline{\\mathcal{R}}_0 \\setminus  \\underline{\\mathcal{B}}_1^\\flat$ is a union of about $(\\kappa_0 \\kappa^{-1}_1)^2$ squares of the form $\\underline{\\mathcal{R}}_1 = I_1 \\times J_1$, of size $\\bigl| I_1 \\bigr|, \\bigl| J_1 \\bigr| \\sim \\kappa_1$. For each of these squares we have: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_1} \\bigl| f_1 (\\underline{x})  \\bigr|  \\ge \\epsilon_1$$ which means: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_1} \\bigl| \\ \\partial^{(m_1, m_2-1)} \\, v (\\underline{x})  \\bigr| \\ge \\epsilon_1$$\n\n$\\rule[.2ex]{.8ex}{.8ex}$ **Step 2.** Pick any of the squares $\\underline{\\mathcal{R}}_1 = I_1 \\times J_1$ from the previous step and consider say $$f_2 (\\underline{x}) := \\partial^{(m_1-1, m_2-1)} \\, v (\\underline{x})$$ Then $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_1} \\bigl| \\partial_{x_1}f_2 (\\underline{x})  \\bigr| =  \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_1 }  \\bigl|  \\partial^{(m_1, m_2-1)} \\, v (\\underline{x})  \\bigr| \\ge \\epsilon_1$$\n\nApply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> to the function $f_2$ with the following data:\n\n<div class=\"center\">\n\n$\\underline{\\mathcal{R}}_1$, $\\kappa_1$, $\\epsilon_1$ from Step 1,  $\\epsilon_2 < \\frac{\\epsilon_1 \\kappa_1}{4}$,  $\\kappa_2 \\sim \\epsilon_2 A^{-1}$\n\n</div>\n\nwhere $\\epsilon_2$ will be chosen later.",
    "labels": [],
    "refs": [
      "L-ind"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L597-609::s9",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L624-635::s11",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L624-635::s11",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 624,
    "end_line": 635,
    "text": "where $\\epsilon_2$ will be chosen later.\n\nWe get a set $\\underline{\\mathcal{B}}_2$, $\\text{ mes } [ \\underline{\\mathcal{B}}_2 ] \\lesssim\\kappa_1 \\epsilon_2 \\epsilon^{-1}_1$ such that $\\underline{\\mathcal{R}}_1 \\setminus  \\underline{\\mathcal{B}}_2$ is a union of about $(\\kappa_1 \\kappa^{-1}_2)^2$ squares of the form $\\underline{\\mathcal{R}}_2 = I_2 \\times J_2$, of size $\\bigl| I_2 \\bigr|, \\bigl| J_2 \\bigr| \\sim \\kappa_2$. For each of these squares we have: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_2} \\bigl| f_2 (\\underline{x})  \\bigr|  \\ge \\epsilon_2$$ which means: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_2} \\bigl| \\ \\partial^{(m_1-1, m_2-1)} \\, v (\\underline{x})  \\bigr| \\ge \\epsilon_2$$\n\nIf we do this for each of the $\\sim (\\kappa_0 \\kappa^{-1}_1)^2$ squares resulting from Step 1, and if we put together all the ‘bad’ sets $\\underline{\\mathcal{B}}_2$ corresponding to each of these squares, we conclude the following.\n\nThere is a set $\\underline{\\mathcal{B}}_2^{\\flat} \\subset \\underline{\\mathcal{R}}$ such that: $$\\text{ mes } [ \\underline{\\mathcal{B}}_2^{\\flat} ] \\lesssim\\kappa_1 \\epsilon_2 \\epsilon^{-1}_1 \\cdot (\\kappa_0 \\kappa^{-1}_1)^2 = \\kappa_0 \\epsilon_2 \\epsilon^{-1}_1 \\kappa^{-1}_1 \\sim \\kappa_0^2 A \\cdot \\epsilon_2 \\epsilon^{-2}_1$$\n\nHence the total measure of the ‘bad’ set in Step 2 is: $$\\text{ mes } [ \\underline{\\mathcal{B}}_2^{\\flat} ] \\lesssim\\kappa_0^2 A \\cdot \\epsilon_2 \\epsilon^{-2}_1$$\n\nMoreover, $\\underline{\\mathcal{R}}\\setminus (\\underline{\\mathcal{B}}_1^{\\flat} \\cup \\underline{\\mathcal{B}}_2^{\\flat})$ is covered by squares of the form $\\underline{\\mathcal{R}}_2 = I_2 \\times J_2$, of size $\\bigl| I_2 \\bigr|, \\bigl| J_2 \\bigr| \\sim \\kappa_2$.\n\nThe total number of such squares is about $$(\\kappa_1 \\kappa^{-1}_2)^2 \\cdot (\\kappa_0 \\kappa^{-1}_1)^2 = (\\kappa_0 \\kappa^{-1}_2)^2$$",
    "labels": [],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L610-623::s10",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L636-637::s12",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L636-637::s12",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 636,
    "end_line": 637,
    "text": "The total number of such squares is about $$(\\kappa_1 \\kappa^{-1}_2)^2 \\cdot (\\kappa_0 \\kappa^{-1}_1)^2 = (\\kappa_0 \\kappa^{-1}_2)^2$$\n\nOn each of these squares we have:",
    "labels": [],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L624-635::s11",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L638-669::s13",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L638-669::s13",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 638,
    "end_line": 669,
    "text": "On each of these squares we have:\n\n$$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_2} \\bigl| \\ \\partial^{(m_1-1, m_2-1)} \\, v (\\underline{x})  \\bigr| \\ge \\epsilon_2$$\n\nIt is clear how this procedure continues. Perform it for $m-1$ steps. We will get sets $\\underline{\\mathcal{B}}_1^{\\flat}, \\dotsc,  \\underline{\\mathcal{B}}_{m-1}^{\\flat}$ such that $\\underline{\\mathcal{R}}\\setminus (\\underline{\\mathcal{B}}_1^{\\flat} \\cup \\dotsc \\cup \\underline{\\mathcal{B}}_{m-1}^{\\flat})$ consists of about $(\\kappa_0 \\kappa^{-1}_{m-1})^2$ squares of the form $\\underline{\\mathcal{R}}_{m-1} = I_{m-1}  \\times J_{m-1}$, of size $\\bigl| I_{m-1} \\bigr|, \\bigl| J_{m-1} \\bigr| \\sim \\kappa_{m-1}$. On each of these squares we have $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl| \\ \\partial_{x_2}\\, v (\\underline{x})  \\bigr| \\ge \\epsilon_{m-1} \\ \\text{ or } \\ \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl| \\ \\partial_{x_1}\\, v (\\underline{x})  \\bigr| \\ge \\epsilon_{m-1}$$\n\n$\\rule[.2ex]{.8ex}{.8ex}$ **Step m.** Assume the former inequality above and apply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> one more time. Let $$f_m (\\underline{x}) := v (\\underline{x}) - E$$ for some fixed energy $E$ with $\\bigl| E \\bigr| \\le 2A$ (the estimates will not depend on $E$). Then for each of the squares $\\underline{\\mathcal{R}}_{m-1}$ from the previous step we have: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl|  \\partial_{x_2}\\, f_{m} (\\underline{x})  \\bigr|  =  \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl| \\partial_{x_2}\\, v (\\underline{x})  \\bigr| \\ge \\epsilon_{m-1}$$\n\nApply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> to the function $f_m$ with the following data:\n\n<div class=\"center\">\n\n$\\underline{\\mathcal{R}}_{m-1}$, $\\kappa_{m-1}$, $\\epsilon_{m-1}$ from the previous step,  $\\epsilon_m < \\frac{\\epsilon_{m-1}  \\kappa_{m-1}}{4}$,  $\\kappa_m \\sim \\epsilon_m A^{-1}$\n\n</div>\n\nwhere $\\epsilon_m$ will be chosen later.\n\nWe get a set $\\underline{\\mathcal{B}}_m$, $\\text{ mes } [ \\underline{\\mathcal{B}}_m ] \\lesssim\\kappa_{m-1} \\epsilon_m \\epsilon^{-1}_{m-1}$ such that $\\underline{\\mathcal{R}}_{m-1} \\setminus  \\underline{\\mathcal{B}}_m$ is a union of about $(\\kappa_{m-1} \\kappa^{-1}_m)^2$ squares of the form $\\underline{\\mathcal{R}}_m = I_m \\times J_m$, of size $\\bigl| I_m \\bigr|, \\bigl| J_m \\bigr| \\sim \\kappa_m$. For each of these squares we have: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_m} \\bigl| f_m (\\underline{x})  \\bigr|  \\ge \\epsilon_m$$ which means: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_m} \\bigl|  v (\\underline{x}) - E  \\bigr| \\ge \\epsilon_m$$\n\nIf we do this for each of the $\\sim (\\kappa_0 \\kappa^{-1}_{m-1})^2$ squares resulting from the previous step, and if we put together all the corresponding ‘bad’ sets, we conclude.\n\nThere is a set $\\underline{\\mathcal{B}}_m^{\\flat} \\subset \\underline{\\mathcal{R}}$ such that: $$\\text{ mes } [ \\underline{\\mathcal{B}}_m^{\\flat} ] \\lesssim\\kappa_{m-1} \\epsilon_m \\epsilon^{-1}_{m-1} \\cdot (\\kappa_0 \\kappa^{-1}_{m-1})^2 = \\kappa_0 \\epsilon_m \\epsilon^{-1}_{m-1} \\kappa^{-1}_{m-1} \\sim \\kappa_0^2 A \\cdot \\epsilon_m \\epsilon^{-2}_{m-1}$$\n\nHence the total measure of the ‘bad’ set in Step m is: $$\\text{ mes } [ \\underline{\\mathcal{B}}_m^{\\flat} ] \\lesssim\\kappa_0^2 A \\cdot \\epsilon_m \\epsilon^{-2}_{m-1}$$\n\nMoreover, $\\underline{\\mathcal{R}}\\setminus (\\underline{\\mathcal{B}}_1^{\\flat} \\cup \\underline{\\mathcal{B}}_2^{\\flat} \\dotsc \\cup \\underline{\\mathcal{B}}_m^{\\flat} )$ is covered by squares of the form $\\underline{\\mathcal{R}}_m = I_m \\times J_m$, of size $\\bigl| I_m \\bigr|, \\bigl| J_m \\bigr| \\sim \\kappa_m$.\n\nThe total number of such squares is about $$(\\kappa_{m-1} \\kappa^{-1}_m)^2 \\cdot (\\kappa_0 \\kappa^{-1}_{m-1})^2 = (\\kappa_0 \\kappa^{-1}_m)^2$$\n\nOn each of these squares we have:\n\n$$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_m} \\bigl|  v (\\underline{x}) - E  \\bigr| \\ge \\epsilon_m$$",
    "labels": [],
    "refs": [
      "L-ind"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L636-637::s12",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L670-682::s14",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L670-682::s14",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 670,
    "end_line": 682,
    "text": "$$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_2} \\bigl| \\ \\partial^{(m_1-1, m_2-1)} \\, v (\\underline{x})  \\bigr| \\ge \\epsilon_2$$\n\nIt is clear how this procedure continues. Perform it for $m-1$ steps. We will get sets $\\underline{\\mathcal{B}}_1^{\\flat}, \\dotsc,  \\underline{\\mathcal{B}}_{m-1}^{\\flat}$ such that $\\underline{\\mathcal{R}}\\setminus (\\underline{\\mathcal{B}}_1^{\\flat} \\cup \\dotsc \\cup \\underline{\\mathcal{B}}_{m-1}^{\\flat})$ consists of about $(\\kappa_0 \\kappa^{-1}_{m-1})^2$ squares of the form $\\underline{\\mathcal{R}}_{m-1} = I_{m-1}  \\times J_{m-1}$, of size $\\bigl| I_{m-1} \\bigr|, \\bigl| J_{m-1} \\bigr| \\sim \\kappa_{m-1}$. On each of these squares we have $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl| \\ \\partial_{x_2}\\, v (\\underline{x})  \\bigr| \\ge \\epsilon_{m-1} \\ \\text{ or } \\ \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl| \\ \\partial_{x_1}\\, v (\\underline{x})  \\bigr| \\ge \\epsilon_{m-1}$$\n\n$\\rule[.2ex]{.8ex}{.8ex}$ **Step m.** Assume the former inequality above and apply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> one more time. Let $$f_m (\\underline{x}) := v (\\underline{x}) - E$$ for some fixed energy $E$ with $\\bigl| E \\bigr| \\le 2A$ (the estimates will not depend on $E$). Then for each of the squares $\\underline{\\mathcal{R}}_{m-1}$ from the previous step we have: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl|  \\partial_{x_2}\\, f_{m} (\\underline{x})  \\bigr|  =  \\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_{m-1}} \\bigl| \\partial_{x_2}\\, v (\\underline{x})  \\bigr| \\ge \\epsilon_{m-1}$$\n\nApply Lemma <a href=\"#L-ind\" data-reference-type=\"ref\" data-reference=\"L-ind\">7</a> to the function $f_m$ with the following data:\n\n<div class=\"center\">\n\n$\\underline{\\mathcal{R}}_{m-1}$, $\\kappa_{m-1}$, $\\epsilon_{m-1}$ from the previous step,  $\\epsilon_m < \\frac{\\epsilon_{m-1}  \\kappa_{m-1}}{4}$,  $\\kappa_m \\sim \\epsilon_m A^{-1}$\n\n</div>\n\nwhere $\\epsilon_m$ will be chosen later.\n\nWe get a set $\\underline{\\mathcal{B}}_m$, $\\text{ mes } [ \\underline{\\mathcal{B}}_m ] \\lesssim\\kappa_{m-1} \\epsilon_m \\epsilon^{-1}_{m-1}$ such that $\\underline{\\mathcal{R}}_{m-1} \\setminus  \\underline{\\mathcal{B}}_m$ is a union of about $(\\kappa_{m-1} \\kappa^{-1}_m)^2$ squares of the form $\\underline{\\mathcal{R}}_m = I_m \\times J_m$, of size $\\bigl| I_m \\bigr|, \\bigl| J_m \\bigr| \\sim \\kappa_m$. For each of these squares we have: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_m} \\bigl| f_m (\\underline{x})  \\bigr|  \\ge \\epsilon_m$$ which means: $$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_m} \\bigl|  v (\\underline{x}) - E  \\bigr| \\ge \\epsilon_m$$\n\nIf we do this for each of the $\\sim (\\kappa_0 \\kappa^{-1}_{m-1})^2$ squares resulting from the previous step, and if we put together all the corresponding ‘bad’ sets, we conclude.\n\nThere is a set $\\underline{\\mathcal{B}}_m^{\\flat} \\subset \\underline{\\mathcal{R}}$ such that: $$\\text{ mes } [ \\underline{\\mathcal{B}}_m^{\\flat} ] \\lesssim\\kappa_{m-1} \\epsilon_m \\epsilon^{-1}_{m-1} \\cdot (\\kappa_0 \\kappa^{-1}_{m-1})^2 = \\kappa_0 \\epsilon_m \\epsilon^{-1}_{m-1} \\kappa^{-1}_{m-1} \\sim \\kappa_0^2 A \\cdot \\epsilon_m \\epsilon^{-2}_{m-1}$$\n\nHence the total measure of the ‘bad’ set in Step m is: $$\\text{ mes } [ \\underline{\\mathcal{B}}_m^{\\flat} ] \\lesssim\\kappa_0^2 A \\cdot \\epsilon_m \\epsilon^{-2}_{m-1}$$\n\nMoreover, $\\underline{\\mathcal{R}}\\setminus (\\underline{\\mathcal{B}}_1^{\\flat} \\cup \\underline{\\mathcal{B}}_2^{\\flat} \\dotsc \\cup \\underline{\\mathcal{B}}_m^{\\flat} )$ is covered by squares of the form $\\underline{\\mathcal{R}}_m = I_m \\times J_m$, of size $\\bigl| I_m \\bigr|, \\bigl| J_m \\bigr| \\sim \\kappa_m$.\n\nThe total number of such squares is about $$(\\kappa_{m-1} \\kappa^{-1}_m)^2 \\cdot (\\kappa_0 \\kappa^{-1}_{m-1})^2 = (\\kappa_0 \\kappa^{-1}_m)^2$$\n\nOn each of these squares we have:\n\n$$\\min_{\\underline{x}\\in \\underline{\\mathcal{R}}_m} \\bigl|  v (\\underline{x}) - E  \\bigr| \\ge \\epsilon_m$$\n\nTherefore, the total measure of the bad set from all steps is: $$\\label{total-bad}\n\\text{ mes } [ \\underline{\\mathcal{B}}_1^{\\flat} \\cup \\underline{\\mathcal{B}}_2^{\\flat} \\dotsc \\cup \\underline{\\mathcal{B}}_m^{\\flat}  ] \\lesssim\\kappa_0^2 A \\cdot [ \\epsilon_1 \\epsilon^{-2}_0 +  \\epsilon_2 \\epsilon^{-2}_1 + \\dotsc  \\epsilon_m \\epsilon^{-2}_{m-1} ]$$\n\nWe choose $$\\epsilon_j := \\epsilon^{1/3^{m-j}} \\ \\text{ for } 1 \\le j \\le m$$\n\nIf $\\epsilon< \\epsilon^{*}  (c, m)$, then $\\epsilon_0 \\sim c > \\epsilon^{1/3^m}$, $\\epsilon^{-2}_0 \\sim c^{-2} < \\epsilon^{-2}$, so there is no harm in also putting (for simplicity) $\\epsilon_0 = \\epsilon^{1/3^m}$.\n\nIt is a simple calculation to see that for any $\\epsilon< \\epsilon^{*} (m, A)$, we have $\\epsilon_{j+1} < \\frac{\\epsilon_j \\kappa_j}{4}$ for all $j = \\overline{0 \\ldots m-1}$, which allows our inductive process to work.\n\nNote that $\\epsilon_j^3 = \\epsilon_{j+1}$ so $\\epsilon_{j+1} \\epsilon^{-2}_j = \\epsilon_j$. This implies: $$\\epsilon_1 \\epsilon^{-2}_0 +  \\epsilon_2 \\epsilon^{-2}_1 + \\dotsc  \\epsilon_m \\epsilon^{-2}_{m-1} = \\epsilon_0 + \\epsilon_1 + \\dotsc + \\epsilon_{m-1} \\le m \\epsilon_0 = m \\cdot \\epsilon^{1/3^m}$$\n\nFrom <a href=\"#total-bad\" data-reference-type=\"eqref\" data-reference=\"total-bad\">[total-bad]</a> it follows that the total measure of the bad set inside the square $\\underline{\\mathcal{R}}$ is: $$\\text{ mes } [ \\underline{\\mathcal{B}}_1^{\\flat} \\cup \\underline{\\mathcal{B}}_2^{\\flat} \\dotsc \\cup \\underline{\\mathcal{B}}_m^{\\flat}  ] \\lesssim\\kappa_0^2 \\, A \\, m \\cdot \\epsilon^{1/3^m}$$ There are about $(\\frac{2A}{c})^2 = \\kappa^{-2}_0$ such squares.",
    "labels": [
      "total-bad"
    ],
    "refs": [
      "L-ind",
      "total-bad"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L638-669::s13",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L683-692::s15",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L683-692::s15",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L683-692::s15",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 683,
    "end_line": 692,
    "text": "From <a href=\"#total-bad\" data-reference-type=\"eqref\" data-reference=\"total-bad\">[total-bad]</a> it follows that the total measure of the bad set inside the square $\\underline{\\mathcal{R}}$ is: $$\\text{ mes } [ \\underline{\\mathcal{B}}_1^{\\flat} \\cup \\underline{\\mathcal{B}}_2^{\\flat} \\dotsc \\cup \\underline{\\mathcal{B}}_m^{\\flat}  ] \\lesssim\\kappa_0^2 \\, A \\, m \\cdot \\epsilon^{1/3^m}$$ There are about $(\\frac{2A}{c})^2 = \\kappa^{-2}_0$ such squares.\n\nWe conclude that outside a bad set $\\underline{\\mathcal{B}}$, $\\text{ mes } [ \\underline{\\mathcal{B}}] < A \\, m \\cdot e^{1/3^m}$, we have $\\bigl|  v (\\underline{x}) - E  \\bigr| \\ge \\epsilon$, which proves <a href=\"#Loj\" data-reference-type=\"eqref\" data-reference=\"Loj\">[Loj]</a> with $C \\sim A \\, m$ and $b = \\frac{1}{3^m}$. ◻\n\n</div>\n\n<div class=\"remark\">\n\n**Remark 1**. *The exponent $b$ in <a href=\"#loj\" data-reference-type=\"eqref\" data-reference=\"loj\">[loj]</a> is related to the Łojasiewicz exponent of the function $v$ (see , ). Determining the optimal exponent in such an inequality is an interesting problem in itself, and has been studied extensively for polynomials and analytic functions. It is clear that for a polynomial, the Łojasiewicz exponent should be related to its degree $d$, and it is in fact shown to be $O (\\frac{1}{d^2})$ with explicit underlying constants (see , ). The proof of the Łojasiewicz inequality for analytic functions in (see Lemma 11.4 there) does not provide an explicit value for the exponent, but Theorem 4 in provides a scheme for computing it via the Newton distance of $v$.*\n\n*In our proof for smooth, transversal functions, we obtain the exponent $\\frac{1}{3^m}$, where $m$ is the maximum number of partial derivatives needed for transversality. If $v$ were a polynomial of degree $d$, then $m$ would be $d$, which shows that our estimate is very wasteful (we have obtained a better estimate, $O (\\frac{1}{m})$, for one-variable functions, see Lemma 5.3 in ). This, however, seems to be the only such estimate available now for non-analytic functions of two variables.*",
    "labels": [],
    "refs": [
      "Loj",
      "loj",
      "total-bad"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L670-682::s14",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L693-696::s16",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L670-682::s14",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L693-696::s16",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Description of the approximation process",
    "start_line": 693,
    "end_line": 696,
    "text": "*In our proof for smooth, transversal functions, we obtain the exponent $\\frac{1}{3^m}$, where $m$ is the maximum number of partial derivatives needed for transversality. If $v$ were a polynomial of degree $d$, then $m$ would be $d$, which shows that our estimate is very wasteful (we have obtained a better estimate, $O (\\frac{1}{m})$, for one-variable functions, see Lemma 5.3 in ). This, however, seems to be the only such estimate available now for non-analytic functions of two variables.*\n\n*A similar argument can be made for functions of more than two variables, so <a href=\"#loj\" data-reference-type=\"eqref\" data-reference=\"loj\">[loj]</a> will hold for such functions as well.*\n\n</div>",
    "labels": [],
    "refs": [
      "loj"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": " Description of the approximation process"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L683-692::s15",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L697-704::s0",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 697,
    "end_line": 704,
    "text": "# Large deviation theorem, the proof of main results\n\nUsing induction on the scale $N$, we will prove the large deviation estimate <a href=\"#ldt-strategy\" data-reference-type=\"eqref\" data-reference=\"ldt-strategy\">[ldt-strategy]</a> for the logarithmic average of transfer matrices: $$\\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 \\colon \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}, E) \\rVert - L_{N} (E)  \\bigr| > N^{-\\tau} ] <  e^{-N^\\sigma}$$ as well as a lower bound on the mean of these quantities: $$L_N (E) \\ge \\gamma_N \\, \\log \\left| \\lambda \\right|$$\n\nThe base step of the induction uses the quantitative description <a href=\"#loj\" data-reference-type=\"eqref\" data-reference=\"loj\">[loj]</a> of the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> on the potential function, and the large size of the coupling constant. The inductive step uses only the regularity of the potential function via Lemma <a href=\"#lemma1\" data-reference-type=\"ref\" data-reference=\"lemma1\">1</a>, which provides a good approximation of these logarithmic averages by pluri-subharmonic functions.\n\n<div id=\"base-step\" class=\"lemma\">",
    "labels": [
      "base-step"
    ],
    "refs": [
      "TC",
      "ldt-strategy",
      "lemma1",
      "loj"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L693-696::s16",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L161-167::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L958-973::s22",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L705-724::s1",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 705,
    "end_line": 724,
    "text": "<div id=\"base-step\" class=\"lemma\">\n\n**Lemma 8**. *(Base step of the induction) Assume that $v (\\underline{x})$ is smooth and satisfies the transversality condition (<a href=\"#TC\" data-reference-type=\"ref\" data-reference=\"TC\">[TC]</a>). Then given any constant $C > 0$, there are positive constants $\\lambda_1$ and $B$ which depend on $v$ and $C$, such that for any scale $N_0$, for any $\\lambda$ subject to $\\left| \\lambda \\right| \\ge \\max \\{ \\lambda_1, N_0^B \\}$ and for any $E \\in \\mathbb{R}$ we have: $$\\label{step1}\n\\mbox{ mes } [  \\underline{x}\\in \\mathbb{T}^2 \\colon \n\\, \\bigl|   \\frac{1}{N_0} \\log \\lVert  M_{N_0} (\\underline{x}, \\lambda, E) \\rVert - L_{N_0} (\\lambda, E)  \\bigr|\n> \\frac{1}{20} \\, S(\\lambda) \\, ]  < N_0^{- C}$$*\n\n*Furthermore, for these $\\lambda$, $N_0$ and for all $E$ we have: $$\\begin{aligned}\n L_{N_0} (\\lambda, E) \\geq \\frac{1}{2} \\, S(\\lambda)  \\label{step10}  \\\\\n L_{N_0} (\\lambda, E) -  L_{2 N_0} (\\lambda, E) \\leq  \\frac{1}{80} \\, S(\\lambda)  \\label{step100}\n\\end{aligned}$$*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* The proof of this result is similar to the analytic potential function case. That is because the only fact about analyticity needed here is the Łojasiewicz inequality <a href=\"#loj\" data-reference-type=\"eqref\" data-reference=\"loj\">[loj]</a>, which holds for any non-constant analytic functions, and which we have established in section <a href=\"#lojasiewicz\" data-reference-type=\"ref\" data-reference=\"lojasiewicz\">5</a> for smooth functions satisfying the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>. We will then omit the proof, but the reader is referred to the proof of Lemma 2.10 in for details. ◻\n\n</div>\n\nWe will now explain the idea of the proof of the inductive step.",
    "labels": [
      "base-step",
      "step1",
      "step10",
      "step100"
    ],
    "refs": [
      "TC",
      "loj",
      "lojasiewicz"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L958-973::s22",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L725-734::s2",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 725,
    "end_line": 734,
    "text": "We will now explain the idea of the proof of the inductive step.\n\nIf at scale $N_0$ we apply the almost invariance property (<a href=\"#mshift\" data-reference-type=\"ref\" data-reference=\"mshift\">[mshift]</a>) $n$ times and then average, we get: $$\\label{mshift2}\n \\bigl|  L_{N_0} (\\underline{x})  -  \\frac{1}{n} \\sum_{j = 0}^{n-1}  L_{N_0} ({\\rm T}^j \\underline{x})  \\bigr|  \\lesssim\\frac{n S(\\lambda)}{N_0}$$ so using the approximation <a href=\"#aproxu\" data-reference-type=\"eqref\" data-reference=\"aproxu\">[aproxu]</a>, we also get: $$\\label{mshift3}\n \\bigl|  u_{N_0} (\\underline{x})  -  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u_{N_0} ({\\rm T}^j \\underline{x})  \\bigr|  \\lesssim\\frac{n S(\\lambda)}{N_0}$$\n\nTo have a decay above, we need to take a smaller number of shifts $n \\ll N_0$.\n\nApply the estimate (<a href=\"#shiftldt\" data-reference-type=\"ref\" data-reference=\"shiftldt\">[shiftldt]</a>) on averages of shifts of pluri-subharmonic functions to $u_{N_0} (x)$ and get: $$\\label{shiftldt2} \n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 : | \\, \\frac{1}{n} \\sum_{j = 0}^{n-1}  u_{N_0} ({\\rm T}^j \\underline{x})  \\, -  \\left< u_{N_0} \\right>   | > \\frac{S}{\\rho_{N_0}} \\, n^{- \\tau_0} ] < \ne^{- n^{\\sigma_0}}$$",
    "labels": [
      "mshift2",
      "mshift3",
      "shiftldt2"
    ],
    "refs": [
      "aproxu",
      "mshift",
      "shiftldt"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L737-745::s4",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L746-759::s5",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L735-736::s3",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 735,
    "end_line": 736,
    "text": "Apply the estimate (<a href=\"#shiftldt\" data-reference-type=\"ref\" data-reference=\"shiftldt\">[shiftldt]</a>) on averages of shifts of pluri-subharmonic functions to $u_{N_0} (x)$ and get: $$\\label{shiftldt2} \n\\mbox{mes }[ \\underline{x}\\in \\mathbb{T}^2 : | \\, \\frac{1}{n} \\sum_{j = 0}^{n-1}  u_{N_0} ({\\rm T}^j \\underline{x})  \\, -  \\left< u_{N_0} \\right>   | > \\frac{S}{\\rho_{N_0}} \\, n^{- \\tau_0} ] < \ne^{- n^{\\sigma_0}}$$\n\nWe may combine <a href=\"#mshift3\" data-reference-type=\"eqref\" data-reference=\"mshift3\">[mshift3]</a>, <a href=\"#shiftldt2\" data-reference-type=\"eqref\" data-reference=\"shiftldt2\">[shiftldt2]</a> to directly obtain a large deviation estimate for $u_{N_0} (x)$ and then, via the approximations <a href=\"#aproxu\" data-reference-type=\"eqref\" data-reference=\"aproxu\">[aproxu]</a>, <a href=\"#aprox&lt;u&gt;\" data-reference-type=\"eqref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a> to obtain the LDT for $L_{N_0} (x)$, *only* when the deviation $\\frac{S}{\\rho_{N_0}} n^{- \\tau_0}  \\ll 1$. In other words, this approach works only when the scaling factor $\\frac{S}{\\rho_{N_0}}$ is not too large to cancel the decay $n^{- \\tau_0}$. This is the case of the single or multi-frequency shift model with *analytic* potential (see , ) where $\\frac{S}{\\rho_{N_0}} = \\frac{S}{\\rho}$ is just a constant depending on the potential function $v$. This approach also works for the *single*-frequency model with potential function in a Gevrey class of order $s<2$, since in this case sharper estimates than (<a href=\"#shiftldt2\" data-reference-type=\"ref\" data-reference=\"shiftldt2\">[shiftldt2]</a>) are available for averages of shifts of single-variable subharmonic functions (see ). This approach fails for the skew-shift model (whether the potential function is analytic or Gevrey) and also for the multi-frequency model with Gevrey potential function, because the size $\\rho_{N_0}$ of the subharmonic extension depends on the scale $N_0$.",
    "labels": [
      "shiftldt2"
    ],
    "refs": [
      "aprox&lt;u&gt;",
      "aproxu",
      "mshift3",
      "shiftldt",
      "shiftldt2"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L737-745::s4",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L737-745::s4",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L746-759::s5",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L737-745::s4",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 737,
    "end_line": 745,
    "text": "We may combine <a href=\"#mshift3\" data-reference-type=\"eqref\" data-reference=\"mshift3\">[mshift3]</a>, <a href=\"#shiftldt2\" data-reference-type=\"eqref\" data-reference=\"shiftldt2\">[shiftldt2]</a> to directly obtain a large deviation estimate for $u_{N_0} (x)$ and then, via the approximations <a href=\"#aproxu\" data-reference-type=\"eqref\" data-reference=\"aproxu\">[aproxu]</a>, <a href=\"#aprox&lt;u&gt;\" data-reference-type=\"eqref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a> to obtain the LDT for $L_{N_0} (x)$, *only* when the deviation $\\frac{S}{\\rho_{N_0}} n^{- \\tau_0}  \\ll 1$. In other words, this approach works only when the scaling factor $\\frac{S}{\\rho_{N_0}}$ is not too large to cancel the decay $n^{- \\tau_0}$. This is the case of the single or multi-frequency shift model with *analytic* potential (see , ) where $\\frac{S}{\\rho_{N_0}} = \\frac{S}{\\rho}$ is just a constant depending on the potential function $v$. This approach also works for the *single*-frequency model with potential function in a Gevrey class of order $s<2$, since in this case sharper estimates than (<a href=\"#shiftldt2\" data-reference-type=\"ref\" data-reference=\"shiftldt2\">[shiftldt2]</a>) are available for averages of shifts of single-variable subharmonic functions (see ). This approach fails for the skew-shift model (whether the potential function is analytic or Gevrey) and also for the multi-frequency model with Gevrey potential function, because the size $\\rho_{N_0}$ of the subharmonic extension depends on the scale $N_0$.\n\nTherefore, in order to beat the scaling factor $\\frac{S}{\\rho_{N_0}}$ when applying the estimate (<a href=\"#shiftldt2\" data-reference-type=\"ref\" data-reference=\"shiftldt2\">[shiftldt2]</a>) to a transfer matrix substitute $u_{N_0} (\\underline{x})$ at scale $N_0$, we need to consider a large number of shifts $n \\gg N_0$. The averages of shifts thus obtained will be close to the mean $\\left< u_{N_0} \\right>$. Moreover, we will get: $$\\begin{aligned}\n L_{N_0}\\overset{(1)}\\approx \\, \\left< u_{N_0}  \\right> \\, \\overset{(2)} \\approx  \\frac{1}{n} \\sum_{j = 0}^{n-1}  u_{N_0} ({\\rm T}^j \\underline{x}) \\\\\n \\overset{(3)} \\approx  \\, \\frac{1}{n} \\sum_{j = 0}^{n-1}  \\frac{1}{N_0} \\log \\lVert M_{N_0} ({\\rm T}^j \\underline{x}) \\rVert \\overset{(4)} \\approx \\, \n  \\frac{1}{n N_0} \\log \\lVert M_{n N_0} (\\underline{x}) \\rVert\n\n\\end{aligned}$$\n\nThe first approximation above is just (<a href=\"#aprox&lt;u&gt;\" data-reference-type=\"ref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a>). The second is exactly (<a href=\"#shiftldt2\" data-reference-type=\"ref\" data-reference=\"shiftldt2\">[shiftldt2]</a>). The third is due to (<a href=\"#aproxu\" data-reference-type=\"ref\" data-reference=\"aproxu\">[aproxu]</a>). The last approximation above essentially says that: $$\\prod_{j=0}^{n-1}  \\lVert M_{N_0} ({\\rm T}^j \\underline{x}) \\rVert \\approx \\lVert \\prod_{j=0}^{n-1}   M_{N_0} ({\\rm T}^j \\underline{x}) \\rVert \\approx \\lVert   M_{n N_0} (\\underline{x}) \\rVert$$ or in other words, that the product of the norms of certain transfer matrices is approximately equal to the norm of the product of these matrices, the latter giving us the transfer matrix at the larger scale $n N_0$.",
    "labels": [],
    "refs": [
      "aprox&lt;u&gt;",
      "aproxu",
      "mshift3",
      "shiftldt2"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L746-759::s5",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L746-759::s5",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 746,
    "end_line": 759,
    "text": "The first approximation above is just (<a href=\"#aprox&lt;u&gt;\" data-reference-type=\"ref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a>). The second is exactly (<a href=\"#shiftldt2\" data-reference-type=\"ref\" data-reference=\"shiftldt2\">[shiftldt2]</a>). The third is due to (<a href=\"#aproxu\" data-reference-type=\"ref\" data-reference=\"aproxu\">[aproxu]</a>). The last approximation above essentially says that: $$\\prod_{j=0}^{n-1}  \\lVert M_{N_0} ({\\rm T}^j \\underline{x}) \\rVert \\approx \\lVert \\prod_{j=0}^{n-1}   M_{N_0} ({\\rm T}^j \\underline{x}) \\rVert \\approx \\lVert   M_{n N_0} (\\underline{x}) \\rVert$$ or in other words, that the product of the norms of certain transfer matrices is approximately equal to the norm of the product of these matrices, the latter giving us the transfer matrix at the larger scale $n N_0$.\n\nIf these heuristics were true, then for $n \\gg N_0$ we would get $$L_{N_0} \\approx  \\frac{1}{n N_0} \\log \\lVert M_{n N_0} (\\underline{x}) \\rVert$$ which would establish the large deviation estimate for transfer matrices at a larger scale $n N_0$.\n\nThe avalanche principle, which is a deterministic result, describes how estimates on the norms of individual (and of products of two consecutive) $SL_2 (\\mathbb{R})$ matrices can lead to estimates on the norm of the product of all matrices (see , ), thus providing the basis for establishing the above heuristics. It requires a uniform lower bound on the norms of individual matrices in the product, as well as knowing that the norm of the product of any two consecutive matrices is comparable to the product of their norms.\n\nThe following lemma provides the inductive step in proving the LDT for an increasing sequence of scales $N$. It also provides the inductive step in proving the positivity and continuity of the Lyapunov exponent. The proof of this lemma is based on the heuristics described above, and combines the averages of shifts estimate (<a href=\"#shiftldt\" data-reference-type=\"ref\" data-reference=\"shiftldt\">[shiftldt]</a>), the almost invariance property (<a href=\"#mshift\" data-reference-type=\"ref\" data-reference=\"mshift\">[mshift]</a>) and the avalanche principle (see Proposition 2.2 in ).\n\nBefore stating the lemma let us describe the various parameters and constants that will appear.\n\n**List of constants and parameters:**\n\n$\\rule[.2ex]{.4ex}{.4ex}$ $s > 1$ is the order of the Gevrey class.\n\n$\\rule[.2ex]{.4ex}{.4ex}$ $\\delta = 2 (s-1)$ refers to the size ($\\approx N^{-\\delta}$) of the holomorphic extensions of the transfer matrix substitutes.",
    "labels": [],
    "refs": [
      "aprox&lt;u&gt;",
      "aproxu",
      "mshift",
      "shiftldt",
      "shiftldt2"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L737-745::s4",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L725-734::s2",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L735-736::s3",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L760-778::s6",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 760,
    "end_line": 778,
    "text": "$\\rule[.2ex]{.4ex}{.4ex}$ $\\delta = 2 (s-1)$ refers to the size ($\\approx N^{-\\delta}$) of the holomorphic extensions of the transfer matrix substitutes.\n\n$\\rule[.2ex]{.4ex}{.4ex}$ $D := 2 \\delta + 8$, $A := \\max \\{\\frac{2 \\, (\\delta+1)}{\\tau_0}, \\, 2 \\}$ are some well chosen powers of the scale $N$, $\\tau_0$ is the exponent from (<a href=\"#shiftldt\" data-reference-type=\"ref\" data-reference=\"shiftldt\">[shiftldt]</a>).\n\n$\\rule[.2ex]{.4ex}{.4ex}$ $\\gamma > \\frac{1}{4}$ is a fixed number.\n\nNote that all these constants are either universal or depend on the order $s$ of the Gevrey class.\n\n$\\rule[.2ex]{.4ex}{.4ex}$ $\\lambda$, $E$ are fixed parameters such that $\\bigl| E \\bigr|  \\le \\bigl| \\lambda \\bigr|  B + 2$, and $\\displaystyle  B := \\sup_{ \\underline{x}\\in \\mathbb{T}} \\bigl| v (\\underline{x}) \\bigr|$.\n\n$\\rule[.2ex]{.4ex}{.4ex}$ The transformation ${\\rm T}= {\\rm S}_\\omega$ where $\\omega\\in DC_{\\kappa}$ or ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$ where $\\underline{\\omega}\\in DC_{\\kappa}$ for some $\\kappa > 0$.\n\n$\\rule[.2ex]{.4ex}{.4ex}$ $N_{0 0} = N_{0 0} (s, \\kappa, B)$ is a sufficiently large integer, such that the asymptotic behavior of various powers and exponentials applies to $N_{0 0}$ and such that (<a href=\"#shiftldt\" data-reference-type=\"ref\" data-reference=\"shiftldt\">[shiftldt]</a>) holds for $N_{0 0}$ shifts.\n\n<div id=\"ind\" class=\"lemma\">\n\n**Lemma 9**. *(The inductive step)Consider two scales $N_0$ and $N$ such that $N_0 \\geq N_{0 0}$, (<a href=\"#aproxu\" data-reference-type=\"ref\" data-reference=\"aproxu\">[aproxu]</a>) holds at scale $N_0$, that is: $$\\label{scale2}\nN_0 \\geq S (\\lambda) \\hspace{.1in} \\Leftrightarrow \\hspace{.1in} \n| \\lambda | \\leq e^{ N_0}$$ and $$\\label{scale1} \nN_{0}^{A} \\leq N \\leq  e^{N_0}$$*",
    "labels": [
      "ind",
      "scale1",
      "scale2"
    ],
    "refs": [
      "aproxu",
      "shiftldt"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L746-759::s5",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L897-909::s17",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L958-973::s22",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L779-798::s7",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 779,
    "end_line": 798,
    "text": "**Lemma 9**. *(The inductive step)Consider two scales $N_0$ and $N$ such that $N_0 \\geq N_{0 0}$, (<a href=\"#aproxu\" data-reference-type=\"ref\" data-reference=\"aproxu\">[aproxu]</a>) holds at scale $N_0$, that is: $$\\label{scale2}\nN_0 \\geq S (\\lambda) \\hspace{.1in} \\Leftrightarrow \\hspace{.1in} \n| \\lambda | \\leq e^{ N_0}$$ and $$\\label{scale1} \nN_{0}^{A} \\leq N \\leq  e^{N_0}$$*\n\n*Assume that a weak LDT holds at scales $N_0$ and $2 N_0$: $$\\label{indhyp1}\n\\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{N_0} \\log \\lVert M_{N_0} (\\underline{x}, \\lambda, E ) \\rVert - L_{N_0} (\\lambda, E )  \\bigr| >  \\frac{\\gamma}{10} S (\\lambda) ]  <  N^{- D}$$ $$\\label{indhyp2}\n \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{2 N_0} \\log \\lVert M_{2 N_0} (\\underline{x}, \\lambda, E ) \\rVert - L_{2 N_0} (\\lambda, E )  \\bigr|  >   \\frac{\\gamma}{10}S (\\lambda) ]  <  N^{- D}$$ and that the means $L_{N_0}$, $L_{2 N_0}$ have a lower bound and are close to each other: $$\\begin{aligned}\n L_{ N_0} (\\lambda, E ), \\, L_{2 N_0} (\\lambda, E ) \\geq & \\gamma S(\\lambda) \\label{indhyp3} \\\\\n L_{ N_0} (\\lambda, E ) -  L_{2 N_0} (\\lambda, E ) \\leq  & \\frac{\\gamma}{40}S (\\lambda) \\label{indhyp4}\n\\end{aligned}$$*\n\n*Then similar (but stronger) estimates hold at the larger scale $N$: $$\\label{indc3}\n \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}, \\lambda, E ) \\rVert - L_{N} (\\lambda, E )  \\bigr|  >  S( \\lambda )  N^{-\\tau} ]  <   e^{-N^\\sigma}$$ $$\\begin{aligned}\nL_{N} (\\lambda, E ) & \\geq & \\gamma S(\\lambda)  \\label{indc1} \\\\\n& & - 2 [  L_{ N_0} (\\lambda, E ) -  L_{2 N_0} (\\lambda, E ) ] - C_{0} S (\\lambda) N_{0} N^{-1} \\notag \\\\\nL_{ N} (\\lambda, E ) -  L_{2 N} (\\lambda, E ) & \\leq & C_{0} S (\\lambda) N_{0} N^{-1} \\label{indc2}\n\\end{aligned}$$ for some positive absolute constants $C_0, \\tau, \\sigma$.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* The parameters $\\lambda$, $E$ and the transformation ${\\rm T}= {\\rm S}_\\omega$ or ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$ are fixed, so they can be suppressed from notations. For instance $M_N (\\underline{x}) = M_N (\\underline{x}, \\lambda, E)$, $S(\\lambda) = S$ etc.",
    "labels": [
      "indc1",
      "indc2",
      "indc3",
      "indhyp1",
      "indhyp2",
      "indhyp3",
      "indhyp4",
      "scale1",
      "scale2"
    ],
    "refs": [
      "aproxu"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L799-806::s8",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L799-806::s8",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L836-845::s11",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L897-909::s17",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L920-935::s19",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L799-806::s8",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 799,
    "end_line": 806,
    "text": "*Proof.* The parameters $\\lambda$, $E$ and the transformation ${\\rm T}= {\\rm S}_\\omega$ or ${\\rm T}= {\\rm T}_{\\underline{\\omega}}$ are fixed, so they can be suppressed from notations. For instance $M_N (\\underline{x}) = M_N (\\underline{x}, \\lambda, E)$, $S(\\lambda) = S$ etc.\n\n$\\rule[.2ex]{.8ex}{.8ex}$ We can assume without loss of generality that $N$ is a multiple of $N_0$, that is, that $N = n \\cdot N_0$. Indeed, if $N = n \\cdot N_0 + r$, $0 \\leq r <  N_0$, then $$\\label{N/N_0}\n \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert - \\frac{1}{n \\cdot N_0} \\log \\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert  \\bigr| \n \\leq 2 S N_0 N^{- 1}$$\n\nTherefore, if we prove (<a href=\"#indc1\" data-reference-type=\"ref\" data-reference=\"indc1\">[indc1]</a>), (<a href=\"#indc2\" data-reference-type=\"ref\" data-reference=\"indc2\">[indc2]</a>), (<a href=\"#indc3\" data-reference-type=\"ref\" data-reference=\"indc3\">[indc3]</a>) at scale $n \\cdot N_0$, then they hold at scale $N$ too.\n\nTo prove (<a href=\"#N/N_0\" data-reference-type=\"ref\" data-reference=\"N/N_0\">[N/N_0]</a>), first note that $M_N (\\underline{x}) = B (\\underline{x}) \\cdot M_{n \\cdot N_0} (\\underline{x})$, where $$B (\\underline{x}) := \\prod_{j=N}^{n \\cdot N_0 + 1} A ({\\rm T}^j \\underline{x}) = \\prod_{j=n \\cdot N_0 + r}^{n \\cdot N_0 + 1} A ({\\rm T}^j \\underline{x})$$ so $$\\lVert B (\\underline{x}) \\rVert   \\leq e^{r \\cdot S} \\leq e^{N_0 \\cdot S} \\mbox{  and   } \\, \\lVert B (\\underline{x}) ^{-1} \\rVert    \\leq e^{r \\cdot S} \\leq e^{N_0 \\cdot S}$$",
    "labels": [
      "N/N_0"
    ],
    "refs": [
      "N/N_0",
      "indc1",
      "indc2",
      "indc3"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L807-825::s9",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L807-825::s9",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L807-825::s9",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 807,
    "end_line": 825,
    "text": "To prove (<a href=\"#N/N_0\" data-reference-type=\"ref\" data-reference=\"N/N_0\">[N/N_0]</a>), first note that $M_N (\\underline{x}) = B (\\underline{x}) \\cdot M_{n \\cdot N_0} (\\underline{x})$, where $$B (\\underline{x}) := \\prod_{j=N}^{n \\cdot N_0 + 1} A ({\\rm T}^j \\underline{x}) = \\prod_{j=n \\cdot N_0 + r}^{n \\cdot N_0 + 1} A ({\\rm T}^j \\underline{x})$$ so $$\\lVert B (\\underline{x}) \\rVert   \\leq e^{r \\cdot S} \\leq e^{N_0 \\cdot S} \\mbox{  and   } \\, \\lVert B (\\underline{x}) ^{-1} \\rVert    \\leq e^{r \\cdot S} \\leq e^{N_0 \\cdot S}$$\n\nSince $\\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert \\geq 1$ and $\\lVert M_{N} (\\underline{x}) \\rVert \\geq 1$, it follows that: $$\\begin{aligned}\n  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert - \\frac{1}{n \\cdot N_0} \\log \\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert    = \n \\frac{1}{n \\cdot N_0} \\log \\frac{\\lVert M_{N} (\\underline{x}) \\rVert^{\\frac{n \\cdot N_0}{N}}}{\\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert} \\\\\n \\ \\leq   \\frac{1}{n \\cdot N_0} \\log \\frac{\\lVert B (\\underline{x}) \\rVert^{\\frac{n \\cdot N_0}{N}} \\cdot \\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert^{\\frac{n \\cdot N_0}{N}}}{\\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert}   \\\\\n\\  \\leq  \\frac{1}{n \\cdot N_0} \\log \\, (e^{N_0 S})^{\\frac{n \\cdot N_0}{N}} = S N_0 N^{- 1}\n\n\\end{aligned}$$\n\nSimilarly $$\\begin{aligned}\n \\frac{1}{n \\cdot N_0} \\log \\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert -  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert =\n\\frac{1}{n \\cdot N_0} \\log \\frac{|| M_{n \\cdot N_0} (\\underline{x})||}{ \\lVert M_{N} (\\underline{x}) \\rVert^{\\frac{n \\cdot N_0}{N}}} \n\\end{aligned}$$ $$\\begin{aligned}\n = & \\ \\frac{1}{n \\cdot N_0} \\, \\log \\; [ \\, \\Bigl( \\frac{\\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert}{|| M_N (\\underline{x}) ||} \\Bigr)^{\\frac{n \\cdot N_0}{N}} \\cdot \\, \\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert^{\\frac{r}{N}} \\, ] \\\\\n \\leq & \\ \\frac{1}{n \\cdot N_0} \\,  \\log \\; [ \\,\n\\lVert ( B (\\underline{x}) )^{-1} \\rVert^{\\frac{n \\cdot N_0}{N}} \\cdot \\lVert M_{n \\cdot N_0} (\\underline{x}) \\rVert^{\\frac{r}{N}} \\, ] \\\\\n \\leq & \\ \\frac{1}{n \\cdot N_0} \\, \\log \\; [ \\, (e^{ N_0 S})^{\\frac{n \\cdot N_0}{N}} \\cdot (e^{n  N_0 S})^{\\frac{N_0}{N}} ] \\, = 2 S N_0 N^{- 1}\n\n\\end{aligned}$$ and inequality (<a href=\"#N/N_0\" data-reference-type=\"ref\" data-reference=\"N/N_0\">[N/N_0]</a>) now follows.",
    "labels": [],
    "refs": [
      "N/N_0"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L799-806::s8",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L799-806::s8",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L826-835::s10",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 826,
    "end_line": 835,
    "text": "\\end{aligned}$$ and inequality (<a href=\"#N/N_0\" data-reference-type=\"ref\" data-reference=\"N/N_0\">[N/N_0]</a>) now follows.\n\n$\\rule[.2ex]{.8ex}{.8ex}$ We are going to show that (<a href=\"#scale1\" data-reference-type=\"ref\" data-reference=\"scale1\">[scale1]</a>) - (<a href=\"#indhyp4\" data-reference-type=\"ref\" data-reference=\"indhyp4\">[indhyp4]</a>) allow us to apply the avalanche principle to the “blocks” $M_{N_0} ({\\rm T}^{(j-1) N_0} \\, \\underline{x})$, for $j = \\overline{1, n}$. Each of these blocks is a product of $N_0$ matrices, and they multiply up to $M_N (\\underline{x})$.\n\nDenote the set in (<a href=\"#indhyp1\" data-reference-type=\"ref\" data-reference=\"indhyp1\">[indhyp1]</a>) by $B_{N_0}$ and similarly the set in (<a href=\"#indhyp2\" data-reference-type=\"ref\" data-reference=\"indhyp2\">[indhyp2]</a>) by $B_{2 N_0}$.  \nIf $\\underline{x}\\notin B_{N_0}$ then using (<a href=\"#indhyp1\" data-reference-type=\"ref\" data-reference=\"indhyp1\">[indhyp1]</a>), (<a href=\"#indhyp3\" data-reference-type=\"ref\" data-reference=\"indhyp3\">[indhyp3]</a>) and <a href=\"#scale1\" data-reference-type=\"eqref\" data-reference=\"scale1\">[scale1]</a> we get $$\\lVert M_{N_0} (\\underline{x}) \\rVert >  e^{- \\frac{\\gamma}{10} S  N_{0} +  L_{N_0} \\cdot \\, N_0 } \\geq e^{\\frac{9 \\gamma}{10} S  N_{0} } =: \\mu > e^{N_0}  \\geq N > n$$ so $$\\label{avalp1}\n \\lVert M_{N_0} (\\underline{x}) \\rVert \\geq \\mu \\geq n \\hspace{.2in} \\mbox{ if } \\underline{x}\\notin B_{N_0}$$\n\nFor $1 \\leq j \\leq n = \\frac{N}{N_0}$ consider $A_{j} = A_{j} (\\underline{x}) := M_{N_0} ({\\rm T}^{(j-1) N_0} \\underline{x})$. Then (<a href=\"#avalp1\" data-reference-type=\"ref\" data-reference=\"avalp1\">[avalp1]</a>) implies $$\\label{avalpp1}\n\\min_{1 \\leq j \\leq n} \\lVert A_{j} (\\underline{x}) \\rVert\\geq \\mu  \\hspace{.2in} \\mbox{ for all } \n x \\notin \\bigcup _{j=0}^{n} {\\rm T}^{ - j N_0}  B_{N_0}$$",
    "labels": [
      "avalp1",
      "avalpp1"
    ],
    "refs": [
      "N/N_0",
      "avalp1",
      "indhyp1",
      "indhyp2",
      "indhyp3",
      "indhyp4",
      "scale1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L807-825::s9",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L836-845::s11",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L799-806::s8",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L836-845::s11",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L846-858::s12",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L836-845::s11",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 836,
    "end_line": 845,
    "text": "For $1 \\leq j \\leq n = \\frac{N}{N_0}$ consider $A_{j} = A_{j} (\\underline{x}) := M_{N_0} ({\\rm T}^{(j-1) N_0} \\underline{x})$. Then (<a href=\"#avalp1\" data-reference-type=\"ref\" data-reference=\"avalp1\">[avalp1]</a>) implies $$\\label{avalpp1}\n\\min_{1 \\leq j \\leq n} \\lVert A_{j} (\\underline{x}) \\rVert\\geq \\mu  \\hspace{.2in} \\mbox{ for all } \n x \\notin \\bigcup _{j=0}^{n} {\\rm T}^{ - j N_0}  B_{N_0}$$\n\nSince $A_{j+1} (\\underline{x}) \\cdot A_{j} (\\underline{x}) =  M_{2 N_0} ({\\rm T}^{(j-1) N_0} \\underline{x})$, using (<a href=\"#indhyp1\" data-reference-type=\"ref\" data-reference=\"indhyp1\">[indhyp1]</a>), (<a href=\"#indhyp2\" data-reference-type=\"ref\" data-reference=\"indhyp2\">[indhyp2]</a>), (<a href=\"#indhyp4\" data-reference-type=\"ref\" data-reference=\"indhyp4\">[indhyp4]</a>), for $\\underline{x}\\notin  \\bigcup _{j=0}^{n} ({\\rm T}^{ - j N_0}  B_{N_0}) \\cup   \\bigcup _{j=0}^{n} ({\\rm T}^{ - j N_0}  B_{2 N_0})$ (which is a set of measure  \n$< 2 N^{- D} \\cdot N = 2 N^{- D + 1}$), we have : $$\\begin{aligned}\n \\log \\lVert A_{j+1} (\\underline{x}) \\rVert +  \\log \\lVert A_{j} (\\underline{x}) \\rVert- \\log \\lVert A_{j+1}(\\underline{x}) \\cdot A_{j}(\\underline{x}) \\rVert\\\\\n  = \\log \\lVert M_{N_0} ({\\rm T}^{j N_0} \\underline{x}) \\rVert + \\log \\lVert M_{N_0} ({\\rm T}^{(j-1) N_0} \\underline{x}) \\rVert - \\log \\lVert M_{2 N_0} ({\\rm T}^{(j-1) N_0} \\underline{x}) \\rVert  \\\\\n  \\leq  N_{0} (  L_{N_0} + \\frac{S \\gamma}{10} ) +  N_{0} (  L_{N_0} + \\frac{S \\gamma}{10} ) + 2 N_{0} (\\frac{S \\gamma}{10} -  L_{2 N_0}) \\\\\n =  2 N_{0} (  L_{N_0} -   L_{2 N_0}) +  \\frac{4 S \\gamma}{10} N_{0} \\leq  \\frac{9 S \\gamma}{20} N_{0} = \\frac{1}{2} \\log \\mu\n\n\\end{aligned}$$ Therefore, $$\\label{avalpp2}\n \\log \\lVert A_{j+1}(\\underline{x}) \\rVert +  \\log \\lVert A_{j}(\\underline{x}) \\rVert - \\log \\lVert A_{j+1}(\\underline{x}) \\cdot A_{j}(\\underline{x}) \\rVert \\leq  \\frac{1}{2} \\log \\mu$$ for $\\underline{x}$ outside a set of measure $< 2 N^{- D + 1}$.",
    "labels": [
      "avalpp1",
      "avalpp2"
    ],
    "refs": [
      "avalp1",
      "indhyp1",
      "indhyp2",
      "indhyp4"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L846-858::s12",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L846-858::s12",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L846-858::s12",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 846,
    "end_line": 858,
    "text": "\\end{aligned}$$ Therefore, $$\\label{avalpp2}\n \\log \\lVert A_{j+1}(\\underline{x}) \\rVert +  \\log \\lVert A_{j}(\\underline{x}) \\rVert - \\log \\lVert A_{j+1}(\\underline{x}) \\cdot A_{j}(\\underline{x}) \\rVert \\leq  \\frac{1}{2} \\log \\mu$$ for $\\underline{x}$ outside a set of measure $< 2 N^{- D + 1}$.\n\nEstimates <a href=\"#avalpp1\" data-reference-type=\"eqref\" data-reference=\"avalpp1\">[avalpp1]</a>, <a href=\"#avalpp2\" data-reference-type=\"eqref\" data-reference=\"avalpp2\">[avalpp2]</a> are exactly the assumptions in the avalanche principle (Proposition 2.2 in ). We then conclude: $$\\label{avalpp3}\n \\bigl|  \\log \\lVert A_{n}(\\underline{x}) \\cdot \\dotsc \\cdot A_{1}(\\underline{x}) \\rVert + \\sum_{j=2}^{n-1} \\log \\lVert A_{j}(\\underline{x}) \\rVert  - \\sum_{j=1}^{n-1} \\log \\lVert A_{j+1}(\\underline{x}) \\cdot A_{j}(\\underline{x}) \\rVert  \\bigr| \\lesssim \\frac{n}{\\mu}$$ for $\\underline{x}$ outside a set of measure $< 2 N^{- D + 1}$.\n\nHence, since $N = n \\cdot N_0$ and $A_{n}(\\underline{x}) \\cdot \\dotsc \\cdot A_{1}(\\underline{x}) =  M_{N} (\\underline{x})$, we have: $$\\begin{aligned}\n\\bigl|  \\log \\lVert M_{N} (\\underline{x}) \\rVert +  \\sum_{j=2}^{n-1} \\log \\lVert M_{N_0} ({\\rm T}^{(j-1) N_0} \\underline{x}) \\rVert \\\\\n - \\sum_{j=1}^{n-1} \\log \\lVert M_{2 N_0} ({\\rm T}^{(j-1) N_0} \\underline{x})\\rVert  \\bigr| \\,   \\lesssim \\frac{n}{\\mu}\n\\end{aligned}$$\n\nTherefore $$\\begin{aligned}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert +  \\frac{1}{n} \\sum_{j=2}^{n-1} \\frac{1}{N_0} \\log \\lVert M_{N_0} ({\\rm T}^{(j-1) N_0}  \\underline{x}) \\rVert \\notag \\\\\n - \\frac{2}{n} \\sum_{j=1}^{n-1} \\frac{1}{2 N_0} \\log \\lVert M_{2 N_0} ({\\rm T}^{(j-1) N_0} \\underline{x}) \\rVert  \\bigr|   \\lesssim  \\frac{1}{\\mu} \\label{9}\n\\end{aligned}$$",
    "labels": [
      "9",
      "avalpp2",
      "avalpp3"
    ],
    "refs": [
      "avalpp1",
      "avalpp2"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L836-845::s11",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L859-867::s13",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L826-835::s10",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L836-845::s11",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L859-867::s13",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L859-867::s13",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 859,
    "end_line": 867,
    "text": "Therefore $$\\begin{aligned}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert +  \\frac{1}{n} \\sum_{j=2}^{n-1} \\frac{1}{N_0} \\log \\lVert M_{N_0} ({\\rm T}^{(j-1) N_0}  \\underline{x}) \\rVert \\notag \\\\\n - \\frac{2}{n} \\sum_{j=1}^{n-1} \\frac{1}{2 N_0} \\log \\lVert M_{2 N_0} ({\\rm T}^{(j-1) N_0} \\underline{x}) \\rVert  \\bigr|   \\lesssim  \\frac{1}{\\mu} \\label{9}\n\\end{aligned}$$\n\n$\\rule[.2ex]{.8ex}{.8ex}$ We will go from averages of $n$ blocks in (<a href=\"#9\" data-reference-type=\"ref\" data-reference=\"9\">[9]</a>), to averages of $N$ shifts. In (<a href=\"#9\" data-reference-type=\"ref\" data-reference=\"9\">[9]</a>) replace $\\underline{x}$ by $\\underline{x}, {\\rm T}\\underline{x}, \\dotsc {\\rm T}^{N_{0}-1} \\underline{x}$ and then average (i.e. add up all these $N_0$ inequalities and divide by $N_0$) to get: $$\\begin{aligned}\n\\bigl|  \\frac{1}{N_0} \\sum_{j=0}^{N_{0}-1} \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}^{j} \\underline{x}) \\rVert  +  \n\\frac{1}{N} \\sum_{j=0}^{N-1} \\frac{1}{N_0} \\log \\lVert M_{N_0} ({\\rm T}^{j} \\underline{x}) \\rVert\\notag \\\\\n-  \\frac{2}{N} \\sum_{j=0}^{N-1} \\frac{1}{2 N_0} \\log \\lVert M_{2 N_0} ({\\rm T}^{j} \\underline{x}) \\rVert  \\bigr|   \\lesssim   \\frac{1}{\\mu} \\label{90}\n\\end{aligned}$$\n\nThe almost invariance property - Lemma (<a href=\"#mshift\" data-reference-type=\"ref\" data-reference=\"mshift\">[mshift]</a>) implies: $$\\label{900}\n \\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert -  \\frac{1}{N_0} \\sum_{j=0}^{N_{0}-1} \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}^{j} \\underline{x}) \\rVert  \\bigr|\\lesssim \\frac{S N_0}{N}$$",
    "labels": [
      "9",
      "90",
      "900"
    ],
    "refs": [
      "9",
      "mshift"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L846-858::s12",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L846-858::s12",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L868-880::s14",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 868,
    "end_line": 880,
    "text": "The almost invariance property - Lemma (<a href=\"#mshift\" data-reference-type=\"ref\" data-reference=\"mshift\">[mshift]</a>) implies: $$\\label{900}\n \\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert -  \\frac{1}{N_0} \\sum_{j=0}^{N_{0}-1} \\frac{1}{N} \\log \\lVert M_{N} ({\\rm T}^{j} \\underline{x}) \\rVert  \\bigr|\\lesssim \\frac{S N_0}{N}$$\n\nFrom (<a href=\"#90\" data-reference-type=\"ref\" data-reference=\"90\">[90]</a>) and (<a href=\"#900\" data-reference-type=\"ref\" data-reference=\"900\">[900]</a>) we get: $$\\begin{aligned}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert + \n\\frac{1}{N} \\sum_{j=0}^{N-1} \\frac{1}{N_0} \\log \\lVert M_{N_0} ({\\rm T}^{j} \\underline{x}) \\rVert \\notag \\\\\n-  \\frac{2}{N} \\sum_{j=0}^{N-1} \\frac{1}{2 N_0} \\log \\lVert  M_{2 N_0} ({\\rm T}^{j} \\underline{x}) \\rVert  \\bigr|   \\lesssim   \\frac{S N_0}{N} + \\frac{1}{\\mu} \\,  \\lesssim S N_0 N^{- 1} \\label{10}\n\\end{aligned}$$ for $\\underline{x}\\notin  B_1 := \\bigcup _{j=0}^{N} (T^{ - j }  B_{N_0}) \\cup   \\bigcup _{j=0}^{n} (T^{ - j }  B_{2 N_0})$ where $\\mbox{mes }[ B_1 ] < 2 N^{- D + 1}$.\n\nIntegrating the left hand side of (<a href=\"#10\" data-reference-type=\"ref\" data-reference=\"10\">[10]</a>) in $\\underline{x}$, we get: $$\\begin{aligned}\n \\bigl|   L_{N} +  L_{N_0} - 2  L_{2 N_0}  \\bigr| & < C S N_0 N^{-1}  + 4 S \\cdot 2 N^{- D + 1}  <  C_{0} S N_0 N^{-1} \\label{11}\\\\\nL_{N} +  L_{N_0} - 2  L_{2 N_0} & > -  C_0  S N_0 N^{-1} \\notag \\\\\nL_{N} & >  L_{N_0} -  2 (  L_{ N_0} -  L_{2 N_0} ) - C_{0} S N_{0} N^{-1} \\notag \\\\\n& >  \\gamma S  -  2 (  L_{ N_0} -  L_{2 N_0} ) - C_{0} S N_{0} N^{-1} \\notag \n\\end{aligned}$$ which proves <a href=\"#indc1\" data-reference-type=\"eqref\" data-reference=\"indc1\">[indc1]</a>.",
    "labels": [
      "10",
      "11",
      "900"
    ],
    "refs": [
      "10",
      "90",
      "900",
      "indc1",
      "mshift"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L859-867::s13",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L859-867::s13",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L881-885::s15",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 881,
    "end_line": 885,
    "text": "Integrating the left hand side of (<a href=\"#10\" data-reference-type=\"ref\" data-reference=\"10\">[10]</a>) in $\\underline{x}$, we get: $$\\begin{aligned}\n \\bigl|   L_{N} +  L_{N_0} - 2  L_{2 N_0}  \\bigr| & < C S N_0 N^{-1}  + 4 S \\cdot 2 N^{- D + 1}  <  C_{0} S N_0 N^{-1} \\label{11}\\\\\nL_{N} +  L_{N_0} - 2  L_{2 N_0} & > -  C_0  S N_0 N^{-1} \\notag \\\\\nL_{N} & >  L_{N_0} -  2 (  L_{ N_0} -  L_{2 N_0} ) - C_{0} S N_{0} N^{-1} \\notag \\\\\n& >  \\gamma S  -  2 (  L_{ N_0} -  L_{2 N_0} ) - C_{0} S N_{0} N^{-1} \\notag \n\\end{aligned}$$ which proves <a href=\"#indc1\" data-reference-type=\"eqref\" data-reference=\"indc1\">[indc1]</a>.\n\nClearly all the arguments above work for $N$ replaced by $2 N$, so we get the analogue of (<a href=\"#11\" data-reference-type=\"ref\" data-reference=\"11\">[11]</a>) : $$\\label{111} \n\\bigl|   L_{2 N} +  L_{N_0} - 2  L_{2 N_0}  \\bigr|  <  C_{0} S N_0 N^{-1}$$ From (<a href=\"#11\" data-reference-type=\"ref\" data-reference=\"11\">[11]</a>) and (<a href=\"#111\" data-reference-type=\"ref\" data-reference=\"111\">[111]</a>) we obtain $$L_{N} -  L_{2 N} \\leq  C_{0} S N_0 N^{-1}$$ which is exactly (<a href=\"#indc2\" data-reference-type=\"ref\" data-reference=\"indc2\">[indc2]</a>).\n\n$\\rule[.2ex]{.8ex}{.8ex}$ To prove the LDT (<a href=\"#indc3\" data-reference-type=\"ref\" data-reference=\"indc3\">[indc3]</a>) at scale $N$, we are going to apply the estimate <a href=\"#shiftldt\" data-reference-type=\"eqref\" data-reference=\"shiftldt\">[shiftldt]</a> on averages of shifts of pluri-subharmonic functions to the transfer matrix substitutes $u_{N_0}$ and $u_{2 N_0}$. Their widths of subharmonicity in each variable are $\\rho_{N_0},  \\rho_{2 N_0} \\approx N_0^{- \\delta-1}$ and they are uniformly bounded by $S$.",
    "labels": [
      "11",
      "111"
    ],
    "refs": [
      "10",
      "11",
      "111",
      "indc1",
      "indc2",
      "indc3",
      "shiftldt"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L886-896::s16",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 886,
    "end_line": 896,
    "text": "$\\rule[.2ex]{.8ex}{.8ex}$ To prove the LDT (<a href=\"#indc3\" data-reference-type=\"ref\" data-reference=\"indc3\">[indc3]</a>) at scale $N$, we are going to apply the estimate <a href=\"#shiftldt\" data-reference-type=\"eqref\" data-reference=\"shiftldt\">[shiftldt]</a> on averages of shifts of pluri-subharmonic functions to the transfer matrix substitutes $u_{N_0}$ and $u_{2 N_0}$. Their widths of subharmonicity in each variable are $\\rho_{N_0},  \\rho_{2 N_0} \\approx N_0^{- \\delta-1}$ and they are uniformly bounded by $S$.\n\nUsing (<a href=\"#aproxu\" data-reference-type=\"ref\" data-reference=\"aproxu\">[aproxu]</a>) which holds at scales $N_0$ and $2 N_0$ due to (<a href=\"#scale2\" data-reference-type=\"ref\" data-reference=\"scale2\">[scale2]</a>), we can ‘substitute’ in (<a href=\"#10\" data-reference-type=\"ref\" data-reference=\"10\">[10]</a>) $\\frac{1}{N_0} \\log \\lVert M_{N_0} ({\\rm T}^{j} (\\underline{x}) \\rVert$ by $u_{N_0} ({\\rm T}^j \\underline{x})$ and $\\frac{1}{2 N_0} \\log \\lVert M_{2 N_0} ({\\rm T}^{j} (\\underline{x}) \\rVert$ by $u_{2 N_0} ({\\rm T}^j \\underline{x})$ and get, for $\\underline{x}\\notin B_1$: $$\\label{12}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert +  \\frac{1}{N} \\sum_{j=0}^{N-1} u_{N_0}({\\rm T}^{j} \\underline{x}) -  \\frac{2}{N} \\sum_{j=0}^{N-1}  u_{2 N_0}({\\rm T}^{j} \\underline{x})  \\bigr| \\lesssim S N_0 N^{-1}$$\n\nApplying (<a href=\"#shiftldt\" data-reference-type=\"ref\" data-reference=\"shiftldt\">[shiftldt]</a>) to $u_{N_0}$ and $u_{2 N_0}$ we get : $$\\label{13}\n\\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|  \\frac{1}{N} \\sum_{j=0}^{N-1} u_{N_0}({\\rm T}^{j} \\underline{x}) - \\left<  u_{N_0}  \\right>  \\bigr| >  \nS \\cdot N_{0}^{\\delta+1} \\cdot N^{- \\tau_0 } ] < e^{- N^{\\sigma_0}}$$ $$\\label{13'}\n\\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|  \\frac{1}{N} \\sum_{j=0}^{N-1} u_{2 N_0}({\\rm T}^{j} \\underline{x}) - \\left<  u_{2 N_0}  \\right>  \\bigr|  >  \nS \\cdot N_{0}^{\\delta+1} \\cdot N^{- \\tau_0 } ] < e^{- N^{\\sigma_0}}$$\n\nDenote the union of the two sets in (<a href=\"#13\" data-reference-type=\"ref\" data-reference=\"13\">[13]</a>), (<a href=\"#13&#39;\" data-reference-type=\"ref\" data-reference=\"13&#39;\">[13']</a>) by $B_2$.",
    "labels": [
      "12",
      "13",
      "13'"
    ],
    "refs": [
      "10",
      "13",
      "13&#39;",
      "aproxu",
      "indc3",
      "scale2",
      "shiftldt"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L897-909::s17",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L897-909::s17",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L897-909::s17",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 897,
    "end_line": 909,
    "text": "Denote the union of the two sets in (<a href=\"#13\" data-reference-type=\"ref\" data-reference=\"13\">[13]</a>), (<a href=\"#13&#39;\" data-reference-type=\"ref\" data-reference=\"13&#39;\">[13']</a>) by $B_2$.\n\nSince $N$ satisfies (<a href=\"#scale1\" data-reference-type=\"ref\" data-reference=\"scale1\">[scale1]</a>), $$S \\cdot N_{0}^{\\delta+1} \\cdot N^{-\\tau_0} \n< S \\cdot (N^{1/A})^{\\delta+1} \\cdot N^{-\\tau_0}  < S \\cdot   N^{-\\tau_1} \\ \\text{ where  } \\tau_1< \\frac{\\tau_0}{2}$$\n\nso from (<a href=\"#12\" data-reference-type=\"ref\" data-reference=\"12\">[12]</a>), (<a href=\"#13\" data-reference-type=\"ref\" data-reference=\"13\">[13]</a>), (<a href=\"#13&#39;\" data-reference-type=\"ref\" data-reference=\"13&#39;\">[13']</a>) we get: $$\\begin{aligned}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert  \\, + \\,  \\left<  u_{N_0}  \\right>  \\, - \\,  2  \\left<  u_{2 N_0}  \\right>  \\bigr| \\notag \\\\  \n\\lesssim S N_0 N^{-1}  +  S  \\cdot   N^{-\\tau_1}  \\lesssim  S  \\cdot N^{-\\tau_1} \\label{14}\n\\end{aligned}$$\n\nfor $\\underline{x}\\notin B := B_1  \\cup  B_2$, where $$\\mbox{mes } [ B ] < 2 N^{- D + 1} + 2 e^{-N^{\\sigma}} <  3 N^{- D + 1} <   N^{- D + 2}$$\n\nUsing (<a href=\"#aprox&lt;u&gt;\" data-reference-type=\"ref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a>) at scales $N_0$, $2 N_0$ and taking into account (<a href=\"#scale1\" data-reference-type=\"ref\" data-reference=\"scale1\">[scale1]</a>), estimate (<a href=\"#14\" data-reference-type=\"ref\" data-reference=\"14\">[14]</a>) becomes: $$\\label{15}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert \\, + \\,  L_{N_0}  \\, - \\,   2 L_{2 N_0}  \\bigr|  < 2 S \\cdot N^{-\\tau_1} \\, + \\, 2 e^{-  N_{0}^2} < 3 S N^{-\\tau_1}$$ provided $x \\notin B$.",
    "labels": [
      "14",
      "15"
    ],
    "refs": [
      "12",
      "13",
      "13&#39;",
      "14",
      "aprox&lt;u&gt;",
      "scale1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L886-896::s16",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L910-919::s18",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 910,
    "end_line": 919,
    "text": "Using (<a href=\"#aprox&lt;u&gt;\" data-reference-type=\"ref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a>) at scales $N_0$, $2 N_0$ and taking into account (<a href=\"#scale1\" data-reference-type=\"ref\" data-reference=\"scale1\">[scale1]</a>), estimate (<a href=\"#14\" data-reference-type=\"ref\" data-reference=\"14\">[14]</a>) becomes: $$\\label{15}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert \\, + \\,  L_{N_0}  \\, - \\,   2 L_{2 N_0}  \\bigr|  < 2 S \\cdot N^{-\\tau_1} \\, + \\, 2 e^{-  N_{0}^2} < 3 S N^{-\\tau_1}$$ provided $x \\notin B$.\n\nCombine (<a href=\"#15\" data-reference-type=\"ref\" data-reference=\"15\">[15]</a>) with (<a href=\"#11\" data-reference-type=\"ref\" data-reference=\"11\">[11]</a>) to get: $$\\label{16}\n\\bigl|  \\frac{1}{N}  \\log \\lVert M_{N} (\\underline{x}) \\rVert \\, - \\,  L_{N}  \\bigr|  <  C_{0} S N_0 N^{-1} + 3 S \\cdot N^{-\\tau_1}  <  S \\cdot N^{-\\tau_2}$$ for all $\\underline{x}\\notin B$, where $\\mbox{mes }[ B ] <  N^{- D + 2}$ and $\\tau_2 <  \\tau_1$.\n\nHowever, (<a href=\"#16\" data-reference-type=\"ref\" data-reference=\"16\">[16]</a>) is not exactly what we need in order to prove the estimate (<a href=\"#indc3\" data-reference-type=\"ref\" data-reference=\"indc3\">[indc3]</a>). We have to prove an estimate like (<a href=\"#16\" data-reference-type=\"ref\" data-reference=\"16\">[16]</a>) for $\\underline{x}$ outside an exponentially small set, and we only have it outside a polynomially small set. To boost this estimate, we employ again Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a>.\n\nFrom (<a href=\"#16\" data-reference-type=\"ref\" data-reference=\"16\">[16]</a>), using again (<a href=\"#aproxu\" data-reference-type=\"ref\" data-reference=\"aproxu\">[aproxu]</a>), (<a href=\"#aprox&lt;u&gt;\" data-reference-type=\"ref\" data-reference=\"aprox&lt;u&gt;\">[aprox&lt;u&gt;]</a>) at scale $N$, we get: $$\\label{160}\n \\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|  u_{N} (\\underline{x}) - \\left< u_N \\right>  \\bigr| > S \\cdot N^{-\\tau_2} ] < N^{- D + 2}$$\n\nWe apply Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a> to $u (\\underline{x}) := \\frac{1}{S} u_N (\\underline{x})$, which is a pluri-subharmonic function on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$, with upper bound $B = 1$ on this strip.",
    "labels": [
      "15",
      "16",
      "160"
    ],
    "refs": [
      "11",
      "14",
      "15",
      "16",
      "aprox&lt;u&gt;",
      "aproxu",
      "boost",
      "indc3",
      "scale1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L897-909::s17",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L920-935::s19",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L897-909::s17",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L920-935::s19",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L920-935::s19",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 920,
    "end_line": 935,
    "text": "We apply Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a> to $u (\\underline{x}) := \\frac{1}{S} u_N (\\underline{x})$, which is a pluri-subharmonic function on the strip $\\underline{\\mathcal{A}}_{\\underline{\\rho}_N}$, with upper bound $B = 1$ on this strip.\n\nEstimate (<a href=\"#160\" data-reference-type=\"ref\" data-reference=\"160\">[160]</a>) implies $$\\label{1600}\n \\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :  \\bigl|  u (\\underline{x}) - \\left< u \\right>  \\bigr| >  N^{-\\tau_2} ] < N^{- D + 2}$$\n\nThen for $\\epsilon _0 := N^{-\\tau_2}$, $\\epsilon _1 := N^{- D + 2}$, $B = 1$, $\\rho = \\rho_N \\approx N^{-\\delta-1}$ we have $$\\begin{aligned}\n{\\epsilon _0}^{1/4} + \\sqrt{\\frac{B}{\\rho}}  \\;   \\frac{{\\epsilon_1}^{1/4}} {{\\epsilon_0}^{1/2}}   = \n N^{-{\\tau_2}/4} + N^{\\frac{\\delta+1}{2}} \\, N^{- \\frac{D+2}{4}} \\, N^{{\\tau_2}/2} \\\\\n = N^{-{\\tau_2}/4}  + N^{-1} \\,  N^{{\\tau_2}/2} <  N^{-\\sigma_1}\n\n\\end{aligned}$$ for some positive constant $\\sigma_1$.\n\nThe conclusion <a href=\"#strong\" data-reference-type=\"eqref\" data-reference=\"strong\">[strong]</a> of Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a> then boosts (<a href=\"#160\" data-reference-type=\"ref\" data-reference=\"160\">[160]</a>) from a small deviation outside a polynomially small set, to one outside an exponentially small set, amid a small power loss in the deviation: $$\\mbox{ mes } [ \\underline{x}\\in \\mathbb{T}^2 :   \\bigl|  u_N (\\underline{x}) - \\left< u_N \\right>  \\bigr| >  S \\, N^{-{\\tau_2}/4} ] < e^{-c N^{\\sigma_1}} < e^{-N^{\\sigma}}$$ which proves estimate (<a href=\"#indc3\" data-reference-type=\"ref\" data-reference=\"indc3\">[indc3]</a>). ◻\n\n</div>\n\n<div class=\"remark\">",
    "labels": [
      "1600"
    ],
    "refs": [
      "160",
      "boost",
      "indc3",
      "strong"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L910-919::s18",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L936-943::s20",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 936,
    "end_line": 943,
    "text": "<div class=\"remark\">\n\n**Remark 2**. *The scaling factor $\\sqrt{\\frac{B}{\\rho}}$ in estimate <a href=\"#strong\" data-reference-type=\"eqref\" data-reference=\"strong\">[strong]</a> of Lemma <a href=\"#boost\" data-reference-type=\"ref\" data-reference=\"boost\">3</a> is what prevents this approach via polynomial approximation to extend to more general Carleman classes of potential functions. This is because when the estimates on the Fourier coefficients of the potential function are weaker than estimate <a href=\"#fcoef\" data-reference-type=\"eqref\" data-reference=\"fcoef\">[fcoef]</a> for Gevrey functions, the size $\\rho = \\rho_N$ of the holomorphic extension of the $N$th transfer matrix substitute will cancel any decay in the expression $\\sqrt{\\frac{B}{\\rho}}  \\;   \\frac{{\\epsilon_1}^{1/4}} {{\\epsilon_0}^{1/2}}$ *\n\n</div>\n\nWe will combine the base step (Lemma <a href=\"#base-step\" data-reference-type=\"ref\" data-reference=\"base-step\">8</a>) with the inductive step (Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a>) to prove the large deviation estimate for transfer matrices and the positivity of the Lyapunov exponent. The proof of the LDT will also provide us with the major ingredient for deriving the continuity of the Lyapunov exponent.\n\n<div id=\"LDT\" class=\"theorem\">",
    "labels": [
      "LDT"
    ],
    "refs": [
      "base-step",
      "boost",
      "fcoef",
      "ind",
      "strong"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L920-935::s19",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L266-567::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L568-584::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L944-957::s21",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 944,
    "end_line": 957,
    "text": "<div id=\"LDT\" class=\"theorem\">\n\n**Theorem 3**. *Consider the Schrödinger operator (<a href=\"#op1\" data-reference-type=\"ref\" data-reference=\"op1\">[op1]</a>) on $l^2(\\mathbb{Z})$: $$[H (\\underline{x}) \\, \\psi]_n := - \\psi_{n+1} - \\psi_{n-1} + \\lambda\\, v ({\\rm T}^n \\underline{x}) \\, \\psi_n$$ where the transformation ${\\rm T}$ is either the skew-shift <a href=\"#skew\" data-reference-type=\"eqref\" data-reference=\"skew\">[skew]</a> or the multi-frequency shift <a href=\"#multishift\" data-reference-type=\"eqref\" data-reference=\"multishift\">[multishift]</a>. Assume that for some $\\kappa> 0$ the underlying frequency satisfies the Diophantine condition $DC_\\kappa$ described in <a href=\"#DC\" data-reference-type=\"eqref\" data-reference=\"DC\">[DC]</a> or <a href=\"#DCM\" data-reference-type=\"eqref\" data-reference=\"DCM\">[DCM]</a> respectively.*\n\n*Assume moreover that the potential function $v (\\underline{x})$ belongs to a Gevrey class $G^s (\\mathbb{T}^2)$ and that it is transversal as in <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a>.*\n\n*Then there exists $\\lambda_{0} = \\lambda_{0} ( v, \\kappa )$ so that for every fixed $\\lambda$ with $\\bigl| \\lambda \\bigr| \\geq \\lambda_{0}$ and for every energy $E$, we have: $$\\label{ldt}\n \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}, \\lambda, E ) \\rVert - L_{N} (\\lambda, E )  \\bigr| >  N^{-\\tau} ]  <   e^{- {N^{\\sigma}}}$$ for some absolute constants $\\tau, \\sigma  > 0$, and for all $N \\geq  N_{0} (\\lambda, \\kappa, v, s)$.*\n\n*Furthermore, for every such transformation ${\\rm T}$ and coupling constant $\\lambda$ and for all energies $E \\in \\mathbb{R}$ we have: $$\\label{poslyap}\n L (\\lambda, E) \\geq \\frac{1}{4} \\log\\bigl| \\lambda \\bigr| > 0$$*\n\n</div>\n\n<div class=\"proof\">",
    "labels": [
      "LDT",
      "ldt",
      "poslyap"
    ],
    "refs": [
      "DC",
      "DCM",
      "TC",
      "multishift",
      "op1",
      "skew"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L958-973::s22",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L66-84::s4",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L85-98::s5",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1-17::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L53-65::s3",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1092-1110::s31",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L958-973::s22",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 958,
    "end_line": 973,
    "text": "<div class=\"proof\">\n\n*Proof.* We refer to the list of constants preceding Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a>.\n\nWe use the initial step - Lemma <a href=\"#base-step\" data-reference-type=\"ref\" data-reference=\"base-step\">8</a> at a sufficiently large initial scale $N_0 \\ge N_{0 0} = N_{0 0} (v)$. We will explain how the scale $N_0$ is chosen later. We get constants $\\lambda_1$, $B$ $> 0$ such that for every $\\lambda$ with $\\left| \\lambda \\right|  \\ge \\max \\{ \\lambda _1, (2 N_0) {^B} \\}$ (we want Lemma <a href=\"#base-step\" data-reference-type=\"ref\" data-reference=\"base-step\">8</a> to apply at both scales $N_0$ and $2 N_0$) we have: $$\\begin{aligned}\n  \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{N_0} \\log \\lVert M_{N_0} (\\underline{x}) \\rVert - \nL_{N_0}   \\bigr| >  \\frac{1}{20} S  ]  <   N_0^{- A^2 \\cdot D} \\leq  N^{- D} \\label{ldtN0} \\\\\n \\mbox{mes } [\\underline{x}\\in \\mathbb{T}^2 : | \\frac{1}{2 N_0} \\log || M_{2 N_0} (\\underline{x}) || -L_{2 N_0}  | >  \\frac{1}{20} S  ]  \\notag \\\\ \n <   (2 N_0)^{- A^2 \\cdot D} \\lesssim N^{- D}  \\label{ldt2N0}\n\n\\end{aligned}$$ $$\\begin{aligned}\n L_{ N_0}, \\, L_{2 N_0} \\geq \\frac{1}{2} S \\label{LN0>} \\\\\nL_{ N_0} -  L_{2 N_0} \\leq  \\frac{1}{80} \\, S \\label{LN0-L2N0}\n\\end{aligned}$$\n\nOf course <a href=\"#ldtN0\" data-reference-type=\"eqref\" data-reference=\"ldtN0\">[ldtN0]</a> and <a href=\"#ldt2N0\" data-reference-type=\"eqref\" data-reference=\"ldt2N0\">[ldt2N0]</a> hold provided $N$ satisfies: $$\\label{N<}\nN  \\leq N_0^{A^2}$$",
    "labels": [
      "LN0-L2N0",
      "LN0>",
      "N<",
      "ldt2N0",
      "ldtN0"
    ],
    "refs": [
      "base-step",
      "ind",
      "ldt2N0",
      "ldtN0"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L974-983::s23",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 974,
    "end_line": 983,
    "text": "Of course <a href=\"#ldtN0\" data-reference-type=\"eqref\" data-reference=\"ldtN0\">[ldtN0]</a> and <a href=\"#ldt2N0\" data-reference-type=\"eqref\" data-reference=\"ldt2N0\">[ldt2N0]</a> hold provided $N$ satisfies: $$\\label{N<}\nN  \\leq N_0^{A^2}$$\n\nEstimates <a href=\"#ldtN0\" data-reference-type=\"eqref\" data-reference=\"ldtN0\">[ldtN0]</a> - <a href=\"#LN0-L2N0\" data-reference-type=\"eqref\" data-reference=\"LN0-L2N0\">[LN0-L2N0]</a> above are exactly the assumptions <a href=\"#indhyp1\" data-reference-type=\"eqref\" data-reference=\"indhyp1\">[indhyp1]</a> - <a href=\"#indhyp4\" data-reference-type=\"eqref\" data-reference=\"indhyp4\">[indhyp4]</a> (at scale $N_0$, with $\\gamma = \\gamma_0 = \\frac{1}{2}$) in Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a>. of the inductive step of LDT.\n\nHowever, in order to apply this inductive step lemma and obtain similar estimates at the larger scale $N$, the initial scale $N_0$ and the disorder $\\lambda$ have to satisfy the condition <a href=\"#scale2\" data-reference-type=\"eqref\" data-reference=\"scale2\">[scale2]</a>. Together with the conditions on $\\lambda$ and $N_0$ from the initial step (Lemma <a href=\"#base-step\" data-reference-type=\"ref\" data-reference=\"base-step\">8</a>), $N_0$ and $\\lambda$ have to satisfy: $$\\begin{aligned}\n(2 N_0)^B \\leq \\bigl| \\lambda \\bigr|  \\leq e^{N_0} \\label{alfa} \\\\\nN_0 \\geq N_{0 0} \\label{beta} \\\\\n\\bigl| \\lambda \\bigr|  \\geq  \\lambda_1\\label{gama} \n\\end{aligned}$$\n\nWe want to prove the LDT for every disorder $\\lambda$ large enough, $\\bigl| \\lambda \\bigr|  \\geq \\lambda_0$ and not just for $\\lambda$ in a bounded interval as in <a href=\"#alfa\" data-reference-type=\"eqref\" data-reference=\"alfa\">[alfa]</a>. To do that, we will have to first choose $\\lambda$ large enough, and then to pick $N_0 = N_0 (\\lambda) \\ge N_{0 0}$ appropriately. Here is how we can accomplish that.",
    "labels": [
      "N<",
      "alfa",
      "beta",
      "gama"
    ],
    "refs": [
      "LN0-L2N0",
      "alfa",
      "base-step",
      "ind",
      "indhyp1",
      "indhyp4",
      "ldt2N0",
      "ldtN0",
      "scale2"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L958-973::s22",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L984-992::s24",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L958-973::s22",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L697-704::s0",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L705-724::s1",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L984-992::s24",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L984-992::s24",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 984,
    "end_line": 992,
    "text": "We want to prove the LDT for every disorder $\\lambda$ large enough, $\\bigl| \\lambda \\bigr|  \\geq \\lambda_0$ and not just for $\\lambda$ in a bounded interval as in <a href=\"#alfa\" data-reference-type=\"eqref\" data-reference=\"alfa\">[alfa]</a>. To do that, we will have to first choose $\\lambda$ large enough, and then to pick $N_0 = N_0 (\\lambda) \\ge N_{0 0}$ appropriately. Here is how we can accomplish that.\n\nThe condition <a href=\"#alfa\" data-reference-type=\"eqref\" data-reference=\"alfa\">[alfa]</a> is equivalent to $$\\label{alfa'}\n\\log \\left| \\lambda \\right| \\leq N_0 \\leq  \\frac{1}{2}\\bigl| \\lambda \\bigr|^{1/B}$$\n\nWe can find $\\lambda_0$ large enough, $\\lambda_0 =  \\lambda_0 (v, \\kappa)$, $\\lambda_0 \\ge \\lambda_1$, so that if $\\left| \\lambda \\right| \\geq   \\lambda_0$, then $$\\label{betagama'}\n \\log \\left| \\lambda \\right| \\geq   N_{0 0} \\, \\mbox{  and  } \\,  \n \\log \\left| \\lambda \\right| \\ll   \\frac{1}{2}\\bigl| \\lambda \\bigr|^{1/B}$$\n\nThen for every such $\\lambda$ we can pick $N_0 = N_0 ( \\lambda)$ so that <a href=\"#alfa&#39;\" data-reference-type=\"eqref\" data-reference=\"alfa&#39;\">[alfa']</a> holds. Combining this with <a href=\"#betagama&#39;\" data-reference-type=\"eqref\" data-reference=\"betagama&#39;\">[betagama']</a>, we get that (<a href=\"#alfa\" data-reference-type=\"ref\" data-reference=\"alfa\">[alfa]</a>), (<a href=\"#beta\" data-reference-type=\"ref\" data-reference=\"beta\">[beta]</a>), (<a href=\"#gama\" data-reference-type=\"ref\" data-reference=\"gama\">[gama]</a>) hold.",
    "labels": [
      "alfa'",
      "betagama'"
    ],
    "refs": [
      "alfa",
      "alfa&#39;",
      "beta",
      "betagama&#39;",
      "gama"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L993-999::s25",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 993,
    "end_line": 999,
    "text": "Then for every such $\\lambda$ we can pick $N_0 = N_0 ( \\lambda)$ so that <a href=\"#alfa&#39;\" data-reference-type=\"eqref\" data-reference=\"alfa&#39;\">[alfa']</a> holds. Combining this with <a href=\"#betagama&#39;\" data-reference-type=\"eqref\" data-reference=\"betagama&#39;\">[betagama']</a>, we get that (<a href=\"#alfa\" data-reference-type=\"ref\" data-reference=\"alfa\">[alfa]</a>), (<a href=\"#beta\" data-reference-type=\"ref\" data-reference=\"beta\">[beta]</a>), (<a href=\"#gama\" data-reference-type=\"ref\" data-reference=\"gama\">[gama]</a>) hold.\n\nAll the assumptions on the small scale $N_0$ in the inductive step - Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> hold now, so if we choose the large scale $N$ such that $$\\label{N}\n N_0^{A} \\leq N \\leq  N_0^{A^2} ( <  e^{N_0})$$ then <a href=\"#N&lt;\" data-reference-type=\"eqref\" data-reference=\"N&lt;\">[N&lt;]</a> and <a href=\"#scale1\" data-reference-type=\"eqref\" data-reference=\"scale1\">[scale1]</a> hold, so we can apply Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> to get: $$\\label{fin7}\n \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert - L_{N}   \\bigr| >  S N^{-\\tau} ]  <   e^{-N^\\sigma}$$ $$\\begin{aligned}\nL_{N}  & \\ \\geq \\gamma_0 S - 2 (  L_{ N_0}  -  L_{2 N_0} ) - C_{0} S N_{0} N^{-1} \\label{fin5}\\\\\nL_{ N}  -  L_{2 N}  & \\ \\leq  C_{0} S  N_{0} N^{-1} \\label{fin6}\n\\end{aligned}$$ for some positive absolute constants $C_0, \\tau, \\sigma$.",
    "labels": [
      "N",
      "fin5",
      "fin6",
      "fin7"
    ],
    "refs": [
      "N&lt;",
      "alfa",
      "alfa&#39;",
      "beta",
      "betagama&#39;",
      "gama",
      "ind",
      "scale1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L984-992::s24",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L974-983::s23",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1000-1009::s26",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1000,
    "end_line": 1009,
    "text": "All the assumptions on the small scale $N_0$ in the inductive step - Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> hold now, so if we choose the large scale $N$ such that $$\\label{N}\n N_0^{A} \\leq N \\leq  N_0^{A^2} ( <  e^{N_0})$$ then <a href=\"#N&lt;\" data-reference-type=\"eqref\" data-reference=\"N&lt;\">[N&lt;]</a> and <a href=\"#scale1\" data-reference-type=\"eqref\" data-reference=\"scale1\">[scale1]</a> hold, so we can apply Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> to get: $$\\label{fin7}\n \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{N} \\log \\lVert M_{N} (\\underline{x}) \\rVert - L_{N}   \\bigr| >  S N^{-\\tau} ]  <   e^{-N^\\sigma}$$ $$\\begin{aligned}\nL_{N}  & \\ \\geq \\gamma_0 S - 2 (  L_{ N_0}  -  L_{2 N_0} ) - C_{0} S N_{0} N^{-1} \\label{fin5}\\\\\nL_{ N}  -  L_{2 N}  & \\ \\leq  C_{0} S  N_{0} N^{-1} \\label{fin6}\n\\end{aligned}$$ for some positive absolute constants $C_0, \\tau, \\sigma$.\n\nEstimate (<a href=\"#fin7\" data-reference-type=\"ref\" data-reference=\"fin7\">[fin7]</a>) proves the LDT (<a href=\"#ldt\" data-reference-type=\"ref\" data-reference=\"ldt\">[ldt]</a>) at scale $N$ in the range $[ N_0^{A}, N_0^{A^2} ]$. If $N_1$ is in this range, say $N_1 =  N_0^{A}$, then (<a href=\"#fin6\" data-reference-type=\"ref\" data-reference=\"fin6\">[fin6]</a>) and (<a href=\"#fin5\" data-reference-type=\"ref\" data-reference=\"fin5\">[fin5]</a>) imply: $$L_{ N_1}  -  L_{2 N_1}  \\leq  C_{0} S  N_{0} N^{-1}$$ $$L_{N_1}   \\geq \\gamma_0 \\, S - 3 \\, C_{0} S  N_{0} N^{-1} =  \\gamma_0 \\, S - 3  \\, C_{0}  N_{0}^{- A + 1} S  =: \\gamma_1 \\cdot S$$ where $$\\gamma_1 := \\gamma_0 -  3  \\, C_{0}  N_{0}^{- A + 1} =  \\frac{1}{2} - 3  \\, C_{0}  N_{0}^{- A + 1} >  \\frac{1}{4}$$ provided we chose $N_{0 0}$ (and so $N_0$) large enough depending on $A$, $C_0$.\n\nTherefore we have: $$\\label{fin8}\nL_{N_1}  \\geq \\gamma_1 S$$ and $$L_{ N_1}  -  L_{2 N_1}   \\leq  C_{0} S  N_{0} N^{-1}  = C_{0}  S N_{0}^{- A + 1}  < \\frac{1}{160} \\cdot S \n<  \\frac{\\gamma_1}{40} \\cdot S$$ so $$\\label{fin9}\nL_{ N_1}  -  L_{2 N_1}    <  \\frac{\\gamma_1}{40} \\cdot S$$\n\nSince $2 N_1 = 2 N_0^{A}$ is in the range $[ N_0^{A}, N_0^{A^2} ]$, (<a href=\"#fin8\" data-reference-type=\"ref\" data-reference=\"fin8\">[fin8]</a>) holds at scale $2 N_1$ too, so we have: $$\\label{fin10}\nL_{N_1}, L_{2 N_1}  \\geq \\gamma_1 S$$",
    "labels": [
      "N",
      "fin10",
      "fin5",
      "fin6",
      "fin7",
      "fin8",
      "fin9"
    ],
    "refs": [
      "N&lt;",
      "fin5",
      "fin6",
      "fin7",
      "fin8",
      "ind",
      "ldt",
      "scale1"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L779-798::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1010-1019::s27",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1010,
    "end_line": 1019,
    "text": "Since $2 N_1 = 2 N_0^{A}$ is in the range $[ N_0^{A}, N_0^{A^2} ]$, (<a href=\"#fin8\" data-reference-type=\"ref\" data-reference=\"fin8\">[fin8]</a>) holds at scale $2 N_1$ too, so we have: $$\\label{fin10}\nL_{N_1}, L_{2 N_1}  \\geq \\gamma_1 S$$\n\nChoosing the next large scale $N_2$ so that $N_1^{A} \\leq N_2  \\leq  N_1^{A^2} (< e^{N_1})$, we have $e^{- {N_{1}^{\\sigma}}} < N_{1}^{- A^2 \\cdot D} \\leq N_{2}^{- D}$, so (<a href=\"#fin7\" data-reference-type=\"ref\" data-reference=\"fin7\">[fin7]</a>) implies: $$\\begin{aligned}\n \\mbox{mes } [  \\underline{x}\\in \\mathbb{T}^2 \\colon \\bigl|  \\frac{1}{N_1} \\log \\lVert M_{N_1} (\\underline{x}) \\rVert - \nL_{N_1}  \\bigr| >  \\frac{1}{20} S  ]  <    e^{- {N_{1}^{\\sigma}}} < N_{2}^{- D}    \\label{N1} \\\\\n \\mbox{mes } [ \\underline{x}\\in \\mathbb{T}^2 : \\bigl|  \\frac{1}{2 N_1} \\log \\lVert M_{2 N_1} (\\underline{x}) \\rVert -L_{2 N_1}   \\bigr| >  \\frac{1}{20} S  ]  \\lesssim N_{2}^{- D} \n \\label{N2}\n\n\\end{aligned}$$\n\nEstimates <a href=\"#N1\" data-reference-type=\"eqref\" data-reference=\"N1\">[N1]</a>, <a href=\"#N2\" data-reference-type=\"eqref\" data-reference=\"N2\">[N2]</a>, <a href=\"#fin10\" data-reference-type=\"eqref\" data-reference=\"fin10\">[fin10]</a>, <a href=\"#fin9\" data-reference-type=\"eqref\" data-reference=\"fin9\">[fin9]</a> are the assumptions in the inductive step - Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> with small scale $N_1$ and large scale $N_2$, where $N_2 \\in  [ N_1^{A}, N_1^{A^2} ] \\, = \\,  [ N_0^{A^2}, N_0^{A^3} ]$. Applying Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a>, we get the LDT <a href=\"#ldt\" data-reference-type=\"eqref\" data-reference=\"ldt\">[ldt]</a> for $N_2$ in this range. Moreover, we get:",
    "labels": [
      "N1",
      "N2",
      "fin10"
    ],
    "refs": [
      "N1",
      "N2",
      "fin10",
      "fin7",
      "fin8",
      "fin9",
      "ind",
      "ldt"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1020-1058::s28",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1020,
    "end_line": 1058,
    "text": "Estimates <a href=\"#N1\" data-reference-type=\"eqref\" data-reference=\"N1\">[N1]</a>, <a href=\"#N2\" data-reference-type=\"eqref\" data-reference=\"N2\">[N2]</a>, <a href=\"#fin10\" data-reference-type=\"eqref\" data-reference=\"fin10\">[fin10]</a>, <a href=\"#fin9\" data-reference-type=\"eqref\" data-reference=\"fin9\">[fin9]</a> are the assumptions in the inductive step - Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> with small scale $N_1$ and large scale $N_2$, where $N_2 \\in  [ N_1^{A}, N_1^{A^2} ] \\, = \\,  [ N_0^{A^2}, N_0^{A^3} ]$. Applying Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a>, we get the LDT <a href=\"#ldt\" data-reference-type=\"eqref\" data-reference=\"ldt\">[ldt]</a> for $N_2$ in this range. Moreover, we get:\n\n$$L_{ N_2}  -  L_{2 N_2}  \\leq  C_{0} S  N_{1} N_{2}^{-1}$$ and $$L_{N_2}  \\geq \\gamma_1 S - 2 (  L_{ N_1}  -  L_{2 N_1} ) -\n C_{0} S N_{1} N_{2}^{-1} \\geq (\\gamma_1 - 3 C_0  N_{1}^{- A + 1}) \\cdot S\n=: \\gamma_2 \\cdot S$$ where $$\\gamma_2 := \\gamma_1 -  3  C_{0}  N_{1}^{- A + 1} \\ge\n \\frac{1}{2} -  3  C_{0}  N_{0}^{- A + 1} -  3  C_{0}  N_{0}^{A \\cdot (- A + 1)}\n> \\frac{1}{4}$$ again, provided $N_{0 0}$ (thus $N_0$) was chosen large enough depending on $A$, $C_0$.\n\nHence we have $L_{N_2} \\geq \\gamma_2 \\cdot S$ and $L_{N_2} -  L_{2 N_2} \\leq \\frac{\\gamma_2}{40} \\cdot S$.\n\nContinuing this inductively, we obtain (<a href=\"#ldt\" data-reference-type=\"ref\" data-reference=\"ldt\">[ldt]</a>) at every scale $N \\geq N_{0}^A$.\n\nAlso, at each step $k$ in the induction process, if $N \\in  [ N_{k}^{A}, N_{k}^{A^2} ]$, then $L_N \\geq \\gamma_k \\cdot S > \\frac{1}{4} \\cdot S$ so $$L = \\inf_{N} L_N \\geq \\frac{1}{4} \\cdot S$$ and (<a href=\"#poslyap\" data-reference-type=\"ref\" data-reference=\"poslyap\">[poslyap]</a>) is proven. ◻\n\n</div>\n\nWe now prove that the Lyapunov exponent is continuous as a function of the energy.\n\n<div id=\"cont\" class=\"theorem\">\n\n**Theorem 4**. *Under the same conditions as in Theorem <a href=\"#LDT\" data-reference-type=\"ref\" data-reference=\"LDT\">3</a> above, and for any $\\left|  \\lambda \\right| \\ge \\lambda_0 (v, \\kappa)$, the Lyapunov exponent $L (E)$ is a continuous function of the energy $E$ with modulus of continuity on each compact interval $\\mathcal{E}$ at least: $$\\label{modcont-weak}\nw (t) = C \\, \\bigr(\\log \\frac{1}{t} \\bigl)^{-\\beta}$$ where $C = C (\\mathcal{E}, \\lambda, v, \\kappa, s)$ and $\\beta \\in (0,1)$ is a universal constant that can be chosen, at the expense of $C$, to be arbitrarily close to 1.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* We will fix $\\lambda, {\\rm T}$ and omit them from notations. We also fix the compact interval $\\mathcal{E}$.\n\nIt is easy to show (see below) that for every scale $N$, the functions $L_N (E)$ are (Lipschitz) continuous. To prove that their limits $L (E)$ are also continuous with a certain modulus of continuity, we need a quantitative description of the convergence $L_N (E) \\to L (E)$ as $N \\to \\infty$. The better this rate of convergence, the sharper the modulus of continuity of $L (E)$.\n\nIt follows from the proof of Theorem <a href=\"#LDT\" data-reference-type=\"ref\" data-reference=\"LDT\">3</a> above (see <a href=\"#fin6\" data-reference-type=\"eqref\" data-reference=\"fin6\">[fin6]</a> and the inductive process thereafter) that for every scales $N_0$ and $N$ such that $N_0 \\ge N_{0 0} (\\lambda, v, \\kappa)$ and $N_0^A \\le N \\le N_0^{A^2}$, we have: $$L_N (E)  - L_{2N}  (E) \\lesssim N_0 N^{-1} \\le N^{1/A} \\, N^{-1} =: N^{- \\beta}$$ so $$\\label{cont1}\nL_N (E) - L_{2N} (E)  \\lesssim N^{- \\beta} \\ \\text{ for all } N \\ge N_{0 0}$$ Summing up over dyadic $N$’s we conclude: $$\\label{cont2}\nL_N (E) - L (E)  \\lesssim N^{- \\beta} \\ \\text{ for all } N \\ge N_{0 0}$$ which is the quantitative convergence we were seeking.\n\nTo show that $$L_N (E) = \\frac{1}{N} \\, \\int_{\\mathbb{T}^2} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d \\underline{x}$$ are continuous, we use Trotter’s formula for the transfer matrix $M_N (\\underline{x}, E)$:\n\n$$M_{N} (\\underline{x}, E) -  M_{N} (\\underline{x}, E^\\prime)  =$$ $$=  \\sum_{j=1}^{N} A ({\\rm T}^{N} \\underline{x}, E) \\ldots  \\,  [A ({\\rm T}^j \\underline{x}, E) - A ({\\rm T}^j \\underline{x}, E^\\prime)] \\,  \\ldots A ({\\rm T}\\, \\underline{x}, E^\\prime)$$ But $$A ({\\rm T}^j \\underline{x}, E) - A ({\\rm T}^j \\underline{x}, E^\\prime) = \\Bigl[\\begin{array}{cc}\nE^\\prime - E  &   0  \\\\\n0 &  0 \\\\  \\end{array} \\Bigr]$$ and $$\\lVert A ({\\rm T}^j \\underline{x}, E) \\rVert  \\leq  e^{S} \\quad \\mbox{ for all } E \\in \\mathcal{E}$$ so $$\\lVert M_{N} (\\underline{x}, E) -  M_{N} (\\underline{x}, E^\\prime) \\rVert \\le e^{S N} \\, \\bigl|  E - E^\\prime  \\bigr|$$",
    "labels": [
      "cont",
      "cont1",
      "cont2",
      "modcont-weak"
    ],
    "refs": [
      "LDT",
      "N1",
      "N2",
      "fin10",
      "fin6",
      "fin9",
      "ind",
      "ldt",
      "poslyap"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1010-1019::s27",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1059-1077::s29",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1059,
    "end_line": 1077,
    "text": "$$L_{ N_2}  -  L_{2 N_2}  \\leq  C_{0} S  N_{1} N_{2}^{-1}$$ and $$L_{N_2}  \\geq \\gamma_1 S - 2 (  L_{ N_1}  -  L_{2 N_1} ) -\n C_{0} S N_{1} N_{2}^{-1} \\geq (\\gamma_1 - 3 C_0  N_{1}^{- A + 1}) \\cdot S\n=: \\gamma_2 \\cdot S$$ where $$\\gamma_2 := \\gamma_1 -  3  C_{0}  N_{1}^{- A + 1} \\ge\n \\frac{1}{2} -  3  C_{0}  N_{0}^{- A + 1} -  3  C_{0}  N_{0}^{A \\cdot (- A + 1)}\n> \\frac{1}{4}$$ again, provided $N_{0 0}$ (thus $N_0$) was chosen large enough depending on $A$, $C_0$.\n\nHence we have $L_{N_2} \\geq \\gamma_2 \\cdot S$ and $L_{N_2} -  L_{2 N_2} \\leq \\frac{\\gamma_2}{40} \\cdot S$.\n\nContinuing this inductively, we obtain (<a href=\"#ldt\" data-reference-type=\"ref\" data-reference=\"ldt\">[ldt]</a>) at every scale $N \\geq N_{0}^A$.\n\nAlso, at each step $k$ in the induction process, if $N \\in  [ N_{k}^{A}, N_{k}^{A^2} ]$, then $L_N \\geq \\gamma_k \\cdot S > \\frac{1}{4} \\cdot S$ so $$L = \\inf_{N} L_N \\geq \\frac{1}{4} \\cdot S$$ and (<a href=\"#poslyap\" data-reference-type=\"ref\" data-reference=\"poslyap\">[poslyap]</a>) is proven. ◻\n\n</div>\n\nWe now prove that the Lyapunov exponent is continuous as a function of the energy.\n\n<div id=\"cont\" class=\"theorem\">\n\n**Theorem 4**. *Under the same conditions as in Theorem <a href=\"#LDT\" data-reference-type=\"ref\" data-reference=\"LDT\">3</a> above, and for any $\\left|  \\lambda \\right| \\ge \\lambda_0 (v, \\kappa)$, the Lyapunov exponent $L (E)$ is a continuous function of the energy $E$ with modulus of continuity on each compact interval $\\mathcal{E}$ at least: $$\\label{modcont-weak}\nw (t) = C \\, \\bigr(\\log \\frac{1}{t} \\bigl)^{-\\beta}$$ where $C = C (\\mathcal{E}, \\lambda, v, \\kappa, s)$ and $\\beta \\in (0,1)$ is a universal constant that can be chosen, at the expense of $C$, to be arbitrarily close to 1.*\n\n</div>\n\n<div class=\"proof\">\n\n*Proof.* We will fix $\\lambda, {\\rm T}$ and omit them from notations. We also fix the compact interval $\\mathcal{E}$.\n\nIt is easy to show (see below) that for every scale $N$, the functions $L_N (E)$ are (Lipschitz) continuous. To prove that their limits $L (E)$ are also continuous with a certain modulus of continuity, we need a quantitative description of the convergence $L_N (E) \\to L (E)$ as $N \\to \\infty$. The better this rate of convergence, the sharper the modulus of continuity of $L (E)$.\n\nIt follows from the proof of Theorem <a href=\"#LDT\" data-reference-type=\"ref\" data-reference=\"LDT\">3</a> above (see <a href=\"#fin6\" data-reference-type=\"eqref\" data-reference=\"fin6\">[fin6]</a> and the inductive process thereafter) that for every scales $N_0$ and $N$ such that $N_0 \\ge N_{0 0} (\\lambda, v, \\kappa)$ and $N_0^A \\le N \\le N_0^{A^2}$, we have: $$L_N (E)  - L_{2N}  (E) \\lesssim N_0 N^{-1} \\le N^{1/A} \\, N^{-1} =: N^{- \\beta}$$ so $$\\label{cont1}\nL_N (E) - L_{2N} (E)  \\lesssim N^{- \\beta} \\ \\text{ for all } N \\ge N_{0 0}$$ Summing up over dyadic $N$’s we conclude: $$\\label{cont2}\nL_N (E) - L (E)  \\lesssim N^{- \\beta} \\ \\text{ for all } N \\ge N_{0 0}$$ which is the quantitative convergence we were seeking.\n\nTo show that $$L_N (E) = \\frac{1}{N} \\, \\int_{\\mathbb{T}^2} \\log \\lVert M_N (\\underline{x}, E) \\rVert \\, d \\underline{x}$$ are continuous, we use Trotter’s formula for the transfer matrix $M_N (\\underline{x}, E)$:\n\n$$M_{N} (\\underline{x}, E) -  M_{N} (\\underline{x}, E^\\prime)  =$$ $$=  \\sum_{j=1}^{N} A ({\\rm T}^{N} \\underline{x}, E) \\ldots  \\,  [A ({\\rm T}^j \\underline{x}, E) - A ({\\rm T}^j \\underline{x}, E^\\prime)] \\,  \\ldots A ({\\rm T}\\, \\underline{x}, E^\\prime)$$ But $$A ({\\rm T}^j \\underline{x}, E) - A ({\\rm T}^j \\underline{x}, E^\\prime) = \\Bigl[\\begin{array}{cc}\nE^\\prime - E  &   0  \\\\\n0 &  0 \\\\  \\end{array} \\Bigr]$$ and $$\\lVert A ({\\rm T}^j \\underline{x}, E) \\rVert  \\leq  e^{S} \\quad \\mbox{ for all } E \\in \\mathcal{E}$$ so $$\\lVert M_{N} (\\underline{x}, E) -  M_{N} (\\underline{x}, E^\\prime) \\rVert \\le e^{S N} \\, \\bigl|  E - E^\\prime  \\bigr|$$\n\nTherefore, since $\\lVert M_{N} (\\underline{x}, E) \\rVert \\geq 1$ and $|| M_{N} (\\underline{x}, E^\\prime) || \\geq 1$, we have: $$\\begin{aligned}\n\\bigl|  \\log \\lVert M_{N} (\\underline{x}, E) \\rVert -  \\log \\lVert M_{N} (\\underline{x}, E^\\prime) \\rVert  \\bigr|  \\\\\n\\le \\lVert M_{N} (x, E) -  M_{N} (x, E^\\prime) \\rVert \\le e^{S N} \\, \\bigl|  E - E^\\prime  \\bigr|\n\\end{aligned}$$\n\nIntegrating in $\\underline{x}$ we obtain: $$\\label{cont3}\n| L_{N} (E) - L_{N} (E^\\prime) | \\leq e^{S N} \\, | E - E^\\prime |$$ which shows Lipschitz continuity for the maps $L_N (E)$.\n\nCombining <a href=\"#cont2\" data-reference-type=\"eqref\" data-reference=\"cont2\">[cont2]</a> and <a href=\"#cont3\" data-reference-type=\"eqref\" data-reference=\"cont3\">[cont3]</a> we obtain: $$\\label{cont4}\n\\bigl|  L (E) - L (E^\\prime)  \\bigr| \\lesssim N^{- \\beta} + e^{S N} \\, | E - E^\\prime | \\quad \\text{ for all } N \\ge  N_{0 0} (\\lambda, v, \\kappa)$$\n\nFor every such $N$ let $$\\bigl|  E - E^\\prime  \\bigr| \\sim e^{- S N} \\, N^{- \\beta}$$ so $$\\bigl|  L (E) - L (E^\\prime)  \\bigr| \\lesssim N^{- \\beta}$$ Since $$\\log \\frac{1}{\\bigl|  E - E^\\prime  \\bigr|} \\sim S N + \\beta \\log N \\lesssim S N$$ we have $$N^{- \\beta} \\sim \\bigl(\\frac{1}{S}\\bigr)^{- \\beta} \\, \\bigl( \\log \\frac{1}{\\bigl|  E - E^\\prime  \\bigr|} \\bigr)^{-\\beta} = C \\,  \\bigl( \\log \\frac{1}{\\bigl|  E - E^\\prime  \\bigr|} \\bigr)^{-\\beta}$$ where $C = C (\\lambda, v, \\kappa)$.\n\nWe conclude, using the compactness of $\\mathcal{E}$, that for some constant $C = C(\\mathcal{E}, \\lambda, v, \\kappa)$, and for a constant $\\beta$ that can be chosen arbitrarily close to $1$ by starting off with a large enough constant $A$, we have: $$\\bigl|  L (E) - L (E^\\prime)  \\bigr|  < C \\,  \\bigl( \\log \\frac{1}{\\bigl|  E - E^\\prime  \\bigr|} \\bigr)^{-\\beta}$$ ◻\n\n</div>\n\n<div class=\"remark\">",
    "labels": [
      "cont",
      "cont1",
      "cont2",
      "cont3",
      "cont4",
      "modcont-weak"
    ],
    "refs": [
      "LDT",
      "cont2",
      "cont3",
      "fin6",
      "ldt",
      "poslyap"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L993-999::s25",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1000-1009::s26",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1078-1091::s30",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1078,
    "end_line": 1091,
    "text": "<div class=\"remark\">\n\n**Remark 3**. *The rate of convergence <a href=\"#cont2\" data-reference-type=\"eqref\" data-reference=\"cont2\">[cont2]</a> can be improved to $$\\label{cont2'}\n\\bigl|  L(E) + L_N (E) - 2 L_{2 N} (E)  \\bigr|  \\lesssim e^{-c N^{ \\eta}} \\ \\text{ for all } N \\ge N_{0 0}$$ which follows from the proof of the inductive step, Lemma <a href=\"#ind\" data-reference-type=\"ref\" data-reference=\"ind\">9</a> (see estimate <a href=\"#11\" data-reference-type=\"eqref\" data-reference=\"11\">[11]</a>) and uses the avalanche principle. This faster rate of convergence leads to the sharper modulus of continuity <a href=\"#modcont\" data-reference-type=\"eqref\" data-reference=\"modcont\">[modcont]</a> (see , for details). *\n\n</div>\n\nWe will now explain how Anderson localization is derived from the large deviation theorem <a href=\"#LDT\" data-reference-type=\"ref\" data-reference=\"LDT\">3</a>.\n\nGiven the Schrödinger operator $$\\label{3op}\n[H (\\underline{x}) \\, \\psi]_n := - \\psi_{n+1} - \\psi_{n-1} + \\lambda\\, v ({\\rm T}^n \\underline{x}) \\, \\psi_n$$ for every scale $N$ we denote $$H_N (\\underline{x}) := R_{[1, N]} H (\\underline{x}) R_{[1, N]}$$ where $R_{[1, N]}$ is the coordinate restriction to $[1, N] \\subset \\mathbb{Z}$ with Dirichlet boundary conditions.\n\nThen the associated Green’s functions are defined as $$G_N (\\underline{x}, E) := [ H_N (\\underline{x}) - E ]^{-1}$$ if the $N \\times N$ matrix $H_N (\\underline{x}) - E$ is invertible.\n\nThe large deviation estimate <a href=\"#ldt\" data-reference-type=\"eqref\" data-reference=\"ldt\">[ldt]</a> implies, via Cramer’s rule, ‘good bounds’ on the Green’s functions $G_N (\\underline{x}, E)$ associated with (<a href=\"#3op\" data-reference-type=\"ref\" data-reference=\"3op\">[3op]</a>).",
    "labels": [
      "3op",
      "cont2'"
    ],
    "refs": [
      "11",
      "3op",
      "LDT",
      "cont2",
      "ind",
      "ldt",
      "modcont"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1092-1110::s31",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L868-880::s14",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L881-885::s15",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L936-943::s20",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1020-1058::s28",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1059-1077::s29",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L760-778::s6",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L114-127::s7",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L128-133::s8",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1092-1110::s31",
        "direction": "comment"
      },
      {
        "id": "1204.3086v3::L1111-1120::s32",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1092-1110::s31",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1092,
    "end_line": 1110,
    "text": "The large deviation estimate <a href=\"#ldt\" data-reference-type=\"eqref\" data-reference=\"ldt\">[ldt]</a> implies, via Cramer’s rule, ‘good bounds’ on the Green’s functions $G_N (\\underline{x}, E)$ associated with (<a href=\"#3op\" data-reference-type=\"ref\" data-reference=\"3op\">[3op]</a>).\n\nIndeed, for $1 \\leq n_1 \\leq n_2 \\leq N$, we have: $$\\begin{aligned}\nG_N (\\underline{x}, E) (n_1, n_2) = [ H_N (\\underline{x}) - E ]^{-1} (n_1, n_2) \\\\\n= \\frac{ \\mbox{ det } [ H_{n_1-1} (\\underline{x}) - E ]  \\cdot   \\mbox{ det } [ H_{N-n_2} ({\\rm T}^{n_2} \\underline{x}) - E ] }\n{\\mbox{ det } [ H_{N} (\\underline{x}) - E ] }\n\\end{aligned}$$\n\nThere is the following relation between transfer matrices and determinants: $$\\label{tmdet}\nM_{N} (\\underline{x}, E) = \\Bigl[ \\begin{array}{ccc}\n\\mbox{ det } [ H_N (\\underline{x}) - E ]   & & - \\mbox{ det } [ H_{N-1} ({\\rm T}\\underline{x}) - E ]  \\\\\n \\mbox{ det } [ H_{N-1} (\\underline{x}) - E ] & &  - \\mbox{ det } [ H_{N-2} ({\\rm T}\\underline{x}) - E ] \\\\  \\end{array} \\Bigr]$$\n\nTherefore, we get the following estimate on the Green’s functions: $$\\bigl|  G_N (\\underline{x}, E) (n_1, n_2)  \\bigr| \\le \\frac{\\lVert M_{n_1} (\\underline{x}, E) \\rVert  \\cdot \\lVert M_{N-n_2} ({\\rm T}^{n_2} \\underline{x}, E) \\rVert}\n{\\bigl|  \\mbox{ det } (H_{N} (\\underline{x}) - E)  \\bigr|}$$\n\nCombining this with the LDT <a href=\"#ldt\" data-reference-type=\"eqref\" data-reference=\"ldt\">[ldt]</a>, we obtain the following bounds on the Green’s functions $G_{\\Lambda} (E, \\underline{x})$ associated with the operator <a href=\"#3op\" data-reference-type=\"eqref\" data-reference=\"3op\">[3op]</a>.\n\nFor every $N$ large enough and for every energy $E$, there is a set $\\Omega_{N} (E) \\subset \\mathbb{T}^2$ with $\\mbox{mes } [ \\Omega_{N} (E) ] < e^{- N^{\\sigma}}$ so that for any $\\underline{x}\\notin \\Omega_{N} (E)$, one of the intervals $$\\Lambda = \\Lambda (\\underline{x}) = [1, N ], [1, N - 1], [2, N ], [2, N - 1]$$ will satisfy : $$\\label{3green} \n | G_{\\Lambda} (E, \\underline{x}) (n_1 , n_2 ) | < e^{- c  | n_1  - n_2 | + N^{1 -}}$$",
    "labels": [
      "3green",
      "tmdet"
    ],
    "refs": [
      "3op",
      "ldt"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1111-1120::s32",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L944-957::s21",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1111-1120::s32",
        "direction": "comment"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1111-1120::s32",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1111,
    "end_line": 1120,
    "text": "For every $N$ large enough and for every energy $E$, there is a set $\\Omega_{N} (E) \\subset \\mathbb{T}^2$ with $\\mbox{mes } [ \\Omega_{N} (E) ] < e^{- N^{\\sigma}}$ so that for any $\\underline{x}\\notin \\Omega_{N} (E)$, one of the intervals $$\\Lambda = \\Lambda (\\underline{x}) = [1, N ], [1, N - 1], [2, N ], [2, N - 1]$$ will satisfy : $$\\label{3green} \n | G_{\\Lambda} (E, \\underline{x}) (n_1 , n_2 ) | < e^{- c  | n_1  - n_2 | + N^{1 -}}$$\n\nSince $v(\\underline{x}) = \\sum_{\\underline{l}\\in \\mathbb{Z}^2} \\hat{v} (\\underline{l}) e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$ and $\\bigl|  \\hat{v} (\\underline{l})  \\bigr|  \\leq  M e^{- \\rho \\left|  \\underline{l} \\right|^{1/s}}$ for all $\\underline{l}\\in \\mathbb{Z}^2$, substituting in (<a href=\"#3green\" data-reference-type=\"ref\" data-reference=\"3green\">[3green]</a>) $v (\\underline{x})$ by $v_1 (\\underline{x}) := \\sum_{|\\underline{l}| \\leq C N^{s}} \\hat{v} (\\underline{l}) e^{2 \\pi i \\, \\underline{l}\\cdot \\underline{x}}$ we can assume that the ‘bad set’ $\\Omega_{N} (E)$ above not only has exponentially small measure, but it also has bounded algebraic complexity - it is semi-algebraic of degree $\\, \\leq N^{d(s)}.$\n\nThese sets depend on the energy $E$. The rest of the proof of localization for <a href=\"#3op\" data-reference-type=\"eqref\" data-reference=\"3op\">[3op]</a> involves the elimination of the energy, which uses semi-algebraic set theory, and follows exactly the same pattern as the proof of the corresponding result for the analytic case (see , or Chapter 15 in ).\n\nOur statement for the skew-shift model is weaker than the one for the multi-frequency shift, since they both mirror the corresponding results in the analytic case.\n\n<div class=\"remark\">\n\n**Remark 4**. *We do not know if the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> is indeed necessary, either for the models considered here or for the single-variable shift considered in . In particular, we do not know if the Lyapunov exponent is still positive throughout the spectrum for potential functions that have flat parts but are very smooth otherwise. This is a difficult and interesting problem.*",
    "labels": [
      "3green"
    ],
    "refs": [
      "3green",
      "3op",
      "TC"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1092-1110::s31",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1121-1144::s33",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L1092-1110::s31",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L1078-1091::s30",
        "direction": "reference"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1121-1144::s33",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1121,
    "end_line": 1144,
    "text": "**Remark 4**. *We do not know if the transversality condition <a href=\"#TC\" data-reference-type=\"eqref\" data-reference=\"TC\">[TC]</a> is indeed necessary, either for the models considered here or for the single-variable shift considered in . In particular, we do not know if the Lyapunov exponent is still positive throughout the spectrum for potential functions that have flat parts but are very smooth otherwise. This is a difficult and interesting problem.*\n\n*Finally, a more challenging problem regarding Gevrey potential functions is proving localization for a long range model, one where the Laplacian is replaced by a Toeplitz matrix. In the case of the skew-shift dynamics, this could lead to applications to more general quantum kicked rotator equations.*\n\n</div>\n\n<div class=\"thebibliography\">\n\n10\n\nKristian Bjerklöv, *Positive Lyapunov exponent and minimality for a class of one-dimensional quasi-periodic Schrödinger equations*, Ergodic Theory Dynam. Systems **25** (2005), no. 4, 1015–1045.\n\nJ. Bourgain, *Positive Lyapounov exponents for most energies*, Geometric aspects of functional analysis, Lecture Notes in Math., vol. 1745, Springer, Berlin, 2000, pp. 37–66.\n\nto3em, *On the spectrum of lattice Schrödinger operators with deterministic potential. II*, J. Anal. Math. **88** (2002), 221–254, Dedicated to the memory of Tom Wolff.\n\nto3em, *Green’s function estimates for lattice Schrödinger operators and applications*, Annals of Mathematics Studies, vol. 158, Princeton University Press, Princeton, NJ, 2005.\n\nJ. Bourgain and M. Goldstein, *On nonperturbative localization with quasi-periodic potential*, Ann. of Math. (2) **152** (2000), no. 3, 835–879.\n\nJean Bourgain, Michael Goldstein, and Wilhelm Schlag, *Anderson localization for Schrödinger operators on $\\mathbb Z$ with potentials given by the skew-shift*, Comm. Math. Phys. **220** (2001), no. 3, 583–621.\n\nJackson Chan, *Method of variations of potential of quasi-periodic Schrödinger equations*, Geom. Funct. Anal. **17** (2008), no. 5, 1416–1478.\n\nJakson Chan, Michael Goldstein, and Wilhelm Schlag, *On non-perturbative anderson localization for $C^\\alpha$ potentials generated by shifts and skew-shifts*, preprint (2006), 1–39.",
    "labels": [],
    "refs": [
      "TC"
    ],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1111-1120::s32",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1145-1164::s34",
        "direction": "next"
      },
      {
        "id": "1204.3086v3::L99-113::s6",
        "direction": "reference"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1145-1164::s34",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1145,
    "end_line": 1164,
    "text": "Jakson Chan, Michael Goldstein, and Wilhelm Schlag, *On non-perturbative anderson localization for $C^\\alpha$ potentials generated by shifts and skew-shifts*, preprint (2006), 1–39.\n\nH. L. Cycon, R. G. Froese, W. Kirsch, and B. Simon, *Schrödinger operators with application to quantum mechanics and global geometry*, study ed., Texts and Monographs in Physics, Springer-Verlag, Berlin, 1987.\n\nDidier D’Acunto and Krzysztof Kurdyka, *Explicit bounds for the ł ojasiewicz exponent in the gradient inequality for polynomials*, Ann. Polon. Math. **87** (2005), 51–61.\n\nL. H. Eliasson, *Discrete one-dimensional quasi-periodic Schrödinger operators with pure point spectrum*, Acta Math. **179** (1997), no. 2, 153–196.\n\nMichael Goldstein and Wilhelm Schlag, *Hölder continuity of the integrated density of states for quasi-periodic Schrödinger equations and averages of shifts of subharmonic functions*, Ann. of Math. (2) **154** (2001), no. 1, 155–203.\n\nto3em, *Fine properties of the integrated density of states and a quantitative separation property of the Dirichlet eigenvalues*, Geom. Funct. Anal. **18** (2008), no. 3, 755–869.\n\nto3em, *On resonances and the formation of gaps in the spectrum of quasi-periodic Schrödinger equations*, Ann. of Math. (2) **173** (2011), no. 1, 337–475.\n\nYitzhak Katznelson, *An introduction to harmonic analysis*, John Wiley & Sons Inc., New York, 1968.\n\nSilvius Klein, *Anderson localization for the discrete one-dimensional quasi-periodic schödinger operator with potential defined by a gevrey-class function*, to appear, J. Funct. Anal. (2005), no. 2, 255–292.\n\nJános Kollár, *An effective łojasiewicz inequality for real polynomials*, Period. Math. Hungar. **38** (1999), no. 3, 213–221.\n\nHelge Krüger, *Multiscale analysis for ergodic Schrödinger operators and positivity of Lyapunov exponents*, J. Anal. Math. **115** (2011), 343–387.",
    "labels": [],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1121-1144::s33",
        "direction": "previous"
      },
      {
        "id": "1204.3086v3::L1165-1171::s35",
        "direction": "next"
      }
    ]
  },
  {
    "id": "1204.3086v3::L1165-1171::s35",
    "file": "data/data/full_markdown/1204.3086v3.md",
    "section_path": "Large deviation theorem, the proof of main results",
    "start_line": 1165,
    "end_line": 1171,
    "text": "Helge Krüger, *Multiscale analysis for ergodic Schrödinger operators and positivity of Lyapunov exponents*, J. Anal. Math. **115** (2011), 343–387.\n\nto3em, *The spectrum of skew-shift Schrödinger operators contains intervals*, J. Funct. Anal. **262** (2012), no. 3, 773–810.\n\nB. Ya. Levin, *Lectures on entire functions*, Translations of Mathematical Monographs, vol. 150, American Mathematical Society, Providence, RI, 1996, In collaboration with and with a preface by Yu. Lyubarskii, M. Sodin and V. Tkachenko, Translated from the Russian manuscript by Tkachenko.\n\nD. H. Phong, E. M. Stein, and J. A. Sturm, *On the growth and stability of real-analytic functions*, Amer. J. Math. **121** (1999), no. 3, 519–554.\n\n</div>",
    "labels": [],
    "refs": [],
    "meta": {
      "heading": {
        "level": 1,
        "title": "Large deviation theorem, the proof of main results"
      }
    },
    "neighbors": [
      {
        "id": "1204.3086v3::L1145-1164::s34",
        "direction": "previous"
      }
    ]
  }
]