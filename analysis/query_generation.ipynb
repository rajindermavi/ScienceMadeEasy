{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6518468d",
   "metadata": {},
   "source": [
    "# Query Generation\n",
    "\n",
    "Source data does not come with associated questions. Thus we will generate questions for each chunk to evaluate retrieval and RAG responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fb56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import notebook_bootstrap \n",
    "import inspect\n",
    "from logs.logger import get_logger\n",
    "logger = get_logger()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI()\n",
    "\n",
    "import config\n",
    "from utilities import load_matches, sample_wo_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68c0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = {\n",
    "    'md':config.MD_JSONL,\n",
    "    'txt':config.TXT_JSONL\n",
    "}\n",
    "KEYWORDS = (\"introduction\", \"detail\", \"prelim\", \"result\")\n",
    "NUMBER_RANDOM_ELEMENTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0997c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextToQuery(BaseModel):\n",
    "    query: Optional[str] = None\n",
    "    complexity: int\n",
    "\n",
    "class Status(str, Enum):\n",
    "    OK = \"OK\"\n",
    "    update = \"update\"\n",
    "    fail = \"fail\"\n",
    "\n",
    "class EvalQuery(BaseModel):\n",
    "    status: Status\n",
    "    reason: str\n",
    "    query: Optional[str] = None\n",
    "\n",
    "\n",
    "schema_text_to_query = {\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"title\": \"TextToQuery\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"query\": {\"type\": [\"string\", \"null\"]},\n",
    "        \"complexity\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"minimum\": 0,   \n",
    "            \"maximum\": 10     \n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"query\", \"complexity\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "schema_query_eval = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"status\": {\"type\": \"string\", \"enum\": [\"OK\", \"update\", \"fail\"]},\n",
    "        \"query\": {\"type\": [\"string\", \"null\"]}\n",
    "    },\n",
    "    \"required\": [\"status\"],\n",
    "    \"additionalProperties\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e66a91",
   "metadata": {},
   "source": [
    "## TEXT TO QUERY PROMPTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeffabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TEXT_TO_QUERY_KEY = 'text_to_query_v1'\n",
    "\n",
    "SYSTEM_TEXT_TO_QUERY = \"\"\"\n",
    "You are a question generator for advanced STEM texts.\n",
    "\n",
    "GOAL:\n",
    "Create one thoughtful, conceptually clear question that could be answered by a student who studied the material summarized in the given text chunk — even if they no longer see that exact text.\n",
    "\"\"\"\n",
    "\n",
    "INSTRUCTIONS_TEXT_TO_QUERY = \"\"\"\n",
    "PROCESS:\n",
    "1. Read the text and extract its *main conceptual elements*, including:\n",
    "   - the physical or mathematical system described,\n",
    "   - key parameters and what varying them does,\n",
    "   - contrasting viewpoints, interpretations, or domains (e.g., physics vs mathematics),\n",
    "    - Ignore structural or organizational material (section summaries, theorem references, proof outlines, cross-references, etc.).\n",
    "    - Focus only on scientific or mathematical statements that describe a system, property, phenomenon, or limitation.\n",
    "\n",
    "2. Identify ONE intellectually central aspect of the text — this could be:\n",
    "     • when a normally expected implication fails (e.g., positive Lyapunov exponent does not guarantee localization),\n",
    "     • a specific regime or parameter case (e.g., criticality, localization, number theoretic properties),\n",
    "     • when certain dynamical or spectral conditions change qualitative behavior,\n",
    "     • when a model behaves differently under specific parameter regimes or approximations.\n",
    "     • discussion of physical and mathematical viewpoints,\n",
    "     • a mechanism or phenomenon the model aims to explain,\n",
    "\n",
    "   Then, form a single question that:\n",
    "     - explicitly names that conceptual situation using neutral descriptive phrases \n",
    "     - asks about a *non-trivial property, behavior, or contrast* within that setting,\n",
    "     - asks the student to explain *why, compare, or predict* something within that context,\n",
    "     - is specific enough that an expert reader could tell what concept it is testing,\n",
    "     - could still be answered from a student’s notes without seeing the text itself.\n",
    "       (e.g., “for ergodic Schrödinger operators with quasi-periodic dynamics,” \n",
    "             “when a system is well approximated by periodic transformations,” \n",
    "             “under conditions leading to a positive Lyapunov exponent”), \n",
    "     - remains concrete and content-anchored (avoid generic “a mathematical model” wording).\n",
    "\n",
    "3. Phrase the question using domain-accurate terminology but without literal reuse of the source’s wording or symbols.\n",
    "   Guidelines:\n",
    "     - Allow: “ergodic Schrödinger operator,” “Lyapunov exponent,” “Anderson localization,” “periodic approximation.” etc.\n",
    "     - Avoid: “this paper,” “the text,” “Equation (1),” \"Theorem 2,\" or exact symbols (λ, α, θ).\n",
    "     - When a symbol or name is unavoidable, replace it with a neutral descriptor (e.g., “a coupling parameter,” “the external field,” “the rotation parameter”).\n",
    "\n",
    "\n",
    "4. The question should read naturally and not start with vague scaffolds like “In this approach…”.\n",
    "\n",
    "5. If the text is purely definitional, return an empty query with complexity 0.\n",
    "  OUTPUT FORMAT (JSON ONLY):\n",
    "  {\n",
    "    \"query\": \"<conceptually specific question>\",\n",
    "    \"complexity\": <integer 0–10>\n",
    "  }\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca519e4f",
   "metadata": {},
   "source": [
    "## EVALUATE QUERY PROMPTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b37a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_EVALUATE_QUERY_KEY = 'evaluate_query_v1'\n",
    "\n",
    "SYSTEM_EVALUATE_QUERY = \"\"\"\n",
    "You are an expert in advanced mathematics and mathematical physics. \n",
    "Your task is to evaluate whether a student-generated question is well-posed, self-contained, and answerable \n",
    "by a knowledgeable reader with access to standard reference papers (but not to the original text chunk).\n",
    "\n",
    "Provide a concise explanation (\"reason\") for your decision.\n",
    "\n",
    "A good question must:\n",
    "1. Refer to clearly defined mathematical or physical concepts \n",
    "   (e.g. Lyapunov exponents, CMV matrices, Hausdorff dimension, Anderson localization, reflection symmetries).\n",
    "2. Contain an intelligible question or explanatory structure — it must include a clear interrogative or request for explanation, relation, or significance \n",
    "   (e.g. “what,” “how,” “why,” “explain,” “describe,” “discuss”).\n",
    "3. Be answerable from established literature or standard knowledge, not dependent on access to the original text.\n",
    "4. Avoid contradictions, undefined jargon, or purely contextual references (e.g. “in the given text”).\n",
    "5. Not consist solely of an unordered list of terms, variables, or topics without an explicit question.\n",
    "\n",
    "Return exactly one JSON object in one of these forms:\n",
    "- {\"status\": \"OK\", \"reason\": \"<brief justification>\"}\n",
    "- {\"status\": \"update\", \"query\": \"<lightly corrected question>\", \"reason\": \"<brief justification>\"}\n",
    "- {\"status\": \"fail\", \"reason\": \"<brief justification>\"}\n",
    "\n",
    "Classification guidelines:\n",
    "- Consider concise, domain-specific, or research-level questions as valid when the terms and relationships are standard within advanced mathematics or physics.\n",
    "- If the input is merely a list of topics or keywords with no interrogative phrasing, mark it as \"fail\".\n",
    "- If the question only needs minor stylistic cleanup (e.g. remove vague references, fix LaTeX or clarify notation), mark it as \"update\".\n",
    "- Assign \"fail\" only when the question is incoherent, not a question, or cannot be repaired by small edits.\n",
    "\"\"\".strip()\n",
    "\n",
    "EVAL_QUERY_EG_1_USER = \"purely absolutely continuous spectrum, localization techniques, Aubry duality, Lyapunov exponents\"\n",
    "EVAL_QUERY_EG_1_ASSIST = \"\"\"{\"status\": \"fail\", \"reason\": \"The input is just a list of terms without any question or explanatory structure.\"}\"\"\"\n",
    "\n",
    "EVAL_QUERY_EG_2_USER = \"What are the small denominator problems in one-dimensional quasiperiodic Schrödinger operators?\"\n",
    "EVAL_QUERY_EG_2_ASSIST = \"\"\"{\"status\": \"OK\", \"reason\": \"All terms are well-defined; the question invites a standard explanation from the literature.\"}\"\"\"\n",
    "\n",
    "EVAL_QUERY_EG_3_USER = \"What are the main results regarding localization for CMV operators in the presence of reflection symmetries?\"\n",
    "EVAL_QUERY_EG_3_ASSIST = \"\"\"{\"status\": \"OK\", \"reason\": \"A valid summary-type question referring to established topics in spectral theory.\"\"\"\n",
    "\n",
    "EVAL_QUERY_EG_4_USER = \"Explain the significance of the parameters β and θ in the almost Mathieu operator H_{β,θ}.\"\n",
    "EVAL_QUERY_EG_4_ASSIST = \"\"\"{\"status\": \"OK\", \"reason\": \"Well-defined parameters and context; self-contained and answerable.\"}\"\"\"\n",
    "\n",
    "EVAL_QUERY_EG_4_USER = \"Explain the effect of randomness on energy in physics.\"\n",
    "EVAL_QUERY_EG_4_ASSIST = \"\"\"{\"status\": \"fail\", \"reason\": \"Too broad and lacks precise mathematical context.\"}\"\"\"\n",
    "\n",
    "EVAL_QUERY_EG_5_USER =  \"In the given text, how is the spectrum shown to be self-similar?\" \n",
    "EVAL_QUERY_EG_5_ASSIST = \"\"\"{\"status\": \"update\", \"query\": \"How is the spectrum shown to be self-similar?\", \"reason\": \"Remove reference to source for self-containment.\"}\"\"\"\n",
    "\n",
    "eval_query_input=[\n",
    "   {\"role\": \"system\", \"content\": SYSTEM_TEXT_TO_QUERY},\n",
    "   {\"role\": \"system\", \"content\": INSTRUCTIONS_TEXT_TO_QUERY},\n",
    "   {\"role\": \"user\", \"content\": \"JSON Schema:\"},\n",
    "   {\"role\": \"user\", \"content\": EVAL_QUERY_EG_1_USER},\n",
    "   {\"role\": \"assistant\", \"content\": EVAL_QUERY_EG_1_ASSIST},\n",
    "   {\"role\": \"user\", \"content\": EVAL_QUERY_EG_2_USER},\n",
    "   {\"role\": \"assistant\", \"content\": EVAL_QUERY_EG_2_ASSIST},\n",
    "   {\"role\": \"user\", \"content\": EVAL_QUERY_EG_3_USER},\n",
    "   {\"role\": \"assistant\", \"content\": EVAL_QUERY_EG_3_ASSIST},\n",
    "   {\"role\": \"user\", \"content\": EVAL_QUERY_EG_4_USER},\n",
    "   {\"role\": \"assistant\", \"content\": EVAL_QUERY_EG_4_ASSIST},\n",
    "   {\"role\": \"user\", \"content\": EVAL_QUERY_EG_5_USER},\n",
    "   {\"role\": \"assistant\", \"content\": EVAL_QUERY_EG_5_ASSIST},\n",
    "]\n",
    "\n",
    "USER_EVALUATE_QUERY = \"\"\"\n",
    "<query>\n",
    "{query}\n",
    "</query>\n",
    "\n",
    "EVALUATION INSTRUCTIONS:\n",
    "- If the query uses ambiguous or incorrect terminology but can be clarified by a small edit, fix it and return the updated version.\n",
    "- If the query mixes incompatible concepts, lacks mathematical precision, or cannot be answered without the original text, return \"fail\".\n",
    "- Only output a JSON object — no commentary or explanation.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbdae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_TEXT_TO_QUERY},\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTIONS_TEXT_TO_QUERY},\n",
    "        {\"role\": \"user\", \"content\": \"Priming cache.\"},\n",
    "    ],\n",
    "    max_output_tokens=16,\n",
    "    temperature=0,\n",
    "    text={\"format\": {\"type\": \"json_object\"}},\n",
    "    prompt_cache_key=SYSTEM_TEXT_TO_QUERY_KEY,\n",
    ")\n",
    "\n",
    "_ = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_EVALUATE_QUERY},\n",
    "        {\"role\": \"user\", \"content\": \"Priming cache.\"},\n",
    "    ],\n",
    "    max_output_tokens=16,\n",
    "    temperature=0,\n",
    "    text={\"format\": {\"type\": \"json_object\"}},\n",
    "    prompt_cache_key=SYSTEM_EVALUATE_QUERY_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d453b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_matches = load_matches(config.MD_JSONL,KEYWORDS)\n",
    "md_sample = sample_wo_replacement(md_matches,NUMBER_RANDOM_ELEMENTS)\n",
    "txt_matches = load_matches(config.TXT_JSONL,KEYWORDS)\n",
    "txt_sample = sample_wo_replacement(txt_matches,NUMBER_RANDOM_ELEMENTS)\n",
    "full_sample = [ {**s, 'etl':'md'} for s in md_sample ] + [ {**s, 'etl':'txt'} for s in txt_sample ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4f66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for chunk in full_sample:\n",
    "    try:\n",
    "        chunk_id = chunk['chunk_id']\n",
    "        text = chunk['text']\n",
    "        etl = chunk['etl']\n",
    "        prompt = json.dumps(text)\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            #input=[\n",
    "            #    {\"role\": \"user\", \"content\": USER_TEXT_TO_QUERY.format(text=text)},\n",
    "            #],\n",
    "            instructions='Return JSON ONLY. Return no explanatory prose.',\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_TEXT_TO_QUERY},\n",
    "                {\"role\": \"system\", \"content\": INSTRUCTIONS_TEXT_TO_QUERY},\n",
    "                {\"role\": \"user\", \"content\": \"JSON Schema:\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0.85,\n",
    "            text_format=TextToQuery,\n",
    "            #text={\"format\": {\"type\": \"json_object\"}},\n",
    "            prompt_cache_key=SYSTEM_TEXT_TO_QUERY_KEY,\n",
    "        )\n",
    "        #response = json.loads(response.output_text)\n",
    "        #query = response['query']\n",
    "        #complexity = response['complexity']\n",
    "\n",
    "        if not response.output_parsed.query:\n",
    "            continue\n",
    "\n",
    "        query_v1 = response.output_parsed.query\n",
    "        complexity = response.output_parsed.complexity\n",
    "\n",
    "        eval_query_v1 = [\n",
    "            *eval_query_input,\n",
    "            {\"role\": \"user\", \"content\": USER_EVALUATE_QUERY.format(query=query_v1)},\n",
    "        ]\n",
    "\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o\",\n",
    "            #input=[\n",
    "            #    {\"role\": \"user\", \"content\": USER_TEXT_TO_QUERY.format(text=text)},\n",
    "            #],\n",
    "            input=eval_query_v1,\n",
    "            temperature=0,\n",
    "            text_format=EvalQuery,\n",
    "            #text={\"format\": {\"type\": \"json_object\"}},\n",
    "            prompt_cache_key=SYSTEM_EVALUATE_QUERY_KEY,\n",
    "        )\n",
    "        status = response.output_parsed.status.name\n",
    "        query_v2 = response.output_parsed.query\n",
    "        reason = response.output_parsed.reason\n",
    "        if status != 'fail':\n",
    "            record = {\n",
    "                'chunk_id':chunk_id,\n",
    "                'text':text,\n",
    "                'etl':etl,\n",
    "                'query_v1':query_v1,\n",
    "                'query_v2':query_v2,\n",
    "                'complexity':complexity,\n",
    "                'evaluation':status,\n",
    "                'reason':reason\n",
    "            }\n",
    "            records.append(record)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2654af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"generated_queries.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in records:\n",
    "        json.dump(rec, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
